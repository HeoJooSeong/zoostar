{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-alpha0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import tensorflow.keras.utils as utils\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.utils as utils\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "# 1. 데이터셋 준비하기\n",
    "\n",
    "# 훈련셋과 시험셋 로딩\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# 훈련셋과 검증셋 분리\n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "\n",
    "X_train = X_train.reshape(50000, 784).astype('float32') / 255.0\n",
    "X_val = X_val.reshape(10000, 784).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "# 훈련셋, 검증셋 고르기\n",
    "train_rand_idxs = np.random.choice(50000, 700)\n",
    "val_rand_idxs = np.random.choice(10000, 300)\n",
    "\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]\n",
    "\n",
    "# 라벨링 전환\n",
    "Y_train = utils.to_categorical(Y_train)\n",
    "Y_val = utils.to_categorical(Y_val)\n",
    "Y_test = utils.to_categorical(Y_test)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# # 3. 모델 엮기\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# # 4. 모델 학습시키기\n",
    "# hist = model.fit(X_train, Y_train, epochs=1000, batch_size=10, validation_data=(X_val, Y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700\n"
     ]
    }
   ],
   "source": [
    "print (len(train_rand_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x182f968f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. 모델 학습 과정 표시하기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 직접 콜백 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - loss: 2.305312\n",
      "epoch: 100 - loss: 1.807977\n",
      "epoch: 200 - loss: 1.613291\n",
      "epoch: 300 - loss: 1.491261\n",
      "epoch: 400 - loss: 1.398759\n",
      "epoch: 500 - loss: 1.326976\n",
      "epoch: 600 - loss: 1.269507\n",
      "epoch: 700 - loss: 1.218473\n",
      "epoch: 800 - loss: 1.170793\n",
      "epoch: 900 - loss: 1.125860\n"
     ]
    }
   ],
   "source": [
    "class CustomHistory(tf.keras.callbacks.Callback):\n",
    "    def init(self):\n",
    "        self.epoch = 0\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        self.train_acc = []\n",
    "        self.val_acc = []        \n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.train_loss.append(logs.get('loss'))\n",
    "        self.val_loss.append(logs.get('val_loss'))\n",
    "        self.train_acc.append(logs.get('acc'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        if self.epoch % 100 == 0:\n",
    "            print(\"epoch: {0} - loss: {1:8.6f}\".format(self.epoch, logs.get('loss')))\n",
    "            \n",
    "        self.epoch += 1\n",
    "\n",
    "        \n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# 훈련셋과 검증셋 분리\n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "\n",
    "X_train = X_train.reshape(50000, 784).astype('float32') / 255.0\n",
    "X_val = X_val.reshape(10000, 784).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "# 훈련셋, 검증셋 고르기\n",
    "train_rand_idxs = np.random.choice(50000, 700)\n",
    "val_rand_idxs = np.random.choice(10000, 300)\n",
    "\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]\n",
    "\n",
    "# 라벨링 전환\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_val = np_utils.to_categorical(Y_val)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# 3. 모델 엮기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "\n",
    "custom_hist = CustomHistory()\n",
    "custom_hist.init()\n",
    "\n",
    "for epoch_idx in range(1000):\n",
    "#     print ('epochs : ' + str(epoch_idx) )\n",
    "    model.fit(X_train, Y_train, epochs=1, batch_size=10, verbose=0, validation_data=(X_val, Y_val), callbacks=[custom_hist])\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1832cf3908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(custom_hist.train_loss, 'y', label='train loss')\n",
    "loss_ax.plot(custom_hist.val_loss, 'r', label='val loss')\n",
    "\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 조기종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 0s 250us/sample - loss: 2.3535 - accuracy: 0.0757 - val_loss: 2.3290 - val_accuracy: 0.0867\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 2.3333 - accuracy: 0.0886 - val_loss: 2.3193 - val_accuracy: 0.1067\n",
      "Epoch 3/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.3232 - accuracy: 0.0957 - val_loss: 2.3144 - val_accuracy: 0.1167\n",
      "Epoch 4/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 2.3174 - accuracy: 0.0986 - val_loss: 2.3115 - val_accuracy: 0.1200\n",
      "Epoch 5/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 2.3135 - accuracy: 0.0986 - val_loss: 2.3095 - val_accuracy: 0.1133\n",
      "Epoch 6/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.3109 - accuracy: 0.1100 - val_loss: 2.3078 - val_accuracy: 0.1233\n",
      "Epoch 7/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.3091 - accuracy: 0.1143 - val_loss: 2.3065 - val_accuracy: 0.1267\n",
      "Epoch 8/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.3075 - accuracy: 0.1186 - val_loss: 2.3051 - val_accuracy: 0.1300\n",
      "Epoch 9/3000\n",
      "700/700 [==============================] - 0s 85us/sample - loss: 2.3061 - accuracy: 0.1186 - val_loss: 2.3036 - val_accuracy: 0.1267\n",
      "Epoch 10/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 2.3046 - accuracy: 0.1200 - val_loss: 2.3020 - val_accuracy: 0.1300\n",
      "Epoch 11/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.3030 - accuracy: 0.1286 - val_loss: 2.3001 - val_accuracy: 0.1300\n",
      "Epoch 12/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.3012 - accuracy: 0.1314 - val_loss: 2.2982 - val_accuracy: 0.1300\n",
      "Epoch 13/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 2.2994 - accuracy: 0.1343 - val_loss: 2.2961 - val_accuracy: 0.1367\n",
      "Epoch 14/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.2975 - accuracy: 0.1329 - val_loss: 2.2935 - val_accuracy: 0.1500\n",
      "Epoch 15/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.2952 - accuracy: 0.1343 - val_loss: 2.2903 - val_accuracy: 0.1433\n",
      "Epoch 16/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 2.2925 - accuracy: 0.1386 - val_loss: 2.2867 - val_accuracy: 0.1600\n",
      "Epoch 17/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.2898 - accuracy: 0.1443 - val_loss: 2.2830 - val_accuracy: 0.1633\n",
      "Epoch 18/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.2871 - accuracy: 0.1414 - val_loss: 2.2790 - val_accuracy: 0.1667\n",
      "Epoch 19/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 2.2844 - accuracy: 0.1400 - val_loss: 2.2751 - val_accuracy: 0.1667\n",
      "Epoch 20/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.2816 - accuracy: 0.1429 - val_loss: 2.2712 - val_accuracy: 0.1667\n",
      "Epoch 21/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 2.2789 - accuracy: 0.1414 - val_loss: 2.2676 - val_accuracy: 0.1667\n",
      "Epoch 22/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.2761 - accuracy: 0.1414 - val_loss: 2.2641 - val_accuracy: 0.1633\n",
      "Epoch 23/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.2734 - accuracy: 0.1443 - val_loss: 2.2603 - val_accuracy: 0.1633\n",
      "Epoch 24/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 2.2705 - accuracy: 0.1443 - val_loss: 2.2563 - val_accuracy: 0.1667\n",
      "Epoch 25/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.2676 - accuracy: 0.1486 - val_loss: 2.2524 - val_accuracy: 0.1667\n",
      "Epoch 26/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.2646 - accuracy: 0.1486 - val_loss: 2.2486 - val_accuracy: 0.1733\n",
      "Epoch 27/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.2616 - accuracy: 0.1543 - val_loss: 2.2445 - val_accuracy: 0.1767\n",
      "Epoch 28/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 2.2586 - accuracy: 0.1571 - val_loss: 2.2403 - val_accuracy: 0.1767\n",
      "Epoch 29/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.2555 - accuracy: 0.1586 - val_loss: 2.2363 - val_accuracy: 0.1767\n",
      "Epoch 30/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.2523 - accuracy: 0.1600 - val_loss: 2.2318 - val_accuracy: 0.1767\n",
      "Epoch 31/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 2.2493 - accuracy: 0.1600 - val_loss: 2.2277 - val_accuracy: 0.1767\n",
      "Epoch 32/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 2.2463 - accuracy: 0.1600 - val_loss: 2.2235 - val_accuracy: 0.1800\n",
      "Epoch 33/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 2.2431 - accuracy: 0.1586 - val_loss: 2.2190 - val_accuracy: 0.1800\n",
      "Epoch 34/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 2.2400 - accuracy: 0.1629 - val_loss: 2.2148 - val_accuracy: 0.1833\n",
      "Epoch 35/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 2.2369 - accuracy: 0.1643 - val_loss: 2.2104 - val_accuracy: 0.1867\n",
      "Epoch 36/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.2338 - accuracy: 0.1586 - val_loss: 2.2067 - val_accuracy: 0.1900\n",
      "Epoch 37/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.2308 - accuracy: 0.1643 - val_loss: 2.2025 - val_accuracy: 0.1900\n",
      "Epoch 38/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 2.2279 - accuracy: 0.1600 - val_loss: 2.1988 - val_accuracy: 0.1867\n",
      "Epoch 39/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 2.2250 - accuracy: 0.1614 - val_loss: 2.1952 - val_accuracy: 0.1867\n",
      "Epoch 40/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.2221 - accuracy: 0.1614 - val_loss: 2.1914 - val_accuracy: 0.1900\n",
      "Epoch 41/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.2192 - accuracy: 0.1629 - val_loss: 2.1878 - val_accuracy: 0.1867\n",
      "Epoch 42/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 2.2164 - accuracy: 0.1614 - val_loss: 2.1842 - val_accuracy: 0.1900\n",
      "Epoch 43/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 2.2137 - accuracy: 0.1629 - val_loss: 2.1804 - val_accuracy: 0.1900\n",
      "Epoch 44/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.2109 - accuracy: 0.1614 - val_loss: 2.1770 - val_accuracy: 0.1900\n",
      "Epoch 45/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.2082 - accuracy: 0.1614 - val_loss: 2.1737 - val_accuracy: 0.1900\n",
      "Epoch 46/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.2056 - accuracy: 0.1614 - val_loss: 2.1705 - val_accuracy: 0.1900\n",
      "Epoch 47/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.2031 - accuracy: 0.1600 - val_loss: 2.1675 - val_accuracy: 0.1900\n",
      "Epoch 48/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.2006 - accuracy: 0.1643 - val_loss: 2.1648 - val_accuracy: 0.1933\n",
      "Epoch 49/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.1981 - accuracy: 0.1700 - val_loss: 2.1617 - val_accuracy: 0.1967\n",
      "Epoch 50/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.1955 - accuracy: 0.1686 - val_loss: 2.1590 - val_accuracy: 0.1967\n",
      "Epoch 51/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.1930 - accuracy: 0.1743 - val_loss: 2.1555 - val_accuracy: 0.1967\n",
      "Epoch 52/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.1906 - accuracy: 0.1729 - val_loss: 2.1527 - val_accuracy: 0.1933\n",
      "Epoch 53/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.1882 - accuracy: 0.1729 - val_loss: 2.1499 - val_accuracy: 0.1967\n",
      "Epoch 54/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.1858 - accuracy: 0.1743 - val_loss: 2.1474 - val_accuracy: 0.2000\n",
      "Epoch 55/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.1835 - accuracy: 0.1757 - val_loss: 2.1447 - val_accuracy: 0.2000\n",
      "Epoch 56/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 2.1812 - accuracy: 0.1757 - val_loss: 2.1421 - val_accuracy: 0.2000\n",
      "Epoch 57/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.1789 - accuracy: 0.1743 - val_loss: 2.1395 - val_accuracy: 0.2033\n",
      "Epoch 58/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 2.1767 - accuracy: 0.1786 - val_loss: 2.1368 - val_accuracy: 0.2033\n",
      "Epoch 59/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.1745 - accuracy: 0.1814 - val_loss: 2.1343 - val_accuracy: 0.2033\n",
      "Epoch 60/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.1723 - accuracy: 0.1857 - val_loss: 2.1317 - val_accuracy: 0.2100\n",
      "Epoch 61/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.1701 - accuracy: 0.1843 - val_loss: 2.1295 - val_accuracy: 0.2133\n",
      "Epoch 62/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.1680 - accuracy: 0.1843 - val_loss: 2.1272 - val_accuracy: 0.2133\n",
      "Epoch 63/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.1659 - accuracy: 0.1900 - val_loss: 2.1247 - val_accuracy: 0.2167\n",
      "Epoch 64/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 2.1637 - accuracy: 0.1900 - val_loss: 2.1221 - val_accuracy: 0.2167\n",
      "Epoch 65/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.1617 - accuracy: 0.1871 - val_loss: 2.1198 - val_accuracy: 0.2167\n",
      "Epoch 66/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.1596 - accuracy: 0.1914 - val_loss: 2.1175 - val_accuracy: 0.2167\n",
      "Epoch 67/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.1574 - accuracy: 0.1900 - val_loss: 2.1153 - val_accuracy: 0.2200\n",
      "Epoch 68/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.1553 - accuracy: 0.1914 - val_loss: 2.1128 - val_accuracy: 0.2200\n",
      "Epoch 69/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.1532 - accuracy: 0.1914 - val_loss: 2.1107 - val_accuracy: 0.2200\n",
      "Epoch 70/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.1511 - accuracy: 0.1929 - val_loss: 2.1085 - val_accuracy: 0.2200\n",
      "Epoch 71/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 2.1491 - accuracy: 0.1914 - val_loss: 2.1066 - val_accuracy: 0.2200\n",
      "Epoch 72/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 2.1470 - accuracy: 0.1929 - val_loss: 2.1043 - val_accuracy: 0.2200\n",
      "Epoch 73/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 2.1449 - accuracy: 0.1929 - val_loss: 2.1020 - val_accuracy: 0.2167\n",
      "Epoch 74/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 2.1429 - accuracy: 0.1971 - val_loss: 2.0995 - val_accuracy: 0.2167\n",
      "Epoch 75/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.1409 - accuracy: 0.2000 - val_loss: 2.0971 - val_accuracy: 0.2167\n",
      "Epoch 76/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.1386 - accuracy: 0.2014 - val_loss: 2.0948 - val_accuracy: 0.2167\n",
      "Epoch 77/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.1364 - accuracy: 0.2043 - val_loss: 2.0923 - val_accuracy: 0.2200\n",
      "Epoch 78/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.1341 - accuracy: 0.2100 - val_loss: 2.0896 - val_accuracy: 0.2267\n",
      "Epoch 79/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.1317 - accuracy: 0.2029 - val_loss: 2.0871 - val_accuracy: 0.2300\n",
      "Epoch 80/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.1290 - accuracy: 0.2100 - val_loss: 2.0839 - val_accuracy: 0.2233\n",
      "Epoch 81/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.1263 - accuracy: 0.2100 - val_loss: 2.0808 - val_accuracy: 0.2333\n",
      "Epoch 82/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.1236 - accuracy: 0.2129 - val_loss: 2.0776 - val_accuracy: 0.2367\n",
      "Epoch 83/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.1209 - accuracy: 0.2143 - val_loss: 2.0746 - val_accuracy: 0.2433\n",
      "Epoch 84/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.1178 - accuracy: 0.2200 - val_loss: 2.0711 - val_accuracy: 0.2467\n",
      "Epoch 85/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.1147 - accuracy: 0.2271 - val_loss: 2.0678 - val_accuracy: 0.2467\n",
      "Epoch 86/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.1117 - accuracy: 0.2286 - val_loss: 2.0645 - val_accuracy: 0.2500\n",
      "Epoch 87/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.1087 - accuracy: 0.2314 - val_loss: 2.0613 - val_accuracy: 0.2533\n",
      "Epoch 88/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.1055 - accuracy: 0.2314 - val_loss: 2.0578 - val_accuracy: 0.2533\n",
      "Epoch 89/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.1023 - accuracy: 0.2300 - val_loss: 2.0545 - val_accuracy: 0.2567\n",
      "Epoch 90/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.0990 - accuracy: 0.2343 - val_loss: 2.0510 - val_accuracy: 0.2567\n",
      "Epoch 91/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.0959 - accuracy: 0.2329 - val_loss: 2.0473 - val_accuracy: 0.2533\n",
      "Epoch 92/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.0925 - accuracy: 0.2357 - val_loss: 2.0438 - val_accuracy: 0.2667\n",
      "Epoch 93/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.0893 - accuracy: 0.2386 - val_loss: 2.0405 - val_accuracy: 0.2667\n",
      "Epoch 94/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.0860 - accuracy: 0.2400 - val_loss: 2.0369 - val_accuracy: 0.2633\n",
      "Epoch 95/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.0826 - accuracy: 0.2414 - val_loss: 2.0336 - val_accuracy: 0.2700\n",
      "Epoch 96/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.0792 - accuracy: 0.2429 - val_loss: 2.0300 - val_accuracy: 0.2700\n",
      "Epoch 97/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.0760 - accuracy: 0.2429 - val_loss: 2.0269 - val_accuracy: 0.2700\n",
      "Epoch 98/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.0727 - accuracy: 0.2443 - val_loss: 2.0237 - val_accuracy: 0.2667\n",
      "Epoch 99/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.0695 - accuracy: 0.2471 - val_loss: 2.0207 - val_accuracy: 0.2733\n",
      "Epoch 100/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.0663 - accuracy: 0.2500 - val_loss: 2.0171 - val_accuracy: 0.2733\n",
      "Epoch 101/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.0630 - accuracy: 0.2500 - val_loss: 2.0138 - val_accuracy: 0.2733\n",
      "Epoch 102/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.0596 - accuracy: 0.2514 - val_loss: 2.0105 - val_accuracy: 0.2700\n",
      "Epoch 103/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.0562 - accuracy: 0.2514 - val_loss: 2.0071 - val_accuracy: 0.2700\n",
      "Epoch 104/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 2.0530 - accuracy: 0.2514 - val_loss: 2.0037 - val_accuracy: 0.2733\n",
      "Epoch 105/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.0497 - accuracy: 0.2500 - val_loss: 2.0007 - val_accuracy: 0.2733\n",
      "Epoch 106/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.0465 - accuracy: 0.2500 - val_loss: 1.9977 - val_accuracy: 0.2733\n",
      "Epoch 107/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.0432 - accuracy: 0.2529 - val_loss: 1.9946 - val_accuracy: 0.2767\n",
      "Epoch 108/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.0398 - accuracy: 0.2529 - val_loss: 1.9917 - val_accuracy: 0.2767\n",
      "Epoch 109/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.0366 - accuracy: 0.2529 - val_loss: 1.9887 - val_accuracy: 0.2833\n",
      "Epoch 110/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.0334 - accuracy: 0.2543 - val_loss: 1.9857 - val_accuracy: 0.2833\n",
      "Epoch 111/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.0300 - accuracy: 0.2557 - val_loss: 1.9823 - val_accuracy: 0.2800\n",
      "Epoch 112/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.0267 - accuracy: 0.2557 - val_loss: 1.9794 - val_accuracy: 0.2800\n",
      "Epoch 113/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 2.0235 - accuracy: 0.2543 - val_loss: 1.9763 - val_accuracy: 0.2800\n",
      "Epoch 114/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.0201 - accuracy: 0.2557 - val_loss: 1.9732 - val_accuracy: 0.2800\n",
      "Epoch 115/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.0168 - accuracy: 0.2557 - val_loss: 1.9703 - val_accuracy: 0.2800\n",
      "Epoch 116/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.0136 - accuracy: 0.2557 - val_loss: 1.9673 - val_accuracy: 0.2800\n",
      "Epoch 117/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 2.0103 - accuracy: 0.2557 - val_loss: 1.9641 - val_accuracy: 0.2800\n",
      "Epoch 118/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 2.0070 - accuracy: 0.2571 - val_loss: 1.9612 - val_accuracy: 0.2767\n",
      "Epoch 119/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.0038 - accuracy: 0.2600 - val_loss: 1.9579 - val_accuracy: 0.2767\n",
      "Epoch 120/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.0006 - accuracy: 0.2586 - val_loss: 1.9548 - val_accuracy: 0.2767\n",
      "Epoch 121/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.9974 - accuracy: 0.2600 - val_loss: 1.9518 - val_accuracy: 0.2767\n",
      "Epoch 122/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.9942 - accuracy: 0.2586 - val_loss: 1.9490 - val_accuracy: 0.2767\n",
      "Epoch 123/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.9912 - accuracy: 0.2600 - val_loss: 1.9458 - val_accuracy: 0.2767\n",
      "Epoch 124/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.9880 - accuracy: 0.2586 - val_loss: 1.9428 - val_accuracy: 0.2767\n",
      "Epoch 125/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.9848 - accuracy: 0.2586 - val_loss: 1.9399 - val_accuracy: 0.2767\n",
      "Epoch 126/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.9816 - accuracy: 0.2586 - val_loss: 1.9369 - val_accuracy: 0.2767\n",
      "Epoch 127/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.9785 - accuracy: 0.2586 - val_loss: 1.9339 - val_accuracy: 0.2767\n",
      "Epoch 128/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.9754 - accuracy: 0.2571 - val_loss: 1.9310 - val_accuracy: 0.2767\n",
      "Epoch 129/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.9723 - accuracy: 0.2586 - val_loss: 1.9279 - val_accuracy: 0.2767\n",
      "Epoch 130/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.9690 - accuracy: 0.2600 - val_loss: 1.9249 - val_accuracy: 0.2767\n",
      "Epoch 131/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.9660 - accuracy: 0.2600 - val_loss: 1.9218 - val_accuracy: 0.2767\n",
      "Epoch 132/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.9629 - accuracy: 0.2643 - val_loss: 1.9190 - val_accuracy: 0.2767\n",
      "Epoch 133/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.9598 - accuracy: 0.2600 - val_loss: 1.9160 - val_accuracy: 0.2767\n",
      "Epoch 134/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.9566 - accuracy: 0.2600 - val_loss: 1.9134 - val_accuracy: 0.2767\n",
      "Epoch 135/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.9536 - accuracy: 0.2614 - val_loss: 1.9104 - val_accuracy: 0.2767\n",
      "Epoch 136/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.9505 - accuracy: 0.2629 - val_loss: 1.9075 - val_accuracy: 0.2767\n",
      "Epoch 137/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.9475 - accuracy: 0.2600 - val_loss: 1.9048 - val_accuracy: 0.2767\n",
      "Epoch 138/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.9445 - accuracy: 0.2629 - val_loss: 1.9019 - val_accuracy: 0.2800\n",
      "Epoch 139/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.9415 - accuracy: 0.2671 - val_loss: 1.8987 - val_accuracy: 0.2800\n",
      "Epoch 140/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.9384 - accuracy: 0.2629 - val_loss: 1.8960 - val_accuracy: 0.2800\n",
      "Epoch 141/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.9354 - accuracy: 0.2629 - val_loss: 1.8934 - val_accuracy: 0.2800\n",
      "Epoch 142/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.9324 - accuracy: 0.2671 - val_loss: 1.8905 - val_accuracy: 0.2800\n",
      "Epoch 143/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.9294 - accuracy: 0.2643 - val_loss: 1.8879 - val_accuracy: 0.2800\n",
      "Epoch 144/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.9264 - accuracy: 0.2671 - val_loss: 1.8851 - val_accuracy: 0.2800\n",
      "Epoch 145/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.9235 - accuracy: 0.2671 - val_loss: 1.8823 - val_accuracy: 0.2800\n",
      "Epoch 146/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.9206 - accuracy: 0.2657 - val_loss: 1.8796 - val_accuracy: 0.2800\n",
      "Epoch 147/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.9176 - accuracy: 0.2657 - val_loss: 1.8771 - val_accuracy: 0.2800\n",
      "Epoch 148/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.9148 - accuracy: 0.2657 - val_loss: 1.8744 - val_accuracy: 0.2800\n",
      "Epoch 149/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.9118 - accuracy: 0.2643 - val_loss: 1.8718 - val_accuracy: 0.2800\n",
      "Epoch 150/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.9090 - accuracy: 0.2671 - val_loss: 1.8692 - val_accuracy: 0.2800\n",
      "Epoch 151/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.9061 - accuracy: 0.2700 - val_loss: 1.8667 - val_accuracy: 0.2800\n",
      "Epoch 152/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.9032 - accuracy: 0.2671 - val_loss: 1.8640 - val_accuracy: 0.2767\n",
      "Epoch 153/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.9004 - accuracy: 0.2714 - val_loss: 1.8614 - val_accuracy: 0.2767\n",
      "Epoch 154/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.8976 - accuracy: 0.2686 - val_loss: 1.8590 - val_accuracy: 0.2767\n",
      "Epoch 155/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.8948 - accuracy: 0.2686 - val_loss: 1.8565 - val_accuracy: 0.2767\n",
      "Epoch 156/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.8920 - accuracy: 0.2729 - val_loss: 1.8540 - val_accuracy: 0.2767\n",
      "Epoch 157/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.8893 - accuracy: 0.2700 - val_loss: 1.8515 - val_accuracy: 0.2767\n",
      "Epoch 158/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.8866 - accuracy: 0.2700 - val_loss: 1.8491 - val_accuracy: 0.2767\n",
      "Epoch 159/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.8838 - accuracy: 0.2729 - val_loss: 1.8467 - val_accuracy: 0.2767\n",
      "Epoch 160/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.8810 - accuracy: 0.2743 - val_loss: 1.8441 - val_accuracy: 0.2767\n",
      "Epoch 161/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.8784 - accuracy: 0.2714 - val_loss: 1.8418 - val_accuracy: 0.2767\n",
      "Epoch 162/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.8757 - accuracy: 0.2729 - val_loss: 1.8397 - val_accuracy: 0.2767\n",
      "Epoch 163/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.8730 - accuracy: 0.2714 - val_loss: 1.8373 - val_accuracy: 0.2767\n",
      "Epoch 164/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.8704 - accuracy: 0.2729 - val_loss: 1.8350 - val_accuracy: 0.2767\n",
      "Epoch 165/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.8678 - accuracy: 0.2729 - val_loss: 1.8325 - val_accuracy: 0.2767\n",
      "Epoch 166/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.8651 - accuracy: 0.2714 - val_loss: 1.8303 - val_accuracy: 0.2767\n",
      "Epoch 167/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.8626 - accuracy: 0.2729 - val_loss: 1.8282 - val_accuracy: 0.2767\n",
      "Epoch 168/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.8600 - accuracy: 0.2700 - val_loss: 1.8259 - val_accuracy: 0.2767\n",
      "Epoch 169/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.8574 - accuracy: 0.2729 - val_loss: 1.8236 - val_accuracy: 0.2767\n",
      "Epoch 170/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.8549 - accuracy: 0.2743 - val_loss: 1.8211 - val_accuracy: 0.2733\n",
      "Epoch 171/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.8524 - accuracy: 0.2729 - val_loss: 1.8189 - val_accuracy: 0.2733\n",
      "Epoch 172/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.8498 - accuracy: 0.2714 - val_loss: 1.8171 - val_accuracy: 0.2733\n",
      "Epoch 173/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.8474 - accuracy: 0.2786 - val_loss: 1.8149 - val_accuracy: 0.2767\n",
      "Epoch 174/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.8449 - accuracy: 0.2757 - val_loss: 1.8127 - val_accuracy: 0.2733\n",
      "Epoch 175/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.8423 - accuracy: 0.2786 - val_loss: 1.8107 - val_accuracy: 0.2833\n",
      "Epoch 176/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.8398 - accuracy: 0.2771 - val_loss: 1.8086 - val_accuracy: 0.2733\n",
      "Epoch 177/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.8374 - accuracy: 0.2786 - val_loss: 1.8066 - val_accuracy: 0.2733\n",
      "Epoch 178/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.8349 - accuracy: 0.2800 - val_loss: 1.8047 - val_accuracy: 0.2800\n",
      "Epoch 179/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.8326 - accuracy: 0.2786 - val_loss: 1.8025 - val_accuracy: 0.2800\n",
      "Epoch 180/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.8301 - accuracy: 0.2814 - val_loss: 1.8006 - val_accuracy: 0.2833\n",
      "Epoch 181/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.8277 - accuracy: 0.2843 - val_loss: 1.7986 - val_accuracy: 0.2867\n",
      "Epoch 182/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.8253 - accuracy: 0.2829 - val_loss: 1.7964 - val_accuracy: 0.2867\n",
      "Epoch 183/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.8229 - accuracy: 0.2843 - val_loss: 1.7947 - val_accuracy: 0.2867\n",
      "Epoch 184/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.8205 - accuracy: 0.2871 - val_loss: 1.7926 - val_accuracy: 0.2867\n",
      "Epoch 185/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.8182 - accuracy: 0.2871 - val_loss: 1.7904 - val_accuracy: 0.2867\n",
      "Epoch 186/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.8159 - accuracy: 0.2871 - val_loss: 1.7888 - val_accuracy: 0.2867\n",
      "Epoch 187/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.8135 - accuracy: 0.2900 - val_loss: 1.7870 - val_accuracy: 0.2867\n",
      "Epoch 188/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.8112 - accuracy: 0.2900 - val_loss: 1.7848 - val_accuracy: 0.2867\n",
      "Epoch 189/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.8089 - accuracy: 0.2929 - val_loss: 1.7830 - val_accuracy: 0.2867\n",
      "Epoch 190/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.8066 - accuracy: 0.2900 - val_loss: 1.7813 - val_accuracy: 0.2867\n",
      "Epoch 191/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.8043 - accuracy: 0.2900 - val_loss: 1.7795 - val_accuracy: 0.2900\n",
      "Epoch 192/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.8021 - accuracy: 0.2943 - val_loss: 1.7777 - val_accuracy: 0.2900\n",
      "Epoch 193/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7998 - accuracy: 0.2914 - val_loss: 1.7759 - val_accuracy: 0.2967\n",
      "Epoch 194/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7975 - accuracy: 0.3029 - val_loss: 1.7740 - val_accuracy: 0.2967\n",
      "Epoch 195/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.7953 - accuracy: 0.3086 - val_loss: 1.7721 - val_accuracy: 0.2967\n",
      "Epoch 196/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.7931 - accuracy: 0.3071 - val_loss: 1.7703 - val_accuracy: 0.2967\n",
      "Epoch 197/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.7908 - accuracy: 0.3071 - val_loss: 1.7687 - val_accuracy: 0.2967\n",
      "Epoch 198/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7887 - accuracy: 0.3086 - val_loss: 1.7670 - val_accuracy: 0.2967\n",
      "Epoch 199/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.7865 - accuracy: 0.3057 - val_loss: 1.7652 - val_accuracy: 0.2967\n",
      "Epoch 200/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.7844 - accuracy: 0.3057 - val_loss: 1.7635 - val_accuracy: 0.3033\n",
      "Epoch 201/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7822 - accuracy: 0.3114 - val_loss: 1.7615 - val_accuracy: 0.3033\n",
      "Epoch 202/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.7801 - accuracy: 0.3129 - val_loss: 1.7601 - val_accuracy: 0.3067\n",
      "Epoch 203/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.7779 - accuracy: 0.3157 - val_loss: 1.7585 - val_accuracy: 0.3067\n",
      "Epoch 204/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.7758 - accuracy: 0.3129 - val_loss: 1.7568 - val_accuracy: 0.3067\n",
      "Epoch 205/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.7737 - accuracy: 0.3100 - val_loss: 1.7549 - val_accuracy: 0.3100\n",
      "Epoch 206/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.7716 - accuracy: 0.3157 - val_loss: 1.7532 - val_accuracy: 0.3100\n",
      "Epoch 207/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.7695 - accuracy: 0.3171 - val_loss: 1.7517 - val_accuracy: 0.3133\n",
      "Epoch 208/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.7675 - accuracy: 0.3186 - val_loss: 1.7501 - val_accuracy: 0.3100\n",
      "Epoch 209/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.7653 - accuracy: 0.3200 - val_loss: 1.7487 - val_accuracy: 0.3167\n",
      "Epoch 210/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7634 - accuracy: 0.3257 - val_loss: 1.7469 - val_accuracy: 0.3167\n",
      "Epoch 211/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.7613 - accuracy: 0.3257 - val_loss: 1.7455 - val_accuracy: 0.3200\n",
      "Epoch 212/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.7593 - accuracy: 0.3257 - val_loss: 1.7437 - val_accuracy: 0.3200\n",
      "Epoch 213/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.7572 - accuracy: 0.3314 - val_loss: 1.7421 - val_accuracy: 0.3200\n",
      "Epoch 214/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.7552 - accuracy: 0.3300 - val_loss: 1.7406 - val_accuracy: 0.3200\n",
      "Epoch 215/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.7532 - accuracy: 0.3300 - val_loss: 1.7389 - val_accuracy: 0.3167\n",
      "Epoch 216/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.7512 - accuracy: 0.3314 - val_loss: 1.7374 - val_accuracy: 0.3167\n",
      "Epoch 217/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.7492 - accuracy: 0.3357 - val_loss: 1.7359 - val_accuracy: 0.3167\n",
      "Epoch 218/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.7472 - accuracy: 0.3386 - val_loss: 1.7346 - val_accuracy: 0.3167\n",
      "Epoch 219/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.7453 - accuracy: 0.3386 - val_loss: 1.7329 - val_accuracy: 0.3167\n",
      "Epoch 220/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.7432 - accuracy: 0.3443 - val_loss: 1.7310 - val_accuracy: 0.3167\n",
      "Epoch 221/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.7414 - accuracy: 0.3443 - val_loss: 1.7297 - val_accuracy: 0.3167\n",
      "Epoch 222/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.7393 - accuracy: 0.3457 - val_loss: 1.7283 - val_accuracy: 0.3167\n",
      "Epoch 223/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.7375 - accuracy: 0.3529 - val_loss: 1.7266 - val_accuracy: 0.3167\n",
      "Epoch 224/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.7355 - accuracy: 0.3529 - val_loss: 1.7253 - val_accuracy: 0.3167\n",
      "Epoch 225/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.7336 - accuracy: 0.3571 - val_loss: 1.7237 - val_accuracy: 0.3167\n",
      "Epoch 226/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.7318 - accuracy: 0.3529 - val_loss: 1.7221 - val_accuracy: 0.3200\n",
      "Epoch 227/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.7298 - accuracy: 0.3571 - val_loss: 1.7207 - val_accuracy: 0.3200\n",
      "Epoch 228/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.7280 - accuracy: 0.3600 - val_loss: 1.7192 - val_accuracy: 0.3200\n",
      "Epoch 229/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.7261 - accuracy: 0.3557 - val_loss: 1.7179 - val_accuracy: 0.3167\n",
      "Epoch 230/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7243 - accuracy: 0.3586 - val_loss: 1.7166 - val_accuracy: 0.3167\n",
      "Epoch 231/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7224 - accuracy: 0.3586 - val_loss: 1.7152 - val_accuracy: 0.3167\n",
      "Epoch 232/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.7205 - accuracy: 0.3643 - val_loss: 1.7138 - val_accuracy: 0.3167\n",
      "Epoch 233/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.7187 - accuracy: 0.3657 - val_loss: 1.7122 - val_accuracy: 0.3167\n",
      "Epoch 234/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.7168 - accuracy: 0.3643 - val_loss: 1.7109 - val_accuracy: 0.3200\n",
      "Epoch 235/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7150 - accuracy: 0.3671 - val_loss: 1.7094 - val_accuracy: 0.3233\n",
      "Epoch 236/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.7132 - accuracy: 0.3643 - val_loss: 1.7080 - val_accuracy: 0.3267\n",
      "Epoch 237/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7114 - accuracy: 0.3629 - val_loss: 1.7066 - val_accuracy: 0.3300\n",
      "Epoch 238/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.7096 - accuracy: 0.3657 - val_loss: 1.7052 - val_accuracy: 0.3300\n",
      "Epoch 239/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7078 - accuracy: 0.3671 - val_loss: 1.7038 - val_accuracy: 0.3267\n",
      "Epoch 240/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.7060 - accuracy: 0.3671 - val_loss: 1.7027 - val_accuracy: 0.3233\n",
      "Epoch 241/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7041 - accuracy: 0.3686 - val_loss: 1.7012 - val_accuracy: 0.3300\n",
      "Epoch 242/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7024 - accuracy: 0.3743 - val_loss: 1.7001 - val_accuracy: 0.3300\n",
      "Epoch 243/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.7007 - accuracy: 0.3743 - val_loss: 1.6987 - val_accuracy: 0.3300\n",
      "Epoch 244/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6989 - accuracy: 0.3771 - val_loss: 1.6974 - val_accuracy: 0.3333\n",
      "Epoch 245/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.6971 - accuracy: 0.3800 - val_loss: 1.6960 - val_accuracy: 0.3333\n",
      "Epoch 246/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.6954 - accuracy: 0.3743 - val_loss: 1.6946 - val_accuracy: 0.3300\n",
      "Epoch 247/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.6937 - accuracy: 0.3757 - val_loss: 1.6932 - val_accuracy: 0.3333\n",
      "Epoch 248/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6919 - accuracy: 0.3829 - val_loss: 1.6920 - val_accuracy: 0.3300\n",
      "Epoch 249/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.6903 - accuracy: 0.3729 - val_loss: 1.6907 - val_accuracy: 0.3300\n",
      "Epoch 250/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.6886 - accuracy: 0.3800 - val_loss: 1.6895 - val_accuracy: 0.3300\n",
      "Epoch 251/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.6868 - accuracy: 0.3800 - val_loss: 1.6883 - val_accuracy: 0.3267\n",
      "Epoch 252/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.6852 - accuracy: 0.3814 - val_loss: 1.6869 - val_accuracy: 0.3267\n",
      "Epoch 253/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6835 - accuracy: 0.3757 - val_loss: 1.6855 - val_accuracy: 0.3367\n",
      "Epoch 254/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6819 - accuracy: 0.3771 - val_loss: 1.6841 - val_accuracy: 0.3433\n",
      "Epoch 255/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6801 - accuracy: 0.3814 - val_loss: 1.6829 - val_accuracy: 0.3433\n",
      "Epoch 256/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6785 - accuracy: 0.3829 - val_loss: 1.6817 - val_accuracy: 0.3433\n",
      "Epoch 257/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6769 - accuracy: 0.3829 - val_loss: 1.6803 - val_accuracy: 0.3400\n",
      "Epoch 258/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6752 - accuracy: 0.3814 - val_loss: 1.6791 - val_accuracy: 0.3400\n",
      "Epoch 259/3000\n",
      "700/700 [==============================] - 0s 87us/sample - loss: 1.6736 - accuracy: 0.3814 - val_loss: 1.6780 - val_accuracy: 0.3400\n",
      "Epoch 260/3000\n",
      "700/700 [==============================] - 0s 89us/sample - loss: 1.6719 - accuracy: 0.3786 - val_loss: 1.6767 - val_accuracy: 0.3467\n",
      "Epoch 261/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.6703 - accuracy: 0.3829 - val_loss: 1.6754 - val_accuracy: 0.3467\n",
      "Epoch 262/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.6687 - accuracy: 0.3814 - val_loss: 1.6740 - val_accuracy: 0.3467\n",
      "Epoch 263/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.6671 - accuracy: 0.3786 - val_loss: 1.6727 - val_accuracy: 0.3467\n",
      "Epoch 264/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6655 - accuracy: 0.3843 - val_loss: 1.6715 - val_accuracy: 0.3467\n",
      "Epoch 265/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.6638 - accuracy: 0.3829 - val_loss: 1.6703 - val_accuracy: 0.3467\n",
      "Epoch 266/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6623 - accuracy: 0.3786 - val_loss: 1.6689 - val_accuracy: 0.3467\n",
      "Epoch 267/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6608 - accuracy: 0.3829 - val_loss: 1.6681 - val_accuracy: 0.3467\n",
      "Epoch 268/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6591 - accuracy: 0.3814 - val_loss: 1.6668 - val_accuracy: 0.3467\n",
      "Epoch 269/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6576 - accuracy: 0.3800 - val_loss: 1.6657 - val_accuracy: 0.3467\n",
      "Epoch 270/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6560 - accuracy: 0.3814 - val_loss: 1.6645 - val_accuracy: 0.3500\n",
      "Epoch 271/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6545 - accuracy: 0.3829 - val_loss: 1.6633 - val_accuracy: 0.3533\n",
      "Epoch 272/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.6529 - accuracy: 0.3857 - val_loss: 1.6619 - val_accuracy: 0.3533\n",
      "Epoch 273/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6514 - accuracy: 0.3857 - val_loss: 1.6608 - val_accuracy: 0.3533\n",
      "Epoch 274/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6498 - accuracy: 0.3814 - val_loss: 1.6598 - val_accuracy: 0.3533\n",
      "Epoch 275/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6483 - accuracy: 0.3871 - val_loss: 1.6587 - val_accuracy: 0.3533\n",
      "Epoch 276/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6467 - accuracy: 0.3843 - val_loss: 1.6578 - val_accuracy: 0.3533\n",
      "Epoch 277/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6453 - accuracy: 0.3886 - val_loss: 1.6562 - val_accuracy: 0.3533\n",
      "Epoch 278/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6437 - accuracy: 0.3886 - val_loss: 1.6549 - val_accuracy: 0.3533\n",
      "Epoch 279/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6423 - accuracy: 0.3943 - val_loss: 1.6538 - val_accuracy: 0.3533\n",
      "Epoch 280/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6408 - accuracy: 0.3900 - val_loss: 1.6526 - val_accuracy: 0.3533\n",
      "Epoch 281/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.6393 - accuracy: 0.3929 - val_loss: 1.6514 - val_accuracy: 0.3533\n",
      "Epoch 282/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6377 - accuracy: 0.3971 - val_loss: 1.6506 - val_accuracy: 0.3533\n",
      "Epoch 283/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.6363 - accuracy: 0.3943 - val_loss: 1.6494 - val_accuracy: 0.3533\n",
      "Epoch 284/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6348 - accuracy: 0.3957 - val_loss: 1.6486 - val_accuracy: 0.3500\n",
      "Epoch 285/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.6333 - accuracy: 0.3957 - val_loss: 1.6473 - val_accuracy: 0.3533\n",
      "Epoch 286/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.6319 - accuracy: 0.3986 - val_loss: 1.6461 - val_accuracy: 0.3533\n",
      "Epoch 287/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.6304 - accuracy: 0.3986 - val_loss: 1.6450 - val_accuracy: 0.3533\n",
      "Epoch 288/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6290 - accuracy: 0.4000 - val_loss: 1.6440 - val_accuracy: 0.3533\n",
      "Epoch 289/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6275 - accuracy: 0.4000 - val_loss: 1.6430 - val_accuracy: 0.3533\n",
      "Epoch 290/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6260 - accuracy: 0.3986 - val_loss: 1.6420 - val_accuracy: 0.3533\n",
      "Epoch 291/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.6247 - accuracy: 0.4000 - val_loss: 1.6411 - val_accuracy: 0.3567\n",
      "Epoch 292/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.6232 - accuracy: 0.4000 - val_loss: 1.6399 - val_accuracy: 0.3567\n",
      "Epoch 293/3000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 1.6218 - accuracy: 0.4057 - val_loss: 1.6385 - val_accuracy: 0.3533\n",
      "Epoch 294/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.6203 - accuracy: 0.4057 - val_loss: 1.6375 - val_accuracy: 0.3567\n",
      "Epoch 295/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6189 - accuracy: 0.4071 - val_loss: 1.6364 - val_accuracy: 0.3600\n",
      "Epoch 296/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.6176 - accuracy: 0.4071 - val_loss: 1.6354 - val_accuracy: 0.3600\n",
      "Epoch 297/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.6162 - accuracy: 0.4100 - val_loss: 1.6343 - val_accuracy: 0.3633\n",
      "Epoch 298/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.6148 - accuracy: 0.4100 - val_loss: 1.6333 - val_accuracy: 0.3633\n",
      "Epoch 299/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.6134 - accuracy: 0.4114 - val_loss: 1.6323 - val_accuracy: 0.3633\n",
      "Epoch 300/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6120 - accuracy: 0.4100 - val_loss: 1.6312 - val_accuracy: 0.3633\n",
      "Epoch 301/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6107 - accuracy: 0.4129 - val_loss: 1.6303 - val_accuracy: 0.3633\n",
      "Epoch 302/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.6093 - accuracy: 0.4114 - val_loss: 1.6294 - val_accuracy: 0.3633\n",
      "Epoch 303/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6079 - accuracy: 0.4100 - val_loss: 1.6281 - val_accuracy: 0.3667\n",
      "Epoch 304/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6065 - accuracy: 0.4114 - val_loss: 1.6271 - val_accuracy: 0.3667\n",
      "Epoch 305/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6052 - accuracy: 0.4129 - val_loss: 1.6262 - val_accuracy: 0.3733\n",
      "Epoch 306/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.6038 - accuracy: 0.4129 - val_loss: 1.6252 - val_accuracy: 0.3733\n",
      "Epoch 307/3000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 1.6025 - accuracy: 0.4157 - val_loss: 1.6243 - val_accuracy: 0.3767\n",
      "Epoch 308/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6011 - accuracy: 0.4143 - val_loss: 1.6235 - val_accuracy: 0.3767\n",
      "Epoch 309/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5997 - accuracy: 0.4143 - val_loss: 1.6220 - val_accuracy: 0.3767\n",
      "Epoch 310/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.5985 - accuracy: 0.4143 - val_loss: 1.6211 - val_accuracy: 0.3767\n",
      "Epoch 311/3000\n",
      "700/700 [==============================] - 0s 85us/sample - loss: 1.5972 - accuracy: 0.4171 - val_loss: 1.6203 - val_accuracy: 0.3800\n",
      "Epoch 312/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.5959 - accuracy: 0.4186 - val_loss: 1.6195 - val_accuracy: 0.3800\n",
      "Epoch 313/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.5945 - accuracy: 0.4171 - val_loss: 1.6185 - val_accuracy: 0.3800\n",
      "Epoch 314/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.5932 - accuracy: 0.4157 - val_loss: 1.6174 - val_accuracy: 0.3800\n",
      "Epoch 315/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.5919 - accuracy: 0.4186 - val_loss: 1.6166 - val_accuracy: 0.3800\n",
      "Epoch 316/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5906 - accuracy: 0.4200 - val_loss: 1.6153 - val_accuracy: 0.3800\n",
      "Epoch 317/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.5893 - accuracy: 0.4214 - val_loss: 1.6147 - val_accuracy: 0.3833\n",
      "Epoch 318/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5880 - accuracy: 0.4186 - val_loss: 1.6136 - val_accuracy: 0.3800\n",
      "Epoch 319/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5867 - accuracy: 0.4186 - val_loss: 1.6128 - val_accuracy: 0.3800\n",
      "Epoch 320/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5854 - accuracy: 0.4214 - val_loss: 1.6118 - val_accuracy: 0.3800\n",
      "Epoch 321/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5842 - accuracy: 0.4200 - val_loss: 1.6108 - val_accuracy: 0.3833\n",
      "Epoch 322/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5829 - accuracy: 0.4200 - val_loss: 1.6100 - val_accuracy: 0.3833\n",
      "Epoch 323/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5816 - accuracy: 0.4200 - val_loss: 1.6089 - val_accuracy: 0.3833\n",
      "Epoch 324/3000\n",
      "700/700 [==============================] - 0s 87us/sample - loss: 1.5803 - accuracy: 0.4186 - val_loss: 1.6084 - val_accuracy: 0.3833\n",
      "Epoch 325/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.5791 - accuracy: 0.4243 - val_loss: 1.6072 - val_accuracy: 0.3833\n",
      "Epoch 326/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.5779 - accuracy: 0.4271 - val_loss: 1.6065 - val_accuracy: 0.3833\n",
      "Epoch 327/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5766 - accuracy: 0.4200 - val_loss: 1.6058 - val_accuracy: 0.3833\n",
      "Epoch 328/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5754 - accuracy: 0.4286 - val_loss: 1.6045 - val_accuracy: 0.3833\n",
      "Epoch 329/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5741 - accuracy: 0.4286 - val_loss: 1.6035 - val_accuracy: 0.3833\n",
      "Epoch 330/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5728 - accuracy: 0.4243 - val_loss: 1.6025 - val_accuracy: 0.3867\n",
      "Epoch 331/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5716 - accuracy: 0.4271 - val_loss: 1.6017 - val_accuracy: 0.3867\n",
      "Epoch 332/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5704 - accuracy: 0.4257 - val_loss: 1.6009 - val_accuracy: 0.3867\n",
      "Epoch 333/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.5692 - accuracy: 0.4271 - val_loss: 1.5997 - val_accuracy: 0.3867\n",
      "Epoch 334/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5680 - accuracy: 0.4300 - val_loss: 1.5989 - val_accuracy: 0.3867\n",
      "Epoch 335/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5668 - accuracy: 0.4300 - val_loss: 1.5982 - val_accuracy: 0.3867\n",
      "Epoch 336/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5656 - accuracy: 0.4271 - val_loss: 1.5972 - val_accuracy: 0.3867\n",
      "Epoch 337/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5643 - accuracy: 0.4314 - val_loss: 1.5963 - val_accuracy: 0.3867\n",
      "Epoch 338/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5631 - accuracy: 0.4286 - val_loss: 1.5958 - val_accuracy: 0.3867\n",
      "Epoch 339/3000\n",
      "700/700 [==============================] - 0s 113us/sample - loss: 1.5620 - accuracy: 0.4300 - val_loss: 1.5948 - val_accuracy: 0.3867\n",
      "Epoch 340/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.5608 - accuracy: 0.4329 - val_loss: 1.5936 - val_accuracy: 0.3867\n",
      "Epoch 341/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.5596 - accuracy: 0.4314 - val_loss: 1.5927 - val_accuracy: 0.3833\n",
      "Epoch 342/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5584 - accuracy: 0.4314 - val_loss: 1.5919 - val_accuracy: 0.3800\n",
      "Epoch 343/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5572 - accuracy: 0.4314 - val_loss: 1.5909 - val_accuracy: 0.3867\n",
      "Epoch 344/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.5561 - accuracy: 0.4329 - val_loss: 1.5901 - val_accuracy: 0.3833\n",
      "Epoch 345/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5550 - accuracy: 0.4343 - val_loss: 1.5895 - val_accuracy: 0.3767\n",
      "Epoch 346/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5537 - accuracy: 0.4343 - val_loss: 1.5889 - val_accuracy: 0.3767\n",
      "Epoch 347/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5526 - accuracy: 0.4329 - val_loss: 1.5879 - val_accuracy: 0.3800\n",
      "Epoch 348/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.5515 - accuracy: 0.4357 - val_loss: 1.5870 - val_accuracy: 0.3800\n",
      "Epoch 349/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.5503 - accuracy: 0.4357 - val_loss: 1.5860 - val_accuracy: 0.3800\n",
      "Epoch 350/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.5492 - accuracy: 0.4329 - val_loss: 1.5851 - val_accuracy: 0.3800\n",
      "Epoch 351/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5480 - accuracy: 0.4371 - val_loss: 1.5843 - val_accuracy: 0.3800\n",
      "Epoch 352/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5469 - accuracy: 0.4371 - val_loss: 1.5835 - val_accuracy: 0.3800\n",
      "Epoch 353/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5458 - accuracy: 0.4357 - val_loss: 1.5825 - val_accuracy: 0.3800\n",
      "Epoch 354/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.5445 - accuracy: 0.4357 - val_loss: 1.5812 - val_accuracy: 0.3800\n",
      "Epoch 355/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.5434 - accuracy: 0.4386 - val_loss: 1.5810 - val_accuracy: 0.3800\n",
      "Epoch 356/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.5423 - accuracy: 0.4386 - val_loss: 1.5801 - val_accuracy: 0.3800\n",
      "Epoch 357/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.5412 - accuracy: 0.4386 - val_loss: 1.5792 - val_accuracy: 0.3800\n",
      "Epoch 358/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5401 - accuracy: 0.4400 - val_loss: 1.5785 - val_accuracy: 0.3800\n",
      "Epoch 359/3000\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 1.5390 - accuracy: 0.4386 - val_loss: 1.5776 - val_accuracy: 0.3900\n",
      "Epoch 360/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.5378 - accuracy: 0.4429 - val_loss: 1.5766 - val_accuracy: 0.3900\n",
      "Epoch 361/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5368 - accuracy: 0.4400 - val_loss: 1.5762 - val_accuracy: 0.3900\n",
      "Epoch 362/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.5357 - accuracy: 0.4414 - val_loss: 1.5753 - val_accuracy: 0.3900\n",
      "Epoch 363/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.5345 - accuracy: 0.4414 - val_loss: 1.5742 - val_accuracy: 0.3933\n",
      "Epoch 364/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5335 - accuracy: 0.4429 - val_loss: 1.5733 - val_accuracy: 0.3933\n",
      "Epoch 365/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5324 - accuracy: 0.4414 - val_loss: 1.5725 - val_accuracy: 0.3967\n",
      "Epoch 366/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5313 - accuracy: 0.4414 - val_loss: 1.5717 - val_accuracy: 0.3967\n",
      "Epoch 367/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5302 - accuracy: 0.4400 - val_loss: 1.5709 - val_accuracy: 0.3967\n",
      "Epoch 368/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.5292 - accuracy: 0.4400 - val_loss: 1.5703 - val_accuracy: 0.3967\n",
      "Epoch 369/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.5281 - accuracy: 0.4443 - val_loss: 1.5694 - val_accuracy: 0.3967\n",
      "Epoch 370/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.5270 - accuracy: 0.4386 - val_loss: 1.5688 - val_accuracy: 0.3967\n",
      "Epoch 371/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5259 - accuracy: 0.4400 - val_loss: 1.5676 - val_accuracy: 0.3967\n",
      "Epoch 372/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5249 - accuracy: 0.4400 - val_loss: 1.5668 - val_accuracy: 0.3967\n",
      "Epoch 373/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.5239 - accuracy: 0.4386 - val_loss: 1.5661 - val_accuracy: 0.3967\n",
      "Epoch 374/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5228 - accuracy: 0.4386 - val_loss: 1.5655 - val_accuracy: 0.3967\n",
      "Epoch 375/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5217 - accuracy: 0.4457 - val_loss: 1.5648 - val_accuracy: 0.4000\n",
      "Epoch 376/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5208 - accuracy: 0.4414 - val_loss: 1.5643 - val_accuracy: 0.4000\n",
      "Epoch 377/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.5196 - accuracy: 0.4400 - val_loss: 1.5635 - val_accuracy: 0.4000\n",
      "Epoch 378/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.5188 - accuracy: 0.4400 - val_loss: 1.5626 - val_accuracy: 0.4000\n",
      "Epoch 379/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.5176 - accuracy: 0.4429 - val_loss: 1.5618 - val_accuracy: 0.4000\n",
      "Epoch 380/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.5166 - accuracy: 0.4443 - val_loss: 1.5609 - val_accuracy: 0.4000\n",
      "Epoch 381/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5155 - accuracy: 0.4429 - val_loss: 1.5602 - val_accuracy: 0.4000\n",
      "Epoch 382/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5146 - accuracy: 0.4443 - val_loss: 1.5592 - val_accuracy: 0.4000\n",
      "Epoch 383/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.5135 - accuracy: 0.4457 - val_loss: 1.5586 - val_accuracy: 0.4000\n",
      "Epoch 384/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5125 - accuracy: 0.4457 - val_loss: 1.5577 - val_accuracy: 0.4000\n",
      "Epoch 385/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5115 - accuracy: 0.4443 - val_loss: 1.5569 - val_accuracy: 0.4000\n",
      "Epoch 386/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5105 - accuracy: 0.4457 - val_loss: 1.5560 - val_accuracy: 0.4000\n",
      "Epoch 387/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5095 - accuracy: 0.4443 - val_loss: 1.5554 - val_accuracy: 0.4000\n",
      "Epoch 388/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5085 - accuracy: 0.4457 - val_loss: 1.5550 - val_accuracy: 0.4000\n",
      "Epoch 389/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5075 - accuracy: 0.4443 - val_loss: 1.5540 - val_accuracy: 0.4000\n",
      "Epoch 390/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5064 - accuracy: 0.4486 - val_loss: 1.5534 - val_accuracy: 0.4033\n",
      "Epoch 391/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5055 - accuracy: 0.4457 - val_loss: 1.5526 - val_accuracy: 0.4000\n",
      "Epoch 392/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5045 - accuracy: 0.4500 - val_loss: 1.5519 - val_accuracy: 0.4000\n",
      "Epoch 393/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5035 - accuracy: 0.4471 - val_loss: 1.5513 - val_accuracy: 0.4033\n",
      "Epoch 394/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5026 - accuracy: 0.4486 - val_loss: 1.5508 - val_accuracy: 0.4033\n",
      "Epoch 395/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5015 - accuracy: 0.4486 - val_loss: 1.5501 - val_accuracy: 0.4033\n",
      "Epoch 396/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5007 - accuracy: 0.4500 - val_loss: 1.5490 - val_accuracy: 0.4033\n",
      "Epoch 397/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4996 - accuracy: 0.4529 - val_loss: 1.5484 - val_accuracy: 0.4033\n",
      "Epoch 398/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4986 - accuracy: 0.4529 - val_loss: 1.5476 - val_accuracy: 0.4033\n",
      "Epoch 399/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.4977 - accuracy: 0.4500 - val_loss: 1.5467 - val_accuracy: 0.4033\n",
      "Epoch 400/3000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 1.4968 - accuracy: 0.4486 - val_loss: 1.5461 - val_accuracy: 0.4033\n",
      "Epoch 401/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.4958 - accuracy: 0.4529 - val_loss: 1.5454 - val_accuracy: 0.4033\n",
      "Epoch 402/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4948 - accuracy: 0.4514 - val_loss: 1.5445 - val_accuracy: 0.4033\n",
      "Epoch 403/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4938 - accuracy: 0.4543 - val_loss: 1.5437 - val_accuracy: 0.4033\n",
      "Epoch 404/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.4929 - accuracy: 0.4514 - val_loss: 1.5427 - val_accuracy: 0.4033\n",
      "Epoch 405/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4921 - accuracy: 0.4529 - val_loss: 1.5423 - val_accuracy: 0.4033\n",
      "Epoch 406/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4910 - accuracy: 0.4529 - val_loss: 1.5419 - val_accuracy: 0.4033\n",
      "Epoch 407/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4902 - accuracy: 0.4529 - val_loss: 1.5414 - val_accuracy: 0.4033\n",
      "Epoch 408/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4892 - accuracy: 0.4529 - val_loss: 1.5404 - val_accuracy: 0.4033\n",
      "Epoch 409/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.4883 - accuracy: 0.4543 - val_loss: 1.5397 - val_accuracy: 0.4033\n",
      "Epoch 410/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.4875 - accuracy: 0.4514 - val_loss: 1.5390 - val_accuracy: 0.4033\n",
      "Epoch 411/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.4866 - accuracy: 0.4543 - val_loss: 1.5384 - val_accuracy: 0.4033\n",
      "Epoch 412/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4855 - accuracy: 0.4543 - val_loss: 1.5377 - val_accuracy: 0.4033\n",
      "Epoch 413/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4846 - accuracy: 0.4543 - val_loss: 1.5368 - val_accuracy: 0.4033\n",
      "Epoch 414/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4837 - accuracy: 0.4529 - val_loss: 1.5361 - val_accuracy: 0.4067\n",
      "Epoch 415/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4828 - accuracy: 0.4543 - val_loss: 1.5357 - val_accuracy: 0.4033\n",
      "Epoch 416/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4819 - accuracy: 0.4543 - val_loss: 1.5352 - val_accuracy: 0.4033\n",
      "Epoch 417/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4810 - accuracy: 0.4529 - val_loss: 1.5346 - val_accuracy: 0.4033\n",
      "Epoch 418/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4802 - accuracy: 0.4557 - val_loss: 1.5338 - val_accuracy: 0.4033\n",
      "Epoch 419/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.4793 - accuracy: 0.4571 - val_loss: 1.5331 - val_accuracy: 0.4067\n",
      "Epoch 420/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4784 - accuracy: 0.4571 - val_loss: 1.5326 - val_accuracy: 0.4033\n",
      "Epoch 421/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4775 - accuracy: 0.4557 - val_loss: 1.5318 - val_accuracy: 0.4033\n",
      "Epoch 422/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.4766 - accuracy: 0.4586 - val_loss: 1.5312 - val_accuracy: 0.4033\n",
      "Epoch 423/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4758 - accuracy: 0.4586 - val_loss: 1.5303 - val_accuracy: 0.4067\n",
      "Epoch 424/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4748 - accuracy: 0.4543 - val_loss: 1.5295 - val_accuracy: 0.4067\n",
      "Epoch 425/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.4740 - accuracy: 0.4586 - val_loss: 1.5290 - val_accuracy: 0.4067\n",
      "Epoch 426/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.4731 - accuracy: 0.4543 - val_loss: 1.5286 - val_accuracy: 0.4033\n",
      "Epoch 427/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4723 - accuracy: 0.4571 - val_loss: 1.5280 - val_accuracy: 0.4033\n",
      "Epoch 428/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4714 - accuracy: 0.4557 - val_loss: 1.5274 - val_accuracy: 0.4033\n",
      "Epoch 429/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.4705 - accuracy: 0.4543 - val_loss: 1.5263 - val_accuracy: 0.4067\n",
      "Epoch 430/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4697 - accuracy: 0.4557 - val_loss: 1.5258 - val_accuracy: 0.4033\n",
      "Epoch 431/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4689 - accuracy: 0.4543 - val_loss: 1.5249 - val_accuracy: 0.4033\n",
      "Epoch 432/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4680 - accuracy: 0.4571 - val_loss: 1.5245 - val_accuracy: 0.4033\n",
      "Epoch 433/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4672 - accuracy: 0.4586 - val_loss: 1.5242 - val_accuracy: 0.4033\n",
      "Epoch 434/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4663 - accuracy: 0.4571 - val_loss: 1.5233 - val_accuracy: 0.4033\n",
      "Epoch 435/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4655 - accuracy: 0.4557 - val_loss: 1.5230 - val_accuracy: 0.4033\n",
      "Epoch 436/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4647 - accuracy: 0.4586 - val_loss: 1.5223 - val_accuracy: 0.4033\n",
      "Epoch 437/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4638 - accuracy: 0.4557 - val_loss: 1.5216 - val_accuracy: 0.4033\n",
      "Epoch 438/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4630 - accuracy: 0.4571 - val_loss: 1.5209 - val_accuracy: 0.4033\n",
      "Epoch 439/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4622 - accuracy: 0.4571 - val_loss: 1.5203 - val_accuracy: 0.4033\n",
      "Epoch 440/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.4613 - accuracy: 0.4586 - val_loss: 1.5194 - val_accuracy: 0.4000\n",
      "Epoch 441/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4605 - accuracy: 0.4586 - val_loss: 1.5187 - val_accuracy: 0.4000\n",
      "Epoch 442/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.4597 - accuracy: 0.4571 - val_loss: 1.5181 - val_accuracy: 0.4000\n",
      "Epoch 443/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4588 - accuracy: 0.4571 - val_loss: 1.5173 - val_accuracy: 0.4000\n",
      "Epoch 444/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4581 - accuracy: 0.4571 - val_loss: 1.5166 - val_accuracy: 0.4000\n",
      "Epoch 445/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.4572 - accuracy: 0.4586 - val_loss: 1.5163 - val_accuracy: 0.4000\n",
      "Epoch 446/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.4564 - accuracy: 0.4586 - val_loss: 1.5159 - val_accuracy: 0.4000\n",
      "Epoch 447/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.4556 - accuracy: 0.4586 - val_loss: 1.5152 - val_accuracy: 0.4033\n",
      "Epoch 448/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.4547 - accuracy: 0.4586 - val_loss: 1.5146 - val_accuracy: 0.4067\n",
      "Epoch 449/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4540 - accuracy: 0.4614 - val_loss: 1.5141 - val_accuracy: 0.4067\n",
      "Epoch 450/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4532 - accuracy: 0.4586 - val_loss: 1.5129 - val_accuracy: 0.4000\n",
      "Epoch 451/3000\n",
      "700/700 [==============================] - 0s 90us/sample - loss: 1.4524 - accuracy: 0.4571 - val_loss: 1.5125 - val_accuracy: 0.4033\n",
      "Epoch 452/3000\n",
      "700/700 [==============================] - 0s 117us/sample - loss: 1.4516 - accuracy: 0.4629 - val_loss: 1.5118 - val_accuracy: 0.4033\n",
      "Epoch 453/3000\n",
      "700/700 [==============================] - 0s 98us/sample - loss: 1.4507 - accuracy: 0.4600 - val_loss: 1.5113 - val_accuracy: 0.4067\n",
      "Epoch 454/3000\n",
      "700/700 [==============================] - 0s 89us/sample - loss: 1.4500 - accuracy: 0.4600 - val_loss: 1.5107 - val_accuracy: 0.4067\n",
      "Epoch 455/3000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 1.4492 - accuracy: 0.4600 - val_loss: 1.5103 - val_accuracy: 0.4067\n",
      "Epoch 456/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.4484 - accuracy: 0.4614 - val_loss: 1.5098 - val_accuracy: 0.4067\n",
      "Epoch 457/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4476 - accuracy: 0.4643 - val_loss: 1.5092 - val_accuracy: 0.4067\n",
      "Epoch 458/3000\n",
      "700/700 [==============================] - 0s 88us/sample - loss: 1.4468 - accuracy: 0.4643 - val_loss: 1.5084 - val_accuracy: 0.4067\n",
      "Epoch 459/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.4460 - accuracy: 0.4643 - val_loss: 1.5078 - val_accuracy: 0.4067\n",
      "Epoch 460/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4452 - accuracy: 0.4629 - val_loss: 1.5071 - val_accuracy: 0.4067\n",
      "Epoch 461/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4444 - accuracy: 0.4629 - val_loss: 1.5067 - val_accuracy: 0.4067\n",
      "Epoch 462/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.4437 - accuracy: 0.4600 - val_loss: 1.5060 - val_accuracy: 0.4067\n",
      "Epoch 463/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.4429 - accuracy: 0.4629 - val_loss: 1.5054 - val_accuracy: 0.4067\n",
      "Epoch 464/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.4421 - accuracy: 0.4614 - val_loss: 1.5046 - val_accuracy: 0.4067\n",
      "Epoch 465/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.4413 - accuracy: 0.4629 - val_loss: 1.5041 - val_accuracy: 0.4067\n",
      "Epoch 466/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.4405 - accuracy: 0.4714 - val_loss: 1.5037 - val_accuracy: 0.4067\n",
      "Epoch 467/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4398 - accuracy: 0.4671 - val_loss: 1.5031 - val_accuracy: 0.4067\n",
      "Epoch 468/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4389 - accuracy: 0.4629 - val_loss: 1.5021 - val_accuracy: 0.4067\n",
      "Epoch 469/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4381 - accuracy: 0.4643 - val_loss: 1.5015 - val_accuracy: 0.4033\n",
      "Epoch 470/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.4373 - accuracy: 0.4643 - val_loss: 1.5011 - val_accuracy: 0.4033\n",
      "Epoch 471/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4366 - accuracy: 0.4714 - val_loss: 1.5007 - val_accuracy: 0.4067\n",
      "Epoch 472/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.4357 - accuracy: 0.4671 - val_loss: 1.5000 - val_accuracy: 0.4100\n",
      "Epoch 473/3000\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 1.4349 - accuracy: 0.4657 - val_loss: 1.4992 - val_accuracy: 0.4067\n",
      "Epoch 474/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.4342 - accuracy: 0.4700 - val_loss: 1.4985 - val_accuracy: 0.4067\n",
      "Epoch 475/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4334 - accuracy: 0.4714 - val_loss: 1.4978 - val_accuracy: 0.4100\n",
      "Epoch 476/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4327 - accuracy: 0.4700 - val_loss: 1.4977 - val_accuracy: 0.4100\n",
      "Epoch 477/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.4318 - accuracy: 0.4686 - val_loss: 1.4970 - val_accuracy: 0.4100\n",
      "Epoch 478/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4310 - accuracy: 0.4657 - val_loss: 1.4963 - val_accuracy: 0.4100\n",
      "Epoch 479/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4303 - accuracy: 0.4686 - val_loss: 1.4958 - val_accuracy: 0.4100\n",
      "Epoch 480/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4295 - accuracy: 0.4743 - val_loss: 1.4948 - val_accuracy: 0.4100\n",
      "Epoch 481/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4287 - accuracy: 0.4700 - val_loss: 1.4940 - val_accuracy: 0.4100\n",
      "Epoch 482/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4279 - accuracy: 0.4743 - val_loss: 1.4934 - val_accuracy: 0.4100\n",
      "Epoch 483/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4271 - accuracy: 0.4714 - val_loss: 1.4929 - val_accuracy: 0.4100\n",
      "Epoch 484/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4265 - accuracy: 0.4729 - val_loss: 1.4925 - val_accuracy: 0.4100\n",
      "Epoch 485/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4255 - accuracy: 0.4743 - val_loss: 1.4918 - val_accuracy: 0.4100\n",
      "Epoch 486/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.4248 - accuracy: 0.4771 - val_loss: 1.4911 - val_accuracy: 0.4100\n",
      "Epoch 487/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4239 - accuracy: 0.4729 - val_loss: 1.4902 - val_accuracy: 0.4100\n",
      "Epoch 488/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4232 - accuracy: 0.4757 - val_loss: 1.4897 - val_accuracy: 0.4133\n",
      "Epoch 489/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4225 - accuracy: 0.4800 - val_loss: 1.4892 - val_accuracy: 0.4133\n",
      "Epoch 490/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4216 - accuracy: 0.4757 - val_loss: 1.4888 - val_accuracy: 0.4100\n",
      "Epoch 491/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4209 - accuracy: 0.4757 - val_loss: 1.4880 - val_accuracy: 0.4133\n",
      "Epoch 492/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.4201 - accuracy: 0.4757 - val_loss: 1.4873 - val_accuracy: 0.4133\n",
      "Epoch 493/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.4194 - accuracy: 0.4771 - val_loss: 1.4872 - val_accuracy: 0.4133\n",
      "Epoch 494/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.4186 - accuracy: 0.4771 - val_loss: 1.4869 - val_accuracy: 0.4133\n",
      "Epoch 495/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4178 - accuracy: 0.4771 - val_loss: 1.4859 - val_accuracy: 0.4133\n",
      "Epoch 496/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4171 - accuracy: 0.4786 - val_loss: 1.4856 - val_accuracy: 0.4133\n",
      "Epoch 497/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4164 - accuracy: 0.4757 - val_loss: 1.4848 - val_accuracy: 0.4133\n",
      "Epoch 498/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.4156 - accuracy: 0.4786 - val_loss: 1.4844 - val_accuracy: 0.4133\n",
      "Epoch 499/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4149 - accuracy: 0.4771 - val_loss: 1.4838 - val_accuracy: 0.4133\n",
      "Epoch 500/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4141 - accuracy: 0.4800 - val_loss: 1.4837 - val_accuracy: 0.4133\n",
      "Epoch 501/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.4134 - accuracy: 0.4786 - val_loss: 1.4829 - val_accuracy: 0.4133\n",
      "Epoch 502/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.4127 - accuracy: 0.4757 - val_loss: 1.4823 - val_accuracy: 0.4133\n",
      "Epoch 503/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4120 - accuracy: 0.4800 - val_loss: 1.4820 - val_accuracy: 0.4133\n",
      "Epoch 504/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4112 - accuracy: 0.4786 - val_loss: 1.4813 - val_accuracy: 0.4133\n",
      "Epoch 505/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.4106 - accuracy: 0.4786 - val_loss: 1.4810 - val_accuracy: 0.4133\n",
      "Epoch 506/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.4098 - accuracy: 0.4786 - val_loss: 1.4804 - val_accuracy: 0.4133\n",
      "Epoch 507/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.4091 - accuracy: 0.4829 - val_loss: 1.4801 - val_accuracy: 0.4133\n",
      "Epoch 508/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4084 - accuracy: 0.4757 - val_loss: 1.4792 - val_accuracy: 0.4133\n",
      "Epoch 509/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4077 - accuracy: 0.4814 - val_loss: 1.4787 - val_accuracy: 0.4133\n",
      "Epoch 510/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.4069 - accuracy: 0.4800 - val_loss: 1.4781 - val_accuracy: 0.4133\n",
      "Epoch 511/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4062 - accuracy: 0.4829 - val_loss: 1.4781 - val_accuracy: 0.4133\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(3)\n",
    "\n",
    "# 1. 데이터셋 준비하기\n",
    "\n",
    "# 훈련셋과 시험셋 로딩\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# 훈련셋과 검증셋 분리\n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "\n",
    "X_train = X_train.reshape(50000, 784).astype('float32') / 255.0\n",
    "X_val = X_val.reshape(10000, 784).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "# 훈련셋, 검증셋 고르기\n",
    "train_rand_idxs = np.random.choice(50000, 700)\n",
    "val_rand_idxs = np.random.choice(10000, 300)\n",
    "\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]\n",
    "\n",
    "# 라벨링 전환\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_val = np_utils.to_categorical(Y_val)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# 3. 모델 엮기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping() # 조기종료 콜백함수 정의\n",
    "hist = model.fit(X_train, Y_train,\n",
    "                 epochs=3000,\n",
    "                 batch_size=10, \n",
    "                 validation_data=(X_val, Y_val),\n",
    "                 callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x182e822748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 과적합 모델 살펴보기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 0s 248us/sample - loss: 2.2942 - accuracy: 0.1000 - val_loss: 2.2968 - val_accuracy: 0.0800\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 2.2867 - accuracy: 0.1000 - val_loss: 2.2901 - val_accuracy: 0.1000\n",
      "Epoch 3/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 2.2754 - accuracy: 0.1043 - val_loss: 2.2822 - val_accuracy: 0.1100\n",
      "Epoch 4/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 2.2636 - accuracy: 0.1100 - val_loss: 2.2731 - val_accuracy: 0.1067\n",
      "Epoch 5/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 2.2527 - accuracy: 0.1071 - val_loss: 2.2641 - val_accuracy: 0.1033\n",
      "Epoch 6/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.2429 - accuracy: 0.1143 - val_loss: 2.2556 - val_accuracy: 0.1033\n",
      "Epoch 7/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.2337 - accuracy: 0.1143 - val_loss: 2.2477 - val_accuracy: 0.1067\n",
      "Epoch 8/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 2.2252 - accuracy: 0.1243 - val_loss: 2.2403 - val_accuracy: 0.1200\n",
      "Epoch 9/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.2172 - accuracy: 0.1300 - val_loss: 2.2334 - val_accuracy: 0.1233\n",
      "Epoch 10/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.2095 - accuracy: 0.1286 - val_loss: 2.2266 - val_accuracy: 0.1333\n",
      "Epoch 11/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 2.2021 - accuracy: 0.1357 - val_loss: 2.2204 - val_accuracy: 0.1333\n",
      "Epoch 12/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 2.1952 - accuracy: 0.1357 - val_loss: 2.2143 - val_accuracy: 0.1367\n",
      "Epoch 13/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.1885 - accuracy: 0.1457 - val_loss: 2.2087 - val_accuracy: 0.1333\n",
      "Epoch 14/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.1821 - accuracy: 0.1457 - val_loss: 2.2031 - val_accuracy: 0.1400\n",
      "Epoch 15/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.1759 - accuracy: 0.1471 - val_loss: 2.1976 - val_accuracy: 0.1467\n",
      "Epoch 16/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.1700 - accuracy: 0.1586 - val_loss: 2.1923 - val_accuracy: 0.1467\n",
      "Epoch 17/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.1642 - accuracy: 0.1600 - val_loss: 2.1875 - val_accuracy: 0.1500\n",
      "Epoch 18/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.1585 - accuracy: 0.1629 - val_loss: 2.1825 - val_accuracy: 0.1533\n",
      "Epoch 19/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.1531 - accuracy: 0.1629 - val_loss: 2.1778 - val_accuracy: 0.1533\n",
      "Epoch 20/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.1479 - accuracy: 0.1629 - val_loss: 2.1726 - val_accuracy: 0.1567\n",
      "Epoch 21/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.1428 - accuracy: 0.1629 - val_loss: 2.1681 - val_accuracy: 0.1600\n",
      "Epoch 22/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.1378 - accuracy: 0.1686 - val_loss: 2.1634 - val_accuracy: 0.1600\n",
      "Epoch 23/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 2.1329 - accuracy: 0.1700 - val_loss: 2.1584 - val_accuracy: 0.1667\n",
      "Epoch 24/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 2.1280 - accuracy: 0.1743 - val_loss: 2.1536 - val_accuracy: 0.1733\n",
      "Epoch 25/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 2.1231 - accuracy: 0.1900 - val_loss: 2.1489 - val_accuracy: 0.1733\n",
      "Epoch 26/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 2.1184 - accuracy: 0.1857 - val_loss: 2.1441 - val_accuracy: 0.1867\n",
      "Epoch 27/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 2.1137 - accuracy: 0.1857 - val_loss: 2.1394 - val_accuracy: 0.2133\n",
      "Epoch 28/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 2.1092 - accuracy: 0.2143 - val_loss: 2.1349 - val_accuracy: 0.2467\n",
      "Epoch 29/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.1046 - accuracy: 0.2343 - val_loss: 2.1305 - val_accuracy: 0.2500\n",
      "Epoch 30/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.1002 - accuracy: 0.2429 - val_loss: 2.1261 - val_accuracy: 0.2533\n",
      "Epoch 31/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.0958 - accuracy: 0.2414 - val_loss: 2.1217 - val_accuracy: 0.2567\n",
      "Epoch 32/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.0915 - accuracy: 0.2486 - val_loss: 2.1175 - val_accuracy: 0.2600\n",
      "Epoch 33/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.0872 - accuracy: 0.2529 - val_loss: 2.1133 - val_accuracy: 0.2667\n",
      "Epoch 34/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.0829 - accuracy: 0.2586 - val_loss: 2.1092 - val_accuracy: 0.2633\n",
      "Epoch 35/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.0787 - accuracy: 0.2600 - val_loss: 2.1050 - val_accuracy: 0.2633\n",
      "Epoch 36/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.0745 - accuracy: 0.2686 - val_loss: 2.1009 - val_accuracy: 0.2633\n",
      "Epoch 37/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 2.0703 - accuracy: 0.2686 - val_loss: 2.0968 - val_accuracy: 0.2567\n",
      "Epoch 38/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.0663 - accuracy: 0.2771 - val_loss: 2.0925 - val_accuracy: 0.2567\n",
      "Epoch 39/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.0621 - accuracy: 0.2786 - val_loss: 2.0883 - val_accuracy: 0.2567\n",
      "Epoch 40/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 2.0580 - accuracy: 0.2771 - val_loss: 2.0841 - val_accuracy: 0.2533\n",
      "Epoch 41/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.0540 - accuracy: 0.2814 - val_loss: 2.0799 - val_accuracy: 0.2533\n",
      "Epoch 42/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.0499 - accuracy: 0.2800 - val_loss: 2.0760 - val_accuracy: 0.2533\n",
      "Epoch 43/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.0460 - accuracy: 0.2814 - val_loss: 2.0719 - val_accuracy: 0.2667\n",
      "Epoch 44/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 2.0421 - accuracy: 0.2814 - val_loss: 2.0678 - val_accuracy: 0.2733\n",
      "Epoch 45/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 2.0383 - accuracy: 0.2814 - val_loss: 2.0639 - val_accuracy: 0.2767\n",
      "Epoch 46/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.0344 - accuracy: 0.2843 - val_loss: 2.0600 - val_accuracy: 0.2833\n",
      "Epoch 47/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 2.0305 - accuracy: 0.2871 - val_loss: 2.0561 - val_accuracy: 0.2833\n",
      "Epoch 48/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.0268 - accuracy: 0.2929 - val_loss: 2.0524 - val_accuracy: 0.2900\n",
      "Epoch 49/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 2.0230 - accuracy: 0.2886 - val_loss: 2.0485 - val_accuracy: 0.2933\n",
      "Epoch 50/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.0192 - accuracy: 0.2900 - val_loss: 2.0449 - val_accuracy: 0.3033\n",
      "Epoch 51/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.0156 - accuracy: 0.2929 - val_loss: 2.0409 - val_accuracy: 0.3067\n",
      "Epoch 52/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.0120 - accuracy: 0.2886 - val_loss: 2.0374 - val_accuracy: 0.3067\n",
      "Epoch 53/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.0084 - accuracy: 0.2914 - val_loss: 2.0336 - val_accuracy: 0.3067\n",
      "Epoch 54/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.0048 - accuracy: 0.2929 - val_loss: 2.0300 - val_accuracy: 0.3067\n",
      "Epoch 55/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 2.0013 - accuracy: 0.2929 - val_loss: 2.0263 - val_accuracy: 0.3100\n",
      "Epoch 56/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.9978 - accuracy: 0.2914 - val_loss: 2.0227 - val_accuracy: 0.3133\n",
      "Epoch 57/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.9944 - accuracy: 0.2957 - val_loss: 2.0193 - val_accuracy: 0.3133\n",
      "Epoch 58/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.9909 - accuracy: 0.2957 - val_loss: 2.0155 - val_accuracy: 0.3100\n",
      "Epoch 59/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.9874 - accuracy: 0.2957 - val_loss: 2.0123 - val_accuracy: 0.3133\n",
      "Epoch 60/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.9840 - accuracy: 0.2957 - val_loss: 2.0086 - val_accuracy: 0.3200\n",
      "Epoch 61/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.9807 - accuracy: 0.3014 - val_loss: 2.0052 - val_accuracy: 0.3233\n",
      "Epoch 62/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.9773 - accuracy: 0.2957 - val_loss: 2.0018 - val_accuracy: 0.3233\n",
      "Epoch 63/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.9739 - accuracy: 0.3000 - val_loss: 1.9981 - val_accuracy: 0.3300\n",
      "Epoch 64/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.9706 - accuracy: 0.3014 - val_loss: 1.9948 - val_accuracy: 0.3267\n",
      "Epoch 65/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.9674 - accuracy: 0.3043 - val_loss: 1.9917 - val_accuracy: 0.3300\n",
      "Epoch 66/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.9643 - accuracy: 0.3029 - val_loss: 1.9883 - val_accuracy: 0.3333\n",
      "Epoch 67/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.9610 - accuracy: 0.3043 - val_loss: 1.9852 - val_accuracy: 0.3333\n",
      "Epoch 68/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.9579 - accuracy: 0.3014 - val_loss: 1.9823 - val_accuracy: 0.3367\n",
      "Epoch 69/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.9547 - accuracy: 0.3043 - val_loss: 1.9790 - val_accuracy: 0.3333\n",
      "Epoch 70/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.9516 - accuracy: 0.3043 - val_loss: 1.9757 - val_accuracy: 0.3333\n",
      "Epoch 71/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.9486 - accuracy: 0.3057 - val_loss: 1.9725 - val_accuracy: 0.3333\n",
      "Epoch 72/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.9455 - accuracy: 0.3100 - val_loss: 1.9694 - val_accuracy: 0.3367\n",
      "Epoch 73/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.9425 - accuracy: 0.3157 - val_loss: 1.9664 - val_accuracy: 0.3400\n",
      "Epoch 74/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.9394 - accuracy: 0.3157 - val_loss: 1.9633 - val_accuracy: 0.3400\n",
      "Epoch 75/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.9364 - accuracy: 0.3214 - val_loss: 1.9602 - val_accuracy: 0.3367\n",
      "Epoch 76/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.9335 - accuracy: 0.3257 - val_loss: 1.9572 - val_accuracy: 0.3467\n",
      "Epoch 77/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.9306 - accuracy: 0.3243 - val_loss: 1.9546 - val_accuracy: 0.3500\n",
      "Epoch 78/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.9277 - accuracy: 0.3314 - val_loss: 1.9515 - val_accuracy: 0.3467\n",
      "Epoch 79/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.9249 - accuracy: 0.3286 - val_loss: 1.9488 - val_accuracy: 0.3467\n",
      "Epoch 80/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.9221 - accuracy: 0.3314 - val_loss: 1.9460 - val_accuracy: 0.3467\n",
      "Epoch 81/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.9192 - accuracy: 0.3300 - val_loss: 1.9430 - val_accuracy: 0.3500\n",
      "Epoch 82/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.9164 - accuracy: 0.3343 - val_loss: 1.9403 - val_accuracy: 0.3567\n",
      "Epoch 83/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.9137 - accuracy: 0.3300 - val_loss: 1.9374 - val_accuracy: 0.3567\n",
      "Epoch 84/3000\n",
      "700/700 [==============================] - 0s 109us/sample - loss: 1.9110 - accuracy: 0.3286 - val_loss: 1.9347 - val_accuracy: 0.3600\n",
      "Epoch 85/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.9082 - accuracy: 0.3300 - val_loss: 1.9321 - val_accuracy: 0.3700\n",
      "Epoch 86/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.9055 - accuracy: 0.3329 - val_loss: 1.9294 - val_accuracy: 0.3667\n",
      "Epoch 87/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.9029 - accuracy: 0.3343 - val_loss: 1.9263 - val_accuracy: 0.3633\n",
      "Epoch 88/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.9002 - accuracy: 0.3357 - val_loss: 1.9237 - val_accuracy: 0.3633\n",
      "Epoch 89/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.8976 - accuracy: 0.3414 - val_loss: 1.9207 - val_accuracy: 0.3700\n",
      "Epoch 90/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.8950 - accuracy: 0.3400 - val_loss: 1.9181 - val_accuracy: 0.3667\n",
      "Epoch 91/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.8924 - accuracy: 0.3429 - val_loss: 1.9155 - val_accuracy: 0.3700\n",
      "Epoch 92/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.8899 - accuracy: 0.3429 - val_loss: 1.9128 - val_accuracy: 0.3733\n",
      "Epoch 93/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.8873 - accuracy: 0.3357 - val_loss: 1.9103 - val_accuracy: 0.3767\n",
      "Epoch 94/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.8848 - accuracy: 0.3429 - val_loss: 1.9078 - val_accuracy: 0.3800\n",
      "Epoch 95/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.8823 - accuracy: 0.3429 - val_loss: 1.9054 - val_accuracy: 0.3800\n",
      "Epoch 96/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.8798 - accuracy: 0.3429 - val_loss: 1.9029 - val_accuracy: 0.3833\n",
      "Epoch 97/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.8773 - accuracy: 0.3414 - val_loss: 1.9003 - val_accuracy: 0.3800\n",
      "Epoch 98/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.8748 - accuracy: 0.3386 - val_loss: 1.8978 - val_accuracy: 0.3800\n",
      "Epoch 99/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.8725 - accuracy: 0.3386 - val_loss: 1.8955 - val_accuracy: 0.3733\n",
      "Epoch 100/3000\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 1.8701 - accuracy: 0.3386 - val_loss: 1.8931 - val_accuracy: 0.3667\n",
      "Epoch 101/3000\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 1.8676 - accuracy: 0.3371 - val_loss: 1.8908 - val_accuracy: 0.3667\n",
      "Epoch 102/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.8651 - accuracy: 0.3286 - val_loss: 1.8881 - val_accuracy: 0.3033\n",
      "Epoch 103/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.8628 - accuracy: 0.3229 - val_loss: 1.8857 - val_accuracy: 0.3033\n",
      "Epoch 104/3000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 1.8606 - accuracy: 0.3229 - val_loss: 1.8837 - val_accuracy: 0.3000\n",
      "Epoch 105/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.8581 - accuracy: 0.3243 - val_loss: 1.8814 - val_accuracy: 0.2967\n",
      "Epoch 106/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.8558 - accuracy: 0.3243 - val_loss: 1.8791 - val_accuracy: 0.2900\n",
      "Epoch 107/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.8535 - accuracy: 0.3200 - val_loss: 1.8771 - val_accuracy: 0.2900\n",
      "Epoch 108/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.8512 - accuracy: 0.3214 - val_loss: 1.8748 - val_accuracy: 0.2833\n",
      "Epoch 109/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.8489 - accuracy: 0.3200 - val_loss: 1.8723 - val_accuracy: 0.2800\n",
      "Epoch 110/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.8467 - accuracy: 0.3214 - val_loss: 1.8703 - val_accuracy: 0.2933\n",
      "Epoch 111/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.8444 - accuracy: 0.3229 - val_loss: 1.8682 - val_accuracy: 0.2867\n",
      "Epoch 112/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.8422 - accuracy: 0.3243 - val_loss: 1.8659 - val_accuracy: 0.2967\n",
      "Epoch 113/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.8400 - accuracy: 0.3271 - val_loss: 1.8637 - val_accuracy: 0.2967\n",
      "Epoch 114/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.8377 - accuracy: 0.3143 - val_loss: 1.8614 - val_accuracy: 0.3033\n",
      "Epoch 115/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.8355 - accuracy: 0.3186 - val_loss: 1.8594 - val_accuracy: 0.2967\n",
      "Epoch 116/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.8333 - accuracy: 0.3186 - val_loss: 1.8573 - val_accuracy: 0.2933\n",
      "Epoch 117/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.8311 - accuracy: 0.3214 - val_loss: 1.8549 - val_accuracy: 0.2933\n",
      "Epoch 118/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.8290 - accuracy: 0.3157 - val_loss: 1.8530 - val_accuracy: 0.2867\n",
      "Epoch 119/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.8268 - accuracy: 0.3171 - val_loss: 1.8505 - val_accuracy: 0.2867\n",
      "Epoch 120/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.8247 - accuracy: 0.3157 - val_loss: 1.8485 - val_accuracy: 0.2900\n",
      "Epoch 121/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.8226 - accuracy: 0.3114 - val_loss: 1.8465 - val_accuracy: 0.2900\n",
      "Epoch 122/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.8205 - accuracy: 0.3171 - val_loss: 1.8446 - val_accuracy: 0.2900\n",
      "Epoch 123/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.8185 - accuracy: 0.3186 - val_loss: 1.8427 - val_accuracy: 0.2900\n",
      "Epoch 124/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.8163 - accuracy: 0.3129 - val_loss: 1.8407 - val_accuracy: 0.2900\n",
      "Epoch 125/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.8143 - accuracy: 0.3143 - val_loss: 1.8386 - val_accuracy: 0.2900\n",
      "Epoch 126/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.8122 - accuracy: 0.3186 - val_loss: 1.8365 - val_accuracy: 0.2900\n",
      "Epoch 127/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.8102 - accuracy: 0.3171 - val_loss: 1.8347 - val_accuracy: 0.2900\n",
      "Epoch 128/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.8081 - accuracy: 0.3200 - val_loss: 1.8330 - val_accuracy: 0.2900\n",
      "Epoch 129/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.8062 - accuracy: 0.3157 - val_loss: 1.8310 - val_accuracy: 0.2900\n",
      "Epoch 130/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.8041 - accuracy: 0.3171 - val_loss: 1.8295 - val_accuracy: 0.2900\n",
      "Epoch 131/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.8022 - accuracy: 0.3200 - val_loss: 1.8274 - val_accuracy: 0.2900\n",
      "Epoch 132/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.8001 - accuracy: 0.3171 - val_loss: 1.8251 - val_accuracy: 0.2900\n",
      "Epoch 133/3000\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 1.7983 - accuracy: 0.3171 - val_loss: 1.8234 - val_accuracy: 0.2900\n",
      "Epoch 134/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.7962 - accuracy: 0.3157 - val_loss: 1.8217 - val_accuracy: 0.2900\n",
      "Epoch 135/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.7943 - accuracy: 0.3214 - val_loss: 1.8196 - val_accuracy: 0.2900\n",
      "Epoch 136/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.7923 - accuracy: 0.3286 - val_loss: 1.8180 - val_accuracy: 0.2933\n",
      "Epoch 137/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.7904 - accuracy: 0.3357 - val_loss: 1.8166 - val_accuracy: 0.2933\n",
      "Epoch 138/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.7884 - accuracy: 0.3186 - val_loss: 1.8149 - val_accuracy: 0.2933\n",
      "Epoch 139/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.7866 - accuracy: 0.3200 - val_loss: 1.8131 - val_accuracy: 0.2933\n",
      "Epoch 140/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.7846 - accuracy: 0.3200 - val_loss: 1.8112 - val_accuracy: 0.2933\n",
      "Epoch 141/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7826 - accuracy: 0.3329 - val_loss: 1.8095 - val_accuracy: 0.2933\n",
      "Epoch 142/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.7806 - accuracy: 0.3371 - val_loss: 1.8076 - val_accuracy: 0.2967\n",
      "Epoch 143/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.7786 - accuracy: 0.3414 - val_loss: 1.8062 - val_accuracy: 0.2933\n",
      "Epoch 144/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.7768 - accuracy: 0.3300 - val_loss: 1.8042 - val_accuracy: 0.2967\n",
      "Epoch 145/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7749 - accuracy: 0.3243 - val_loss: 1.8026 - val_accuracy: 0.2967\n",
      "Epoch 146/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7730 - accuracy: 0.3514 - val_loss: 1.8013 - val_accuracy: 0.2967\n",
      "Epoch 147/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.7710 - accuracy: 0.3286 - val_loss: 1.7996 - val_accuracy: 0.2933\n",
      "Epoch 148/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7692 - accuracy: 0.3286 - val_loss: 1.7978 - val_accuracy: 0.3167\n",
      "Epoch 149/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.7673 - accuracy: 0.3629 - val_loss: 1.7961 - val_accuracy: 0.3200\n",
      "Epoch 150/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7654 - accuracy: 0.3486 - val_loss: 1.7948 - val_accuracy: 0.3200\n",
      "Epoch 151/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.7636 - accuracy: 0.3657 - val_loss: 1.7933 - val_accuracy: 0.3200\n",
      "Epoch 152/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.7618 - accuracy: 0.3543 - val_loss: 1.7916 - val_accuracy: 0.3200\n",
      "Epoch 153/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.7598 - accuracy: 0.3686 - val_loss: 1.7899 - val_accuracy: 0.3200\n",
      "Epoch 154/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7579 - accuracy: 0.3543 - val_loss: 1.7887 - val_accuracy: 0.3200\n",
      "Epoch 155/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.7561 - accuracy: 0.3671 - val_loss: 1.7867 - val_accuracy: 0.3267\n",
      "Epoch 156/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7543 - accuracy: 0.3457 - val_loss: 1.7850 - val_accuracy: 0.3233\n",
      "Epoch 157/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.7524 - accuracy: 0.3686 - val_loss: 1.7834 - val_accuracy: 0.3267\n",
      "Epoch 158/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.7505 - accuracy: 0.3729 - val_loss: 1.7821 - val_accuracy: 0.3233\n",
      "Epoch 159/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.7487 - accuracy: 0.3729 - val_loss: 1.7809 - val_accuracy: 0.3200\n",
      "Epoch 160/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.7467 - accuracy: 0.3771 - val_loss: 1.7792 - val_accuracy: 0.3200\n",
      "Epoch 161/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.7449 - accuracy: 0.3743 - val_loss: 1.7778 - val_accuracy: 0.3200\n",
      "Epoch 162/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.7429 - accuracy: 0.3743 - val_loss: 1.7763 - val_accuracy: 0.3200\n",
      "Epoch 163/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.7411 - accuracy: 0.3714 - val_loss: 1.7753 - val_accuracy: 0.3200\n",
      "Epoch 164/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.7392 - accuracy: 0.3786 - val_loss: 1.7738 - val_accuracy: 0.3200\n",
      "Epoch 165/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.7373 - accuracy: 0.3786 - val_loss: 1.7723 - val_accuracy: 0.3200\n",
      "Epoch 166/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7354 - accuracy: 0.3771 - val_loss: 1.7705 - val_accuracy: 0.3233\n",
      "Epoch 167/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.7336 - accuracy: 0.3800 - val_loss: 1.7693 - val_accuracy: 0.3233\n",
      "Epoch 168/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.7317 - accuracy: 0.3771 - val_loss: 1.7678 - val_accuracy: 0.3233\n",
      "Epoch 169/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.7298 - accuracy: 0.3800 - val_loss: 1.7665 - val_accuracy: 0.3233\n",
      "Epoch 170/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7278 - accuracy: 0.3800 - val_loss: 1.7646 - val_accuracy: 0.3267\n",
      "Epoch 171/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.7260 - accuracy: 0.3786 - val_loss: 1.7634 - val_accuracy: 0.3267\n",
      "Epoch 172/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.7241 - accuracy: 0.3857 - val_loss: 1.7619 - val_accuracy: 0.3267\n",
      "Epoch 173/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.7222 - accuracy: 0.3800 - val_loss: 1.7605 - val_accuracy: 0.3300\n",
      "Epoch 174/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.7204 - accuracy: 0.3786 - val_loss: 1.7590 - val_accuracy: 0.3300\n",
      "Epoch 175/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.7185 - accuracy: 0.3857 - val_loss: 1.7580 - val_accuracy: 0.3333\n",
      "Epoch 176/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7166 - accuracy: 0.3843 - val_loss: 1.7565 - val_accuracy: 0.3267\n",
      "Epoch 177/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7148 - accuracy: 0.3829 - val_loss: 1.7548 - val_accuracy: 0.3333\n",
      "Epoch 178/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.7130 - accuracy: 0.3829 - val_loss: 1.7534 - val_accuracy: 0.3333\n",
      "Epoch 179/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.7111 - accuracy: 0.3829 - val_loss: 1.7519 - val_accuracy: 0.3300\n",
      "Epoch 180/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7093 - accuracy: 0.3900 - val_loss: 1.7504 - val_accuracy: 0.3300\n",
      "Epoch 181/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.7074 - accuracy: 0.3900 - val_loss: 1.7489 - val_accuracy: 0.3300\n",
      "Epoch 182/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.7056 - accuracy: 0.3857 - val_loss: 1.7476 - val_accuracy: 0.3300\n",
      "Epoch 183/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.7038 - accuracy: 0.3871 - val_loss: 1.7463 - val_accuracy: 0.3333\n",
      "Epoch 184/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.7019 - accuracy: 0.3886 - val_loss: 1.7449 - val_accuracy: 0.3333\n",
      "Epoch 185/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.7001 - accuracy: 0.3871 - val_loss: 1.7435 - val_accuracy: 0.3300\n",
      "Epoch 186/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6983 - accuracy: 0.3929 - val_loss: 1.7424 - val_accuracy: 0.3300\n",
      "Epoch 187/3000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 1.6965 - accuracy: 0.3986 - val_loss: 1.7408 - val_accuracy: 0.3333\n",
      "Epoch 188/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.6947 - accuracy: 0.3986 - val_loss: 1.7391 - val_accuracy: 0.3333\n",
      "Epoch 189/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.6929 - accuracy: 0.3971 - val_loss: 1.7379 - val_accuracy: 0.3333\n",
      "Epoch 190/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.6911 - accuracy: 0.4029 - val_loss: 1.7366 - val_accuracy: 0.3333\n",
      "Epoch 191/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.6893 - accuracy: 0.4000 - val_loss: 1.7351 - val_accuracy: 0.3333\n",
      "Epoch 192/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6875 - accuracy: 0.3971 - val_loss: 1.7341 - val_accuracy: 0.3333\n",
      "Epoch 193/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.6857 - accuracy: 0.3986 - val_loss: 1.7328 - val_accuracy: 0.3333\n",
      "Epoch 194/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6838 - accuracy: 0.4014 - val_loss: 1.7313 - val_accuracy: 0.3333\n",
      "Epoch 195/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6821 - accuracy: 0.3986 - val_loss: 1.7297 - val_accuracy: 0.3367\n",
      "Epoch 196/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.6801 - accuracy: 0.3986 - val_loss: 1.7282 - val_accuracy: 0.3367\n",
      "Epoch 197/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6782 - accuracy: 0.4043 - val_loss: 1.7268 - val_accuracy: 0.3400\n",
      "Epoch 198/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6764 - accuracy: 0.4057 - val_loss: 1.7255 - val_accuracy: 0.3367\n",
      "Epoch 199/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6747 - accuracy: 0.3986 - val_loss: 1.7241 - val_accuracy: 0.3400\n",
      "Epoch 200/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.6727 - accuracy: 0.4014 - val_loss: 1.7228 - val_accuracy: 0.3400\n",
      "Epoch 201/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.6709 - accuracy: 0.4043 - val_loss: 1.7216 - val_accuracy: 0.3400\n",
      "Epoch 202/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.6691 - accuracy: 0.4014 - val_loss: 1.7199 - val_accuracy: 0.3400\n",
      "Epoch 203/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6673 - accuracy: 0.3971 - val_loss: 1.7184 - val_accuracy: 0.3400\n",
      "Epoch 204/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6655 - accuracy: 0.3929 - val_loss: 1.7170 - val_accuracy: 0.3400\n",
      "Epoch 205/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6635 - accuracy: 0.3986 - val_loss: 1.7156 - val_accuracy: 0.3400\n",
      "Epoch 206/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.6618 - accuracy: 0.3957 - val_loss: 1.7140 - val_accuracy: 0.3400\n",
      "Epoch 207/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.6600 - accuracy: 0.3971 - val_loss: 1.7124 - val_accuracy: 0.3433\n",
      "Epoch 208/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6580 - accuracy: 0.3971 - val_loss: 1.7111 - val_accuracy: 0.3433\n",
      "Epoch 209/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6562 - accuracy: 0.3971 - val_loss: 1.7098 - val_accuracy: 0.3433\n",
      "Epoch 210/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6543 - accuracy: 0.3986 - val_loss: 1.7086 - val_accuracy: 0.3433\n",
      "Epoch 211/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6526 - accuracy: 0.3971 - val_loss: 1.7070 - val_accuracy: 0.3433\n",
      "Epoch 212/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6508 - accuracy: 0.3971 - val_loss: 1.7055 - val_accuracy: 0.3467\n",
      "Epoch 213/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.6490 - accuracy: 0.4014 - val_loss: 1.7040 - val_accuracy: 0.3467\n",
      "Epoch 214/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.6469 - accuracy: 0.4014 - val_loss: 1.7026 - val_accuracy: 0.3467\n",
      "Epoch 215/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.6453 - accuracy: 0.4014 - val_loss: 1.7008 - val_accuracy: 0.3500\n",
      "Epoch 216/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.6434 - accuracy: 0.4014 - val_loss: 1.6993 - val_accuracy: 0.3500\n",
      "Epoch 217/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.6417 - accuracy: 0.4014 - val_loss: 1.6977 - val_accuracy: 0.3467\n",
      "Epoch 218/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.6398 - accuracy: 0.4014 - val_loss: 1.6964 - val_accuracy: 0.3467\n",
      "Epoch 219/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.6379 - accuracy: 0.4014 - val_loss: 1.6951 - val_accuracy: 0.3500\n",
      "Epoch 220/3000\n",
      "700/700 [==============================] - 0s 89us/sample - loss: 1.6360 - accuracy: 0.4043 - val_loss: 1.6938 - val_accuracy: 0.3467\n",
      "Epoch 221/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.6342 - accuracy: 0.4000 - val_loss: 1.6921 - val_accuracy: 0.3433\n",
      "Epoch 222/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6324 - accuracy: 0.4057 - val_loss: 1.6908 - val_accuracy: 0.3433\n",
      "Epoch 223/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.6306 - accuracy: 0.4057 - val_loss: 1.6891 - val_accuracy: 0.3433\n",
      "Epoch 224/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6287 - accuracy: 0.4057 - val_loss: 1.6878 - val_accuracy: 0.3467\n",
      "Epoch 225/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.6269 - accuracy: 0.4086 - val_loss: 1.6861 - val_accuracy: 0.3467\n",
      "Epoch 226/3000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 1.6252 - accuracy: 0.4071 - val_loss: 1.6848 - val_accuracy: 0.3467\n",
      "Epoch 227/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.6232 - accuracy: 0.4071 - val_loss: 1.6835 - val_accuracy: 0.3400\n",
      "Epoch 228/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.6215 - accuracy: 0.4086 - val_loss: 1.6821 - val_accuracy: 0.3433\n",
      "Epoch 229/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.6196 - accuracy: 0.4086 - val_loss: 1.6809 - val_accuracy: 0.3433\n",
      "Epoch 230/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6178 - accuracy: 0.4071 - val_loss: 1.6792 - val_accuracy: 0.3433\n",
      "Epoch 231/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.6160 - accuracy: 0.4114 - val_loss: 1.6778 - val_accuracy: 0.3433\n",
      "Epoch 232/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6142 - accuracy: 0.4114 - val_loss: 1.6764 - val_accuracy: 0.3467\n",
      "Epoch 233/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.6123 - accuracy: 0.4071 - val_loss: 1.6748 - val_accuracy: 0.3467\n",
      "Epoch 234/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6105 - accuracy: 0.4100 - val_loss: 1.6734 - val_accuracy: 0.3467\n",
      "Epoch 235/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6087 - accuracy: 0.4086 - val_loss: 1.6719 - val_accuracy: 0.3467\n",
      "Epoch 236/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6069 - accuracy: 0.4086 - val_loss: 1.6704 - val_accuracy: 0.3467\n",
      "Epoch 237/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6048 - accuracy: 0.4086 - val_loss: 1.6689 - val_accuracy: 0.3467\n",
      "Epoch 238/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6032 - accuracy: 0.4114 - val_loss: 1.6678 - val_accuracy: 0.3467\n",
      "Epoch 239/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6013 - accuracy: 0.4100 - val_loss: 1.6663 - val_accuracy: 0.3467\n",
      "Epoch 240/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5994 - accuracy: 0.4100 - val_loss: 1.6646 - val_accuracy: 0.3500\n",
      "Epoch 241/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5976 - accuracy: 0.4157 - val_loss: 1.6634 - val_accuracy: 0.3500\n",
      "Epoch 242/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5959 - accuracy: 0.4129 - val_loss: 1.6619 - val_accuracy: 0.3467\n",
      "Epoch 243/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5940 - accuracy: 0.4157 - val_loss: 1.6603 - val_accuracy: 0.3467\n",
      "Epoch 244/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.5922 - accuracy: 0.4143 - val_loss: 1.6590 - val_accuracy: 0.3500\n",
      "Epoch 245/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.5902 - accuracy: 0.4114 - val_loss: 1.6571 - val_accuracy: 0.3433\n",
      "Epoch 246/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.5884 - accuracy: 0.4157 - val_loss: 1.6556 - val_accuracy: 0.3533\n",
      "Epoch 247/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5865 - accuracy: 0.4129 - val_loss: 1.6539 - val_accuracy: 0.3533\n",
      "Epoch 248/3000\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 1.5847 - accuracy: 0.4186 - val_loss: 1.6528 - val_accuracy: 0.3500\n",
      "Epoch 249/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.5829 - accuracy: 0.4171 - val_loss: 1.6514 - val_accuracy: 0.3533\n",
      "Epoch 250/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.5811 - accuracy: 0.4186 - val_loss: 1.6499 - val_accuracy: 0.3533\n",
      "Epoch 251/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5791 - accuracy: 0.4200 - val_loss: 1.6486 - val_accuracy: 0.3467\n",
      "Epoch 252/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.5773 - accuracy: 0.4186 - val_loss: 1.6468 - val_accuracy: 0.3500\n",
      "Epoch 253/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.5754 - accuracy: 0.4171 - val_loss: 1.6449 - val_accuracy: 0.3500\n",
      "Epoch 254/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.5736 - accuracy: 0.4243 - val_loss: 1.6434 - val_accuracy: 0.3467\n",
      "Epoch 255/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5717 - accuracy: 0.4214 - val_loss: 1.6423 - val_accuracy: 0.3433\n",
      "Epoch 256/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5699 - accuracy: 0.4271 - val_loss: 1.6411 - val_accuracy: 0.3433\n",
      "Epoch 257/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5680 - accuracy: 0.4186 - val_loss: 1.6392 - val_accuracy: 0.3467\n",
      "Epoch 258/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5660 - accuracy: 0.4186 - val_loss: 1.6372 - val_accuracy: 0.3500\n",
      "Epoch 259/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.5644 - accuracy: 0.4243 - val_loss: 1.6356 - val_accuracy: 0.3467\n",
      "Epoch 260/3000\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 1.5625 - accuracy: 0.4229 - val_loss: 1.6345 - val_accuracy: 0.3433\n",
      "Epoch 261/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5606 - accuracy: 0.4243 - val_loss: 1.6327 - val_accuracy: 0.3500\n",
      "Epoch 262/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5588 - accuracy: 0.4271 - val_loss: 1.6312 - val_accuracy: 0.3433\n",
      "Epoch 263/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5569 - accuracy: 0.4257 - val_loss: 1.6298 - val_accuracy: 0.3433\n",
      "Epoch 264/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.5550 - accuracy: 0.4271 - val_loss: 1.6286 - val_accuracy: 0.3433\n",
      "Epoch 265/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5531 - accuracy: 0.4314 - val_loss: 1.6267 - val_accuracy: 0.3467\n",
      "Epoch 266/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.5513 - accuracy: 0.4314 - val_loss: 1.6254 - val_accuracy: 0.3467\n",
      "Epoch 267/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.5495 - accuracy: 0.4300 - val_loss: 1.6243 - val_accuracy: 0.3467\n",
      "Epoch 268/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.5476 - accuracy: 0.4300 - val_loss: 1.6225 - val_accuracy: 0.3467\n",
      "Epoch 269/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5458 - accuracy: 0.4314 - val_loss: 1.6210 - val_accuracy: 0.3433\n",
      "Epoch 270/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5439 - accuracy: 0.4314 - val_loss: 1.6193 - val_accuracy: 0.3500\n",
      "Epoch 271/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5420 - accuracy: 0.4343 - val_loss: 1.6179 - val_accuracy: 0.3533\n",
      "Epoch 272/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.5403 - accuracy: 0.4343 - val_loss: 1.6164 - val_accuracy: 0.3533\n",
      "Epoch 273/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.5384 - accuracy: 0.4343 - val_loss: 1.6153 - val_accuracy: 0.3533\n",
      "Epoch 274/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5364 - accuracy: 0.4371 - val_loss: 1.6139 - val_accuracy: 0.3533\n",
      "Epoch 275/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5346 - accuracy: 0.4386 - val_loss: 1.6121 - val_accuracy: 0.3533\n",
      "Epoch 276/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5328 - accuracy: 0.4443 - val_loss: 1.6106 - val_accuracy: 0.3533\n",
      "Epoch 277/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.5310 - accuracy: 0.4371 - val_loss: 1.6094 - val_accuracy: 0.3567\n",
      "Epoch 278/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.5291 - accuracy: 0.4471 - val_loss: 1.6077 - val_accuracy: 0.3567\n",
      "Epoch 279/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5273 - accuracy: 0.4457 - val_loss: 1.6058 - val_accuracy: 0.3567\n",
      "Epoch 280/3000\n",
      "700/700 [==============================] - 0s 87us/sample - loss: 1.5255 - accuracy: 0.4429 - val_loss: 1.6043 - val_accuracy: 0.3567\n",
      "Epoch 281/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5236 - accuracy: 0.4471 - val_loss: 1.6029 - val_accuracy: 0.3533\n",
      "Epoch 282/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5218 - accuracy: 0.4443 - val_loss: 1.6016 - val_accuracy: 0.3533\n",
      "Epoch 283/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5199 - accuracy: 0.4457 - val_loss: 1.6004 - val_accuracy: 0.3533\n",
      "Epoch 284/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.5182 - accuracy: 0.4486 - val_loss: 1.5987 - val_accuracy: 0.3533\n",
      "Epoch 285/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5163 - accuracy: 0.4514 - val_loss: 1.5973 - val_accuracy: 0.3533\n",
      "Epoch 286/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5145 - accuracy: 0.4514 - val_loss: 1.5958 - val_accuracy: 0.3500\n",
      "Epoch 287/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5126 - accuracy: 0.4500 - val_loss: 1.5944 - val_accuracy: 0.3500\n",
      "Epoch 288/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5108 - accuracy: 0.4514 - val_loss: 1.5929 - val_accuracy: 0.3500\n",
      "Epoch 289/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.5090 - accuracy: 0.4486 - val_loss: 1.5913 - val_accuracy: 0.3533\n",
      "Epoch 290/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5071 - accuracy: 0.4471 - val_loss: 1.5903 - val_accuracy: 0.3500\n",
      "Epoch 291/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5054 - accuracy: 0.4486 - val_loss: 1.5887 - val_accuracy: 0.3500\n",
      "Epoch 292/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5035 - accuracy: 0.4500 - val_loss: 1.5872 - val_accuracy: 0.3533\n",
      "Epoch 293/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5017 - accuracy: 0.4529 - val_loss: 1.5854 - val_accuracy: 0.3533\n",
      "Epoch 294/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5001 - accuracy: 0.4543 - val_loss: 1.5838 - val_accuracy: 0.3533\n",
      "Epoch 295/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4982 - accuracy: 0.4529 - val_loss: 1.5826 - val_accuracy: 0.3533\n",
      "Epoch 296/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.4963 - accuracy: 0.4586 - val_loss: 1.5809 - val_accuracy: 0.3533\n",
      "Epoch 297/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4945 - accuracy: 0.4557 - val_loss: 1.5797 - val_accuracy: 0.3533\n",
      "Epoch 298/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.4928 - accuracy: 0.4600 - val_loss: 1.5785 - val_accuracy: 0.3533\n",
      "Epoch 299/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4910 - accuracy: 0.4586 - val_loss: 1.5766 - val_accuracy: 0.3500\n",
      "Epoch 300/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4893 - accuracy: 0.4557 - val_loss: 1.5747 - val_accuracy: 0.3533\n",
      "Epoch 301/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4875 - accuracy: 0.4529 - val_loss: 1.5738 - val_accuracy: 0.3567\n",
      "Epoch 302/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.4857 - accuracy: 0.4600 - val_loss: 1.5724 - val_accuracy: 0.3567\n",
      "Epoch 303/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.4839 - accuracy: 0.4557 - val_loss: 1.5707 - val_accuracy: 0.3600\n",
      "Epoch 304/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4820 - accuracy: 0.4629 - val_loss: 1.5692 - val_accuracy: 0.3567\n",
      "Epoch 305/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4804 - accuracy: 0.4600 - val_loss: 1.5676 - val_accuracy: 0.3633\n",
      "Epoch 306/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.4785 - accuracy: 0.4586 - val_loss: 1.5668 - val_accuracy: 0.3667\n",
      "Epoch 307/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4769 - accuracy: 0.4614 - val_loss: 1.5648 - val_accuracy: 0.3600\n",
      "Epoch 308/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4751 - accuracy: 0.4629 - val_loss: 1.5637 - val_accuracy: 0.3667\n",
      "Epoch 309/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4734 - accuracy: 0.4600 - val_loss: 1.5621 - val_accuracy: 0.3600\n",
      "Epoch 310/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4717 - accuracy: 0.4643 - val_loss: 1.5605 - val_accuracy: 0.3600\n",
      "Epoch 311/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4699 - accuracy: 0.4643 - val_loss: 1.5592 - val_accuracy: 0.3633\n",
      "Epoch 312/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.4683 - accuracy: 0.4671 - val_loss: 1.5578 - val_accuracy: 0.3667\n",
      "Epoch 313/3000\n",
      "700/700 [==============================] - 0s 88us/sample - loss: 1.4665 - accuracy: 0.4643 - val_loss: 1.5566 - val_accuracy: 0.3667\n",
      "Epoch 314/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.4647 - accuracy: 0.4657 - val_loss: 1.5547 - val_accuracy: 0.3667\n",
      "Epoch 315/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.4631 - accuracy: 0.4671 - val_loss: 1.5535 - val_accuracy: 0.3700\n",
      "Epoch 316/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4614 - accuracy: 0.4686 - val_loss: 1.5519 - val_accuracy: 0.3700\n",
      "Epoch 317/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4597 - accuracy: 0.4657 - val_loss: 1.5503 - val_accuracy: 0.3700\n",
      "Epoch 318/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4581 - accuracy: 0.4700 - val_loss: 1.5490 - val_accuracy: 0.3733\n",
      "Epoch 319/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4564 - accuracy: 0.4671 - val_loss: 1.5478 - val_accuracy: 0.3733\n",
      "Epoch 320/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4547 - accuracy: 0.4700 - val_loss: 1.5467 - val_accuracy: 0.3733\n",
      "Epoch 321/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4530 - accuracy: 0.4686 - val_loss: 1.5454 - val_accuracy: 0.3667\n",
      "Epoch 322/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.4513 - accuracy: 0.4671 - val_loss: 1.5435 - val_accuracy: 0.3667\n",
      "Epoch 323/3000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 1.4497 - accuracy: 0.4686 - val_loss: 1.5422 - val_accuracy: 0.3633\n",
      "Epoch 324/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4479 - accuracy: 0.4700 - val_loss: 1.5414 - val_accuracy: 0.3600\n",
      "Epoch 325/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4463 - accuracy: 0.4729 - val_loss: 1.5394 - val_accuracy: 0.3700\n",
      "Epoch 326/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.4449 - accuracy: 0.4714 - val_loss: 1.5386 - val_accuracy: 0.3633\n",
      "Epoch 327/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.4431 - accuracy: 0.4714 - val_loss: 1.5371 - val_accuracy: 0.3633\n",
      "Epoch 328/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.4416 - accuracy: 0.4714 - val_loss: 1.5357 - val_accuracy: 0.3700\n",
      "Epoch 329/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4401 - accuracy: 0.4700 - val_loss: 1.5345 - val_accuracy: 0.3700\n",
      "Epoch 330/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4383 - accuracy: 0.4757 - val_loss: 1.5328 - val_accuracy: 0.3733\n",
      "Epoch 331/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4366 - accuracy: 0.4729 - val_loss: 1.5319 - val_accuracy: 0.3733\n",
      "Epoch 332/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.4352 - accuracy: 0.4743 - val_loss: 1.5305 - val_accuracy: 0.3767\n",
      "Epoch 333/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4336 - accuracy: 0.4714 - val_loss: 1.5293 - val_accuracy: 0.3733\n",
      "Epoch 334/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4320 - accuracy: 0.4771 - val_loss: 1.5276 - val_accuracy: 0.3767\n",
      "Epoch 335/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.4304 - accuracy: 0.4743 - val_loss: 1.5265 - val_accuracy: 0.3767\n",
      "Epoch 336/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.4289 - accuracy: 0.4743 - val_loss: 1.5255 - val_accuracy: 0.3767\n",
      "Epoch 337/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4273 - accuracy: 0.4757 - val_loss: 1.5243 - val_accuracy: 0.3767\n",
      "Epoch 338/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.4258 - accuracy: 0.4743 - val_loss: 1.5232 - val_accuracy: 0.3767\n",
      "Epoch 339/3000\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 1.4243 - accuracy: 0.4771 - val_loss: 1.5218 - val_accuracy: 0.3767\n",
      "Epoch 340/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4228 - accuracy: 0.4786 - val_loss: 1.5205 - val_accuracy: 0.3767\n",
      "Epoch 341/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.4213 - accuracy: 0.4757 - val_loss: 1.5191 - val_accuracy: 0.3800\n",
      "Epoch 342/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.4198 - accuracy: 0.4814 - val_loss: 1.5182 - val_accuracy: 0.3833\n",
      "Epoch 343/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.4182 - accuracy: 0.4814 - val_loss: 1.5169 - val_accuracy: 0.3833\n",
      "Epoch 344/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.4169 - accuracy: 0.4786 - val_loss: 1.5162 - val_accuracy: 0.3800\n",
      "Epoch 345/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4154 - accuracy: 0.4800 - val_loss: 1.5150 - val_accuracy: 0.3800\n",
      "Epoch 346/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4139 - accuracy: 0.4829 - val_loss: 1.5139 - val_accuracy: 0.3800\n",
      "Epoch 347/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4124 - accuracy: 0.4814 - val_loss: 1.5123 - val_accuracy: 0.3833\n",
      "Epoch 348/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4111 - accuracy: 0.4814 - val_loss: 1.5112 - val_accuracy: 0.3833\n",
      "Epoch 349/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4095 - accuracy: 0.4800 - val_loss: 1.5102 - val_accuracy: 0.3833\n",
      "Epoch 350/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4083 - accuracy: 0.4829 - val_loss: 1.5088 - val_accuracy: 0.3800\n",
      "Epoch 351/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4067 - accuracy: 0.4886 - val_loss: 1.5076 - val_accuracy: 0.3833\n",
      "Epoch 352/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4054 - accuracy: 0.4829 - val_loss: 1.5061 - val_accuracy: 0.3833\n",
      "Epoch 353/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4040 - accuracy: 0.4786 - val_loss: 1.5049 - val_accuracy: 0.3833\n",
      "Epoch 354/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4027 - accuracy: 0.4886 - val_loss: 1.5039 - val_accuracy: 0.3800\n",
      "Epoch 355/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.4013 - accuracy: 0.4857 - val_loss: 1.5035 - val_accuracy: 0.3733\n",
      "Epoch 356/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4000 - accuracy: 0.4800 - val_loss: 1.5023 - val_accuracy: 0.3733\n",
      "Epoch 357/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3985 - accuracy: 0.4857 - val_loss: 1.5013 - val_accuracy: 0.3733\n",
      "Epoch 358/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.3972 - accuracy: 0.4914 - val_loss: 1.5003 - val_accuracy: 0.3733\n",
      "Epoch 359/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3958 - accuracy: 0.4843 - val_loss: 1.4988 - val_accuracy: 0.3767\n",
      "Epoch 360/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.3945 - accuracy: 0.4814 - val_loss: 1.4977 - val_accuracy: 0.3767\n",
      "Epoch 361/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.3932 - accuracy: 0.4857 - val_loss: 1.4966 - val_accuracy: 0.3767\n",
      "Epoch 362/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.3919 - accuracy: 0.4857 - val_loss: 1.4959 - val_accuracy: 0.3733\n",
      "Epoch 363/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.3905 - accuracy: 0.4929 - val_loss: 1.4946 - val_accuracy: 0.3800\n",
      "Epoch 364/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.3893 - accuracy: 0.4871 - val_loss: 1.4937 - val_accuracy: 0.3767\n",
      "Epoch 365/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.3880 - accuracy: 0.4886 - val_loss: 1.4925 - val_accuracy: 0.3833\n",
      "Epoch 366/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3867 - accuracy: 0.4943 - val_loss: 1.4919 - val_accuracy: 0.3833\n",
      "Epoch 367/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.3854 - accuracy: 0.4929 - val_loss: 1.4907 - val_accuracy: 0.3833\n",
      "Epoch 368/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3841 - accuracy: 0.4943 - val_loss: 1.4897 - val_accuracy: 0.3800\n",
      "Epoch 369/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3829 - accuracy: 0.4900 - val_loss: 1.4888 - val_accuracy: 0.3800\n",
      "Epoch 370/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3815 - accuracy: 0.4929 - val_loss: 1.4878 - val_accuracy: 0.3800\n",
      "Epoch 371/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3803 - accuracy: 0.4886 - val_loss: 1.4868 - val_accuracy: 0.3833\n",
      "Epoch 372/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.3790 - accuracy: 0.4900 - val_loss: 1.4859 - val_accuracy: 0.3833\n",
      "Epoch 373/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3778 - accuracy: 0.4957 - val_loss: 1.4851 - val_accuracy: 0.3833\n",
      "Epoch 374/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.3766 - accuracy: 0.4943 - val_loss: 1.4841 - val_accuracy: 0.3867\n",
      "Epoch 375/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.3752 - accuracy: 0.5014 - val_loss: 1.4836 - val_accuracy: 0.3867\n",
      "Epoch 376/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.3742 - accuracy: 0.4971 - val_loss: 1.4827 - val_accuracy: 0.3833\n",
      "Epoch 377/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.3729 - accuracy: 0.4971 - val_loss: 1.4818 - val_accuracy: 0.3833\n",
      "Epoch 378/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3718 - accuracy: 0.4957 - val_loss: 1.4806 - val_accuracy: 0.3833\n",
      "Epoch 379/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3705 - accuracy: 0.4957 - val_loss: 1.4800 - val_accuracy: 0.3867\n",
      "Epoch 380/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.3694 - accuracy: 0.4986 - val_loss: 1.4789 - val_accuracy: 0.3867\n",
      "Epoch 381/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.3681 - accuracy: 0.5000 - val_loss: 1.4787 - val_accuracy: 0.3867\n",
      "Epoch 382/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.3671 - accuracy: 0.5014 - val_loss: 1.4773 - val_accuracy: 0.3867\n",
      "Epoch 383/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.3658 - accuracy: 0.4986 - val_loss: 1.4761 - val_accuracy: 0.3867\n",
      "Epoch 384/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.3647 - accuracy: 0.4957 - val_loss: 1.4752 - val_accuracy: 0.3933\n",
      "Epoch 385/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.3635 - accuracy: 0.4957 - val_loss: 1.4742 - val_accuracy: 0.3933\n",
      "Epoch 386/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.3625 - accuracy: 0.4957 - val_loss: 1.4730 - val_accuracy: 0.3900\n",
      "Epoch 387/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.3613 - accuracy: 0.4971 - val_loss: 1.4722 - val_accuracy: 0.3933\n",
      "Epoch 388/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3602 - accuracy: 0.4971 - val_loss: 1.4716 - val_accuracy: 0.3967\n",
      "Epoch 389/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3590 - accuracy: 0.4971 - val_loss: 1.4707 - val_accuracy: 0.3967\n",
      "Epoch 390/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.3579 - accuracy: 0.4914 - val_loss: 1.4703 - val_accuracy: 0.3967\n",
      "Epoch 391/3000\n",
      "700/700 [==============================] - 0s 86us/sample - loss: 1.3569 - accuracy: 0.4986 - val_loss: 1.4694 - val_accuracy: 0.3967\n",
      "Epoch 392/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.3556 - accuracy: 0.4943 - val_loss: 1.4686 - val_accuracy: 0.3967\n",
      "Epoch 393/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.3546 - accuracy: 0.4957 - val_loss: 1.4674 - val_accuracy: 0.4000\n",
      "Epoch 394/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.3535 - accuracy: 0.5000 - val_loss: 1.4670 - val_accuracy: 0.4000\n",
      "Epoch 395/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.3525 - accuracy: 0.4943 - val_loss: 1.4662 - val_accuracy: 0.3967\n",
      "Epoch 396/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.3513 - accuracy: 0.4971 - val_loss: 1.4653 - val_accuracy: 0.3967\n",
      "Epoch 397/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3502 - accuracy: 0.4986 - val_loss: 1.4646 - val_accuracy: 0.4000\n",
      "Epoch 398/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.3493 - accuracy: 0.5029 - val_loss: 1.4635 - val_accuracy: 0.4000\n",
      "Epoch 399/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3482 - accuracy: 0.5014 - val_loss: 1.4624 - val_accuracy: 0.3967\n",
      "Epoch 400/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.3472 - accuracy: 0.4986 - val_loss: 1.4616 - val_accuracy: 0.3967\n",
      "Epoch 401/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.3461 - accuracy: 0.5000 - val_loss: 1.4614 - val_accuracy: 0.4000\n",
      "Epoch 402/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3450 - accuracy: 0.5029 - val_loss: 1.4605 - val_accuracy: 0.4000\n",
      "Epoch 403/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3440 - accuracy: 0.4957 - val_loss: 1.4598 - val_accuracy: 0.4000\n",
      "Epoch 404/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.3430 - accuracy: 0.5029 - val_loss: 1.4588 - val_accuracy: 0.4000\n",
      "Epoch 405/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.3419 - accuracy: 0.4971 - val_loss: 1.4583 - val_accuracy: 0.4100\n",
      "Epoch 406/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3410 - accuracy: 0.5014 - val_loss: 1.4577 - val_accuracy: 0.4100\n",
      "Epoch 407/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3400 - accuracy: 0.4957 - val_loss: 1.4574 - val_accuracy: 0.4100\n",
      "Epoch 408/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.3390 - accuracy: 0.4971 - val_loss: 1.4561 - val_accuracy: 0.4133\n",
      "Epoch 409/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.3379 - accuracy: 0.5043 - val_loss: 1.4555 - val_accuracy: 0.4133\n",
      "Epoch 410/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.3370 - accuracy: 0.4957 - val_loss: 1.4542 - val_accuracy: 0.4133\n",
      "Epoch 411/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.3360 - accuracy: 0.4971 - val_loss: 1.4539 - val_accuracy: 0.4167\n",
      "Epoch 412/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.3351 - accuracy: 0.5057 - val_loss: 1.4533 - val_accuracy: 0.4133\n",
      "Epoch 413/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3341 - accuracy: 0.4986 - val_loss: 1.4525 - val_accuracy: 0.4167\n",
      "Epoch 414/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3331 - accuracy: 0.4957 - val_loss: 1.4515 - val_accuracy: 0.4167\n",
      "Epoch 415/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.3321 - accuracy: 0.4957 - val_loss: 1.4506 - val_accuracy: 0.4200\n",
      "Epoch 416/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.3311 - accuracy: 0.5014 - val_loss: 1.4506 - val_accuracy: 0.4200\n",
      "Epoch 417/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3302 - accuracy: 0.4929 - val_loss: 1.4498 - val_accuracy: 0.4200\n",
      "Epoch 418/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.3294 - accuracy: 0.4943 - val_loss: 1.4492 - val_accuracy: 0.4167\n",
      "Epoch 419/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.3283 - accuracy: 0.5029 - val_loss: 1.4480 - val_accuracy: 0.4200\n",
      "Epoch 420/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.3275 - accuracy: 0.5000 - val_loss: 1.4476 - val_accuracy: 0.4200\n",
      "Epoch 421/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3264 - accuracy: 0.5014 - val_loss: 1.4468 - val_accuracy: 0.4233\n",
      "Epoch 422/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.3256 - accuracy: 0.4986 - val_loss: 1.4463 - val_accuracy: 0.4200\n",
      "Epoch 423/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.3244 - accuracy: 0.4986 - val_loss: 1.4452 - val_accuracy: 0.4200\n",
      "Epoch 424/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.3235 - accuracy: 0.5000 - val_loss: 1.4446 - val_accuracy: 0.4200\n",
      "Epoch 425/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.3228 - accuracy: 0.5029 - val_loss: 1.4440 - val_accuracy: 0.4200\n",
      "Epoch 426/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.3217 - accuracy: 0.5014 - val_loss: 1.4432 - val_accuracy: 0.4267\n",
      "Epoch 427/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.3210 - accuracy: 0.4986 - val_loss: 1.4431 - val_accuracy: 0.4267\n",
      "Epoch 428/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.3199 - accuracy: 0.5057 - val_loss: 1.4421 - val_accuracy: 0.4300\n",
      "Epoch 429/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3190 - accuracy: 0.5029 - val_loss: 1.4416 - val_accuracy: 0.4333\n",
      "Epoch 430/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.3181 - accuracy: 0.4986 - val_loss: 1.4407 - val_accuracy: 0.4333\n",
      "Epoch 431/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.3174 - accuracy: 0.5014 - val_loss: 1.4402 - val_accuracy: 0.4333\n",
      "Epoch 432/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.3164 - accuracy: 0.5071 - val_loss: 1.4398 - val_accuracy: 0.4333\n",
      "Epoch 433/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.3156 - accuracy: 0.4971 - val_loss: 1.4392 - val_accuracy: 0.4333\n",
      "Epoch 434/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.3147 - accuracy: 0.5029 - val_loss: 1.4385 - val_accuracy: 0.4333\n",
      "Epoch 435/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.3138 - accuracy: 0.5014 - val_loss: 1.4378 - val_accuracy: 0.4367\n",
      "Epoch 436/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.3128 - accuracy: 0.5000 - val_loss: 1.4374 - val_accuracy: 0.4333\n",
      "Epoch 437/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.3119 - accuracy: 0.4986 - val_loss: 1.4364 - val_accuracy: 0.4333\n",
      "Epoch 438/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3110 - accuracy: 0.5000 - val_loss: 1.4357 - val_accuracy: 0.4333\n",
      "Epoch 439/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.3102 - accuracy: 0.5029 - val_loss: 1.4351 - val_accuracy: 0.4300\n",
      "Epoch 440/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.3094 - accuracy: 0.5029 - val_loss: 1.4346 - val_accuracy: 0.4333\n",
      "Epoch 441/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.3084 - accuracy: 0.5014 - val_loss: 1.4340 - val_accuracy: 0.4333\n",
      "Epoch 442/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.3076 - accuracy: 0.5014 - val_loss: 1.4332 - val_accuracy: 0.4333\n",
      "Epoch 443/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.3068 - accuracy: 0.5071 - val_loss: 1.4331 - val_accuracy: 0.4300\n",
      "Epoch 444/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.3061 - accuracy: 0.5029 - val_loss: 1.4322 - val_accuracy: 0.4300\n",
      "Epoch 445/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.3051 - accuracy: 0.5071 - val_loss: 1.4317 - val_accuracy: 0.4300\n",
      "Epoch 446/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.3043 - accuracy: 0.5043 - val_loss: 1.4313 - val_accuracy: 0.4267\n",
      "Epoch 447/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.3035 - accuracy: 0.5086 - val_loss: 1.4304 - val_accuracy: 0.4300\n",
      "Epoch 448/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.3027 - accuracy: 0.5029 - val_loss: 1.4296 - val_accuracy: 0.4300\n",
      "Epoch 449/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.3018 - accuracy: 0.5086 - val_loss: 1.4294 - val_accuracy: 0.4233\n",
      "Epoch 450/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.3010 - accuracy: 0.5100 - val_loss: 1.4287 - val_accuracy: 0.4200\n",
      "Epoch 451/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3002 - accuracy: 0.5143 - val_loss: 1.4282 - val_accuracy: 0.4200\n",
      "Epoch 452/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2994 - accuracy: 0.5071 - val_loss: 1.4276 - val_accuracy: 0.4200\n",
      "Epoch 453/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2984 - accuracy: 0.5129 - val_loss: 1.4275 - val_accuracy: 0.4267\n",
      "Epoch 454/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.2978 - accuracy: 0.5100 - val_loss: 1.4266 - val_accuracy: 0.4233\n",
      "Epoch 455/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2970 - accuracy: 0.5100 - val_loss: 1.4260 - val_accuracy: 0.4233\n",
      "Epoch 456/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2963 - accuracy: 0.5114 - val_loss: 1.4255 - val_accuracy: 0.4233\n",
      "Epoch 457/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.2954 - accuracy: 0.5157 - val_loss: 1.4254 - val_accuracy: 0.4267\n",
      "Epoch 458/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.2946 - accuracy: 0.5129 - val_loss: 1.4246 - val_accuracy: 0.4267\n",
      "Epoch 459/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2938 - accuracy: 0.5114 - val_loss: 1.4239 - val_accuracy: 0.4267\n",
      "Epoch 460/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2931 - accuracy: 0.5143 - val_loss: 1.4234 - val_accuracy: 0.4267\n",
      "Epoch 461/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.2922 - accuracy: 0.5114 - val_loss: 1.4236 - val_accuracy: 0.4267\n",
      "Epoch 462/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2916 - accuracy: 0.5157 - val_loss: 1.4228 - val_accuracy: 0.4300\n",
      "Epoch 463/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2907 - accuracy: 0.5171 - val_loss: 1.4219 - val_accuracy: 0.4267\n",
      "Epoch 464/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2899 - accuracy: 0.5157 - val_loss: 1.4209 - val_accuracy: 0.4267\n",
      "Epoch 465/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.2894 - accuracy: 0.5129 - val_loss: 1.4209 - val_accuracy: 0.4300\n",
      "Epoch 466/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.2884 - accuracy: 0.5143 - val_loss: 1.4208 - val_accuracy: 0.4267\n",
      "Epoch 467/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2877 - accuracy: 0.5114 - val_loss: 1.4204 - val_accuracy: 0.4267\n",
      "Epoch 468/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2869 - accuracy: 0.5200 - val_loss: 1.4193 - val_accuracy: 0.4300\n",
      "Epoch 469/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.2861 - accuracy: 0.5114 - val_loss: 1.4190 - val_accuracy: 0.4300\n",
      "Epoch 470/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2855 - accuracy: 0.5243 - val_loss: 1.4182 - val_accuracy: 0.4233\n",
      "Epoch 471/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2847 - accuracy: 0.5114 - val_loss: 1.4180 - val_accuracy: 0.4267\n",
      "Epoch 472/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2839 - accuracy: 0.5143 - val_loss: 1.4174 - val_accuracy: 0.4267\n",
      "Epoch 473/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.2831 - accuracy: 0.5243 - val_loss: 1.4166 - val_accuracy: 0.4267\n",
      "Epoch 474/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2824 - accuracy: 0.5171 - val_loss: 1.4160 - val_accuracy: 0.4267\n",
      "Epoch 475/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2817 - accuracy: 0.5143 - val_loss: 1.4160 - val_accuracy: 0.4267\n",
      "Epoch 476/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2809 - accuracy: 0.5157 - val_loss: 1.4161 - val_accuracy: 0.4300\n",
      "Epoch 477/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2801 - accuracy: 0.5200 - val_loss: 1.4154 - val_accuracy: 0.4300\n",
      "Epoch 478/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2793 - accuracy: 0.5186 - val_loss: 1.4141 - val_accuracy: 0.4300\n",
      "Epoch 479/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2788 - accuracy: 0.5186 - val_loss: 1.4137 - val_accuracy: 0.4300\n",
      "Epoch 480/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2780 - accuracy: 0.5214 - val_loss: 1.4135 - val_accuracy: 0.4333\n",
      "Epoch 481/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2774 - accuracy: 0.5229 - val_loss: 1.4130 - val_accuracy: 0.4333\n",
      "Epoch 482/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.2765 - accuracy: 0.5229 - val_loss: 1.4121 - val_accuracy: 0.4367\n",
      "Epoch 483/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2758 - accuracy: 0.5214 - val_loss: 1.4117 - val_accuracy: 0.4333\n",
      "Epoch 484/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2751 - accuracy: 0.5186 - val_loss: 1.4118 - val_accuracy: 0.4333\n",
      "Epoch 485/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.2744 - accuracy: 0.5243 - val_loss: 1.4109 - val_accuracy: 0.4300\n",
      "Epoch 486/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.2737 - accuracy: 0.5171 - val_loss: 1.4108 - val_accuracy: 0.4300\n",
      "Epoch 487/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.2730 - accuracy: 0.5214 - val_loss: 1.4098 - val_accuracy: 0.4300\n",
      "Epoch 488/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2723 - accuracy: 0.5314 - val_loss: 1.4099 - val_accuracy: 0.4333\n",
      "Epoch 489/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2716 - accuracy: 0.5214 - val_loss: 1.4089 - val_accuracy: 0.4367\n",
      "Epoch 490/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2709 - accuracy: 0.5186 - val_loss: 1.4084 - val_accuracy: 0.4367\n",
      "Epoch 491/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.2703 - accuracy: 0.5214 - val_loss: 1.4079 - val_accuracy: 0.4333\n",
      "Epoch 492/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.2696 - accuracy: 0.5243 - val_loss: 1.4073 - val_accuracy: 0.4333\n",
      "Epoch 493/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.2688 - accuracy: 0.5257 - val_loss: 1.4074 - val_accuracy: 0.4333\n",
      "Epoch 494/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2683 - accuracy: 0.5229 - val_loss: 1.4071 - val_accuracy: 0.4267\n",
      "Epoch 495/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2675 - accuracy: 0.5200 - val_loss: 1.4066 - val_accuracy: 0.4267\n",
      "Epoch 496/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2668 - accuracy: 0.5243 - val_loss: 1.4062 - val_accuracy: 0.4267\n",
      "Epoch 497/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.2661 - accuracy: 0.5271 - val_loss: 1.4052 - val_accuracy: 0.4333\n",
      "Epoch 498/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.2654 - accuracy: 0.5243 - val_loss: 1.4054 - val_accuracy: 0.4300\n",
      "Epoch 499/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2648 - accuracy: 0.5243 - val_loss: 1.4048 - val_accuracy: 0.4300\n",
      "Epoch 500/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2641 - accuracy: 0.5271 - val_loss: 1.4044 - val_accuracy: 0.4300\n",
      "Epoch 501/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2634 - accuracy: 0.5243 - val_loss: 1.4039 - val_accuracy: 0.4300\n",
      "Epoch 502/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2627 - accuracy: 0.5271 - val_loss: 1.4033 - val_accuracy: 0.4300\n",
      "Epoch 503/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2619 - accuracy: 0.5300 - val_loss: 1.4034 - val_accuracy: 0.4300\n",
      "Epoch 504/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2614 - accuracy: 0.5257 - val_loss: 1.4026 - val_accuracy: 0.4300\n",
      "Epoch 505/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2609 - accuracy: 0.5286 - val_loss: 1.4023 - val_accuracy: 0.4300\n",
      "Epoch 506/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2602 - accuracy: 0.5271 - val_loss: 1.4022 - val_accuracy: 0.4300\n",
      "Epoch 507/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.2596 - accuracy: 0.5243 - val_loss: 1.4015 - val_accuracy: 0.4300\n",
      "Epoch 508/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2588 - accuracy: 0.5329 - val_loss: 1.4010 - val_accuracy: 0.4300\n",
      "Epoch 509/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2583 - accuracy: 0.5329 - val_loss: 1.4004 - val_accuracy: 0.4300\n",
      "Epoch 510/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2575 - accuracy: 0.5271 - val_loss: 1.3997 - val_accuracy: 0.4300\n",
      "Epoch 511/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2569 - accuracy: 0.5314 - val_loss: 1.3997 - val_accuracy: 0.4300\n",
      "Epoch 512/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.2563 - accuracy: 0.5314 - val_loss: 1.3996 - val_accuracy: 0.4300\n",
      "Epoch 513/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.2556 - accuracy: 0.5357 - val_loss: 1.3989 - val_accuracy: 0.4267\n",
      "Epoch 514/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.2550 - accuracy: 0.5257 - val_loss: 1.3981 - val_accuracy: 0.4300\n",
      "Epoch 515/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2543 - accuracy: 0.5314 - val_loss: 1.3987 - val_accuracy: 0.4300\n",
      "Epoch 516/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.2538 - accuracy: 0.5314 - val_loss: 1.3981 - val_accuracy: 0.4333\n",
      "Epoch 517/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2531 - accuracy: 0.5314 - val_loss: 1.3976 - val_accuracy: 0.4333\n",
      "Epoch 518/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2525 - accuracy: 0.5300 - val_loss: 1.3971 - val_accuracy: 0.4333\n",
      "Epoch 519/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2517 - accuracy: 0.5414 - val_loss: 1.3974 - val_accuracy: 0.4333\n",
      "Epoch 520/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2513 - accuracy: 0.5343 - val_loss: 1.3969 - val_accuracy: 0.4333\n",
      "Epoch 521/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2507 - accuracy: 0.5371 - val_loss: 1.3960 - val_accuracy: 0.4333\n",
      "Epoch 522/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2499 - accuracy: 0.5343 - val_loss: 1.3955 - val_accuracy: 0.4333\n",
      "Epoch 523/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2494 - accuracy: 0.5386 - val_loss: 1.3956 - val_accuracy: 0.4333\n",
      "Epoch 524/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2488 - accuracy: 0.5400 - val_loss: 1.3951 - val_accuracy: 0.4333\n",
      "Epoch 525/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2482 - accuracy: 0.5386 - val_loss: 1.3949 - val_accuracy: 0.4333\n",
      "Epoch 526/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2476 - accuracy: 0.5400 - val_loss: 1.3942 - val_accuracy: 0.4400\n",
      "Epoch 527/3000\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 1.2470 - accuracy: 0.5386 - val_loss: 1.3935 - val_accuracy: 0.4433\n",
      "Epoch 528/3000\n",
      "700/700 [==============================] - 0s 87us/sample - loss: 1.2462 - accuracy: 0.5386 - val_loss: 1.3943 - val_accuracy: 0.4300\n",
      "Epoch 529/3000\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 1.2456 - accuracy: 0.5429 - val_loss: 1.3930 - val_accuracy: 0.4400\n",
      "Epoch 530/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.2450 - accuracy: 0.5386 - val_loss: 1.3927 - val_accuracy: 0.4400\n",
      "Epoch 531/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.2446 - accuracy: 0.5371 - val_loss: 1.3923 - val_accuracy: 0.4433\n",
      "Epoch 532/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.2440 - accuracy: 0.5386 - val_loss: 1.3922 - val_accuracy: 0.4433\n",
      "Epoch 533/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2434 - accuracy: 0.5371 - val_loss: 1.3921 - val_accuracy: 0.4433\n",
      "Epoch 534/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2427 - accuracy: 0.5429 - val_loss: 1.3913 - val_accuracy: 0.4433\n",
      "Epoch 535/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2422 - accuracy: 0.5414 - val_loss: 1.3912 - val_accuracy: 0.4433\n",
      "Epoch 536/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2415 - accuracy: 0.5429 - val_loss: 1.3906 - val_accuracy: 0.4433\n",
      "Epoch 537/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2409 - accuracy: 0.5357 - val_loss: 1.3904 - val_accuracy: 0.4400\n",
      "Epoch 538/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2403 - accuracy: 0.5400 - val_loss: 1.3906 - val_accuracy: 0.4433\n",
      "Epoch 539/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2399 - accuracy: 0.5400 - val_loss: 1.3897 - val_accuracy: 0.4433\n",
      "Epoch 540/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2392 - accuracy: 0.5400 - val_loss: 1.3895 - val_accuracy: 0.4433\n",
      "Epoch 541/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2386 - accuracy: 0.5371 - val_loss: 1.3890 - val_accuracy: 0.4433\n",
      "Epoch 542/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2382 - accuracy: 0.5429 - val_loss: 1.3887 - val_accuracy: 0.4433\n",
      "Epoch 543/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2375 - accuracy: 0.5443 - val_loss: 1.3884 - val_accuracy: 0.4367\n",
      "Epoch 544/3000\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 1.2370 - accuracy: 0.5400 - val_loss: 1.3879 - val_accuracy: 0.4367\n",
      "Epoch 545/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.2363 - accuracy: 0.5414 - val_loss: 1.3875 - val_accuracy: 0.4333\n",
      "Epoch 546/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2358 - accuracy: 0.5400 - val_loss: 1.3870 - val_accuracy: 0.4367\n",
      "Epoch 547/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2354 - accuracy: 0.5429 - val_loss: 1.3872 - val_accuracy: 0.4333\n",
      "Epoch 548/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2346 - accuracy: 0.5443 - val_loss: 1.3872 - val_accuracy: 0.4400\n",
      "Epoch 549/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2340 - accuracy: 0.5386 - val_loss: 1.3864 - val_accuracy: 0.4333\n",
      "Epoch 550/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.2336 - accuracy: 0.5400 - val_loss: 1.3858 - val_accuracy: 0.4333\n",
      "Epoch 551/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.2330 - accuracy: 0.5414 - val_loss: 1.3858 - val_accuracy: 0.4367\n",
      "Epoch 552/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.2324 - accuracy: 0.5414 - val_loss: 1.3853 - val_accuracy: 0.4367\n",
      "Epoch 553/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.2318 - accuracy: 0.5443 - val_loss: 1.3848 - val_accuracy: 0.4333\n",
      "Epoch 554/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2314 - accuracy: 0.5400 - val_loss: 1.3848 - val_accuracy: 0.4367\n",
      "Epoch 555/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2307 - accuracy: 0.5400 - val_loss: 1.3846 - val_accuracy: 0.4367\n",
      "Epoch 556/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2303 - accuracy: 0.5414 - val_loss: 1.3842 - val_accuracy: 0.4367\n",
      "Epoch 557/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2295 - accuracy: 0.5414 - val_loss: 1.3842 - val_accuracy: 0.4400\n",
      "Epoch 558/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2290 - accuracy: 0.5400 - val_loss: 1.3840 - val_accuracy: 0.4433\n",
      "Epoch 559/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2284 - accuracy: 0.5414 - val_loss: 1.3836 - val_accuracy: 0.4400\n",
      "Epoch 560/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2279 - accuracy: 0.5414 - val_loss: 1.3838 - val_accuracy: 0.4433\n",
      "Epoch 561/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2275 - accuracy: 0.5429 - val_loss: 1.3835 - val_accuracy: 0.4433\n",
      "Epoch 562/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2267 - accuracy: 0.5400 - val_loss: 1.3823 - val_accuracy: 0.4467\n",
      "Epoch 563/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.2263 - accuracy: 0.5471 - val_loss: 1.3819 - val_accuracy: 0.4467\n",
      "Epoch 564/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.2258 - accuracy: 0.5514 - val_loss: 1.3815 - val_accuracy: 0.4467\n",
      "Epoch 565/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2254 - accuracy: 0.5471 - val_loss: 1.3811 - val_accuracy: 0.4467\n",
      "Epoch 566/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.2249 - accuracy: 0.5414 - val_loss: 1.3816 - val_accuracy: 0.4467\n",
      "Epoch 567/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2242 - accuracy: 0.5429 - val_loss: 1.3815 - val_accuracy: 0.4467\n",
      "Epoch 568/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2237 - accuracy: 0.5457 - val_loss: 1.3815 - val_accuracy: 0.4467\n",
      "Epoch 569/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2232 - accuracy: 0.5500 - val_loss: 1.3808 - val_accuracy: 0.4500\n",
      "Epoch 570/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2227 - accuracy: 0.5457 - val_loss: 1.3800 - val_accuracy: 0.4500\n",
      "Epoch 571/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2220 - accuracy: 0.5471 - val_loss: 1.3792 - val_accuracy: 0.4467\n",
      "Epoch 572/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.2217 - accuracy: 0.5429 - val_loss: 1.3793 - val_accuracy: 0.4500\n",
      "Epoch 573/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2210 - accuracy: 0.5414 - val_loss: 1.3793 - val_accuracy: 0.4467\n",
      "Epoch 574/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2205 - accuracy: 0.5457 - val_loss: 1.3791 - val_accuracy: 0.4467\n",
      "Epoch 575/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.2201 - accuracy: 0.5429 - val_loss: 1.3791 - val_accuracy: 0.4500\n",
      "Epoch 576/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2195 - accuracy: 0.5471 - val_loss: 1.3791 - val_accuracy: 0.4500\n",
      "Epoch 577/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2190 - accuracy: 0.5486 - val_loss: 1.3787 - val_accuracy: 0.4500\n",
      "Epoch 578/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.2185 - accuracy: 0.5400 - val_loss: 1.3784 - val_accuracy: 0.4533\n",
      "Epoch 579/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.2180 - accuracy: 0.5443 - val_loss: 1.3778 - val_accuracy: 0.4533\n",
      "Epoch 580/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.2174 - accuracy: 0.5429 - val_loss: 1.3778 - val_accuracy: 0.4533\n",
      "Epoch 581/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2169 - accuracy: 0.5457 - val_loss: 1.3778 - val_accuracy: 0.4533\n",
      "Epoch 582/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.2164 - accuracy: 0.5486 - val_loss: 1.3777 - val_accuracy: 0.4533\n",
      "Epoch 583/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2160 - accuracy: 0.5529 - val_loss: 1.3768 - val_accuracy: 0.4533\n",
      "Epoch 584/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.2155 - accuracy: 0.5486 - val_loss: 1.3767 - val_accuracy: 0.4533\n",
      "Epoch 585/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.2149 - accuracy: 0.5514 - val_loss: 1.3760 - val_accuracy: 0.4533\n",
      "Epoch 586/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.2144 - accuracy: 0.5429 - val_loss: 1.3759 - val_accuracy: 0.4533\n",
      "Epoch 587/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.2140 - accuracy: 0.5457 - val_loss: 1.3760 - val_accuracy: 0.4533\n",
      "Epoch 588/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2133 - accuracy: 0.5514 - val_loss: 1.3750 - val_accuracy: 0.4533\n",
      "Epoch 589/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2129 - accuracy: 0.5500 - val_loss: 1.3755 - val_accuracy: 0.4533\n",
      "Epoch 590/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2124 - accuracy: 0.5486 - val_loss: 1.3755 - val_accuracy: 0.4533\n",
      "Epoch 591/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2120 - accuracy: 0.5500 - val_loss: 1.3754 - val_accuracy: 0.4500\n",
      "Epoch 592/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.2115 - accuracy: 0.5557 - val_loss: 1.3750 - val_accuracy: 0.4500\n",
      "Epoch 593/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.2110 - accuracy: 0.5457 - val_loss: 1.3746 - val_accuracy: 0.4533\n",
      "Epoch 594/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2105 - accuracy: 0.5500 - val_loss: 1.3744 - val_accuracy: 0.4567\n",
      "Epoch 595/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2101 - accuracy: 0.5471 - val_loss: 1.3738 - val_accuracy: 0.4567\n",
      "Epoch 596/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2095 - accuracy: 0.5543 - val_loss: 1.3732 - val_accuracy: 0.4567\n",
      "Epoch 597/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2090 - accuracy: 0.5529 - val_loss: 1.3731 - val_accuracy: 0.4533\n",
      "Epoch 598/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2086 - accuracy: 0.5514 - val_loss: 1.3732 - val_accuracy: 0.4567\n",
      "Epoch 599/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2081 - accuracy: 0.5471 - val_loss: 1.3730 - val_accuracy: 0.4533\n",
      "Epoch 600/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2075 - accuracy: 0.5571 - val_loss: 1.3727 - val_accuracy: 0.4533\n",
      "Epoch 601/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.2072 - accuracy: 0.5471 - val_loss: 1.3722 - val_accuracy: 0.4533\n",
      "Epoch 602/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.2068 - accuracy: 0.5557 - val_loss: 1.3720 - val_accuracy: 0.4500\n",
      "Epoch 603/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2061 - accuracy: 0.5486 - val_loss: 1.3713 - val_accuracy: 0.4533\n",
      "Epoch 604/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2057 - accuracy: 0.5486 - val_loss: 1.3722 - val_accuracy: 0.4500\n",
      "Epoch 605/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2052 - accuracy: 0.5571 - val_loss: 1.3715 - val_accuracy: 0.4533\n",
      "Epoch 606/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.2047 - accuracy: 0.5571 - val_loss: 1.3710 - val_accuracy: 0.4533\n",
      "Epoch 607/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2042 - accuracy: 0.5514 - val_loss: 1.3711 - val_accuracy: 0.4567\n",
      "Epoch 608/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2037 - accuracy: 0.5543 - val_loss: 1.3713 - val_accuracy: 0.4567\n",
      "Epoch 609/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2032 - accuracy: 0.5529 - val_loss: 1.3715 - val_accuracy: 0.4567\n",
      "Epoch 610/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2028 - accuracy: 0.5586 - val_loss: 1.3703 - val_accuracy: 0.4533\n",
      "Epoch 611/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2024 - accuracy: 0.5529 - val_loss: 1.3700 - val_accuracy: 0.4533\n",
      "Epoch 612/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2019 - accuracy: 0.5586 - val_loss: 1.3701 - val_accuracy: 0.4533\n",
      "Epoch 613/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2014 - accuracy: 0.5586 - val_loss: 1.3696 - val_accuracy: 0.4533\n",
      "Epoch 614/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.2010 - accuracy: 0.5557 - val_loss: 1.3694 - val_accuracy: 0.4533\n",
      "Epoch 615/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.2007 - accuracy: 0.5557 - val_loss: 1.3687 - val_accuracy: 0.4533\n",
      "Epoch 616/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2000 - accuracy: 0.5600 - val_loss: 1.3688 - val_accuracy: 0.4533\n",
      "Epoch 617/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.1995 - accuracy: 0.5557 - val_loss: 1.3694 - val_accuracy: 0.4500\n",
      "Epoch 618/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.1991 - accuracy: 0.5600 - val_loss: 1.3688 - val_accuracy: 0.4500\n",
      "Epoch 619/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1987 - accuracy: 0.5671 - val_loss: 1.3680 - val_accuracy: 0.4467\n",
      "Epoch 620/3000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 1.1982 - accuracy: 0.5600 - val_loss: 1.3680 - val_accuracy: 0.4467\n",
      "Epoch 621/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.1977 - accuracy: 0.5600 - val_loss: 1.3676 - val_accuracy: 0.4467\n",
      "Epoch 622/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1973 - accuracy: 0.5571 - val_loss: 1.3671 - val_accuracy: 0.4467\n",
      "Epoch 623/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1970 - accuracy: 0.5571 - val_loss: 1.3671 - val_accuracy: 0.4467\n",
      "Epoch 624/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1964 - accuracy: 0.5629 - val_loss: 1.3662 - val_accuracy: 0.4467\n",
      "Epoch 625/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1960 - accuracy: 0.5586 - val_loss: 1.3660 - val_accuracy: 0.4467\n",
      "Epoch 626/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.1956 - accuracy: 0.5571 - val_loss: 1.3661 - val_accuracy: 0.4467\n",
      "Epoch 627/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1950 - accuracy: 0.5586 - val_loss: 1.3661 - val_accuracy: 0.4500\n",
      "Epoch 628/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1948 - accuracy: 0.5614 - val_loss: 1.3656 - val_accuracy: 0.4467\n",
      "Epoch 629/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1941 - accuracy: 0.5614 - val_loss: 1.3661 - val_accuracy: 0.4467\n",
      "Epoch 630/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1937 - accuracy: 0.5600 - val_loss: 1.3661 - val_accuracy: 0.4467\n",
      "Epoch 631/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1933 - accuracy: 0.5600 - val_loss: 1.3654 - val_accuracy: 0.4467\n",
      "Epoch 632/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1929 - accuracy: 0.5600 - val_loss: 1.3653 - val_accuracy: 0.4467\n",
      "Epoch 633/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1924 - accuracy: 0.5571 - val_loss: 1.3653 - val_accuracy: 0.4467\n",
      "Epoch 634/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.1921 - accuracy: 0.5600 - val_loss: 1.3648 - val_accuracy: 0.4467\n",
      "Epoch 635/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.1914 - accuracy: 0.5629 - val_loss: 1.3646 - val_accuracy: 0.4467\n",
      "Epoch 636/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1911 - accuracy: 0.5586 - val_loss: 1.3641 - val_accuracy: 0.4467\n",
      "Epoch 637/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.1908 - accuracy: 0.5614 - val_loss: 1.3641 - val_accuracy: 0.4467\n",
      "Epoch 638/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.1902 - accuracy: 0.5671 - val_loss: 1.3633 - val_accuracy: 0.4467\n",
      "Epoch 639/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.1898 - accuracy: 0.5586 - val_loss: 1.3633 - val_accuracy: 0.4467\n",
      "Epoch 640/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.1894 - accuracy: 0.5629 - val_loss: 1.3635 - val_accuracy: 0.4467\n",
      "Epoch 641/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1890 - accuracy: 0.5629 - val_loss: 1.3630 - val_accuracy: 0.4467\n",
      "Epoch 642/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.1886 - accuracy: 0.5600 - val_loss: 1.3625 - val_accuracy: 0.4467\n",
      "Epoch 643/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1880 - accuracy: 0.5671 - val_loss: 1.3624 - val_accuracy: 0.4467\n",
      "Epoch 644/3000\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 1.1877 - accuracy: 0.5614 - val_loss: 1.3622 - val_accuracy: 0.4467\n",
      "Epoch 645/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.1872 - accuracy: 0.5571 - val_loss: 1.3627 - val_accuracy: 0.4467\n",
      "Epoch 646/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1868 - accuracy: 0.5571 - val_loss: 1.3621 - val_accuracy: 0.4467\n",
      "Epoch 647/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.1864 - accuracy: 0.5600 - val_loss: 1.3619 - val_accuracy: 0.4500\n",
      "Epoch 648/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1859 - accuracy: 0.5614 - val_loss: 1.3616 - val_accuracy: 0.4500\n",
      "Epoch 649/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.1854 - accuracy: 0.5557 - val_loss: 1.3616 - val_accuracy: 0.4500\n",
      "Epoch 650/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.1852 - accuracy: 0.5629 - val_loss: 1.3611 - val_accuracy: 0.4533\n",
      "Epoch 651/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1848 - accuracy: 0.5657 - val_loss: 1.3608 - val_accuracy: 0.4533\n",
      "Epoch 652/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.1844 - accuracy: 0.5671 - val_loss: 1.3606 - val_accuracy: 0.4500\n",
      "Epoch 653/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.1839 - accuracy: 0.5586 - val_loss: 1.3603 - val_accuracy: 0.4533\n",
      "Epoch 654/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.1835 - accuracy: 0.5614 - val_loss: 1.3604 - val_accuracy: 0.4533\n",
      "Epoch 655/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.1832 - accuracy: 0.5629 - val_loss: 1.3600 - val_accuracy: 0.4500\n",
      "Epoch 656/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.1826 - accuracy: 0.5671 - val_loss: 1.3588 - val_accuracy: 0.4500\n",
      "Epoch 657/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.1822 - accuracy: 0.5614 - val_loss: 1.3582 - val_accuracy: 0.4500\n",
      "Epoch 658/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.1819 - accuracy: 0.5614 - val_loss: 1.3590 - val_accuracy: 0.4500\n",
      "Epoch 659/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1814 - accuracy: 0.5643 - val_loss: 1.3589 - val_accuracy: 0.4500\n",
      "Epoch 660/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1810 - accuracy: 0.5629 - val_loss: 1.3586 - val_accuracy: 0.4500\n",
      "Epoch 661/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1805 - accuracy: 0.5643 - val_loss: 1.3590 - val_accuracy: 0.4500\n",
      "Epoch 662/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.1801 - accuracy: 0.5629 - val_loss: 1.3583 - val_accuracy: 0.4533\n",
      "Epoch 663/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.1797 - accuracy: 0.5657 - val_loss: 1.3585 - val_accuracy: 0.4533\n",
      "Epoch 664/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.1795 - accuracy: 0.5614 - val_loss: 1.3586 - val_accuracy: 0.4533\n",
      "Epoch 665/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.1790 - accuracy: 0.5671 - val_loss: 1.3578 - val_accuracy: 0.4533\n",
      "Epoch 666/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.1786 - accuracy: 0.5686 - val_loss: 1.3576 - val_accuracy: 0.4533\n",
      "Epoch 667/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1782 - accuracy: 0.5629 - val_loss: 1.3580 - val_accuracy: 0.4533\n",
      "Epoch 668/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1778 - accuracy: 0.5657 - val_loss: 1.3577 - val_accuracy: 0.4533\n",
      "Epoch 669/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1772 - accuracy: 0.5629 - val_loss: 1.3576 - val_accuracy: 0.4533\n",
      "Epoch 670/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1769 - accuracy: 0.5657 - val_loss: 1.3574 - val_accuracy: 0.4533\n",
      "Epoch 671/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1766 - accuracy: 0.5629 - val_loss: 1.3573 - val_accuracy: 0.4533\n",
      "Epoch 672/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1760 - accuracy: 0.5629 - val_loss: 1.3578 - val_accuracy: 0.4533\n",
      "Epoch 673/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1757 - accuracy: 0.5614 - val_loss: 1.3577 - val_accuracy: 0.4533\n",
      "Epoch 674/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1753 - accuracy: 0.5671 - val_loss: 1.3570 - val_accuracy: 0.4533\n",
      "Epoch 675/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1750 - accuracy: 0.5700 - val_loss: 1.3571 - val_accuracy: 0.4533\n",
      "Epoch 676/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.1746 - accuracy: 0.5671 - val_loss: 1.3566 - val_accuracy: 0.4533\n",
      "Epoch 677/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.1742 - accuracy: 0.5629 - val_loss: 1.3569 - val_accuracy: 0.4533\n",
      "Epoch 678/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.1739 - accuracy: 0.5686 - val_loss: 1.3558 - val_accuracy: 0.4533\n",
      "Epoch 679/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1734 - accuracy: 0.5686 - val_loss: 1.3554 - val_accuracy: 0.4533\n",
      "Epoch 680/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.1729 - accuracy: 0.5686 - val_loss: 1.3558 - val_accuracy: 0.4533\n",
      "Epoch 681/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1727 - accuracy: 0.5657 - val_loss: 1.3554 - val_accuracy: 0.4533\n",
      "Epoch 682/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.1721 - accuracy: 0.5671 - val_loss: 1.3558 - val_accuracy: 0.4533\n",
      "Epoch 683/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1719 - accuracy: 0.5629 - val_loss: 1.3552 - val_accuracy: 0.4533\n",
      "Epoch 684/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.1715 - accuracy: 0.5643 - val_loss: 1.3549 - val_accuracy: 0.4500\n",
      "Epoch 685/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.1711 - accuracy: 0.5643 - val_loss: 1.3552 - val_accuracy: 0.4500\n",
      "Epoch 686/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.1705 - accuracy: 0.5657 - val_loss: 1.3544 - val_accuracy: 0.4500\n",
      "Epoch 687/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.1704 - accuracy: 0.5657 - val_loss: 1.3535 - val_accuracy: 0.4500\n",
      "Epoch 688/3000\n",
      "700/700 [==============================] - 0s 115us/sample - loss: 1.1699 - accuracy: 0.5714 - val_loss: 1.3541 - val_accuracy: 0.4500\n",
      "Epoch 689/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1694 - accuracy: 0.5657 - val_loss: 1.3544 - val_accuracy: 0.4500\n",
      "Epoch 690/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1692 - accuracy: 0.5657 - val_loss: 1.3543 - val_accuracy: 0.4500\n",
      "Epoch 691/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 1.1688 - accuracy: 0.5700 - val_loss: 1.3539 - val_accuracy: 0.4500\n",
      "Epoch 692/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1684 - accuracy: 0.5614 - val_loss: 1.3538 - val_accuracy: 0.4500\n",
      "Epoch 693/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.1680 - accuracy: 0.5714 - val_loss: 1.3535 - val_accuracy: 0.4500\n",
      "Epoch 694/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.1677 - accuracy: 0.5686 - val_loss: 1.3533 - val_accuracy: 0.4500\n",
      "Epoch 695/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.1672 - accuracy: 0.5614 - val_loss: 1.3534 - val_accuracy: 0.4500\n",
      "Epoch 696/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1668 - accuracy: 0.5671 - val_loss: 1.3533 - val_accuracy: 0.4500\n",
      "Epoch 697/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1664 - accuracy: 0.5714 - val_loss: 1.3532 - val_accuracy: 0.4500\n",
      "Epoch 698/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.1661 - accuracy: 0.5643 - val_loss: 1.3528 - val_accuracy: 0.4500\n",
      "Epoch 699/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.1657 - accuracy: 0.5686 - val_loss: 1.3521 - val_accuracy: 0.4500\n",
      "Epoch 700/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.1655 - accuracy: 0.5686 - val_loss: 1.3525 - val_accuracy: 0.4500\n",
      "Epoch 701/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.1651 - accuracy: 0.5686 - val_loss: 1.3520 - val_accuracy: 0.4500\n",
      "Epoch 702/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1646 - accuracy: 0.5657 - val_loss: 1.3516 - val_accuracy: 0.4500\n",
      "Epoch 703/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1641 - accuracy: 0.5686 - val_loss: 1.3512 - val_accuracy: 0.4500\n",
      "Epoch 704/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.1640 - accuracy: 0.5629 - val_loss: 1.3514 - val_accuracy: 0.4500\n",
      "Epoch 705/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1636 - accuracy: 0.5700 - val_loss: 1.3513 - val_accuracy: 0.4500\n",
      "Epoch 706/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1632 - accuracy: 0.5700 - val_loss: 1.3515 - val_accuracy: 0.4500\n",
      "Epoch 707/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1628 - accuracy: 0.5700 - val_loss: 1.3523 - val_accuracy: 0.4500\n",
      "Epoch 708/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.1625 - accuracy: 0.5700 - val_loss: 1.3517 - val_accuracy: 0.4500\n",
      "Epoch 709/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.1620 - accuracy: 0.5686 - val_loss: 1.3516 - val_accuracy: 0.4467\n",
      "Epoch 710/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1617 - accuracy: 0.5700 - val_loss: 1.3514 - val_accuracy: 0.4533\n",
      "Epoch 711/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1614 - accuracy: 0.5729 - val_loss: 1.3512 - val_accuracy: 0.4533\n",
      "Epoch 712/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1610 - accuracy: 0.5671 - val_loss: 1.3517 - val_accuracy: 0.4533\n",
      "Epoch 713/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1606 - accuracy: 0.5657 - val_loss: 1.3512 - val_accuracy: 0.4533\n",
      "Epoch 714/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1603 - accuracy: 0.5686 - val_loss: 1.3513 - val_accuracy: 0.4533\n",
      "Epoch 715/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1599 - accuracy: 0.5657 - val_loss: 1.3504 - val_accuracy: 0.4533\n",
      "Epoch 716/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1596 - accuracy: 0.5729 - val_loss: 1.3499 - val_accuracy: 0.4533\n",
      "Epoch 717/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1592 - accuracy: 0.5643 - val_loss: 1.3495 - val_accuracy: 0.4533\n",
      "Epoch 718/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1588 - accuracy: 0.5700 - val_loss: 1.3497 - val_accuracy: 0.4533\n",
      "Epoch 719/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1584 - accuracy: 0.5700 - val_loss: 1.3490 - val_accuracy: 0.4600\n",
      "Epoch 720/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1581 - accuracy: 0.5714 - val_loss: 1.3500 - val_accuracy: 0.4533\n",
      "Epoch 721/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1576 - accuracy: 0.5714 - val_loss: 1.3492 - val_accuracy: 0.4533\n",
      "Epoch 722/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1574 - accuracy: 0.5700 - val_loss: 1.3487 - val_accuracy: 0.4567\n",
      "Epoch 723/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1570 - accuracy: 0.5686 - val_loss: 1.3483 - val_accuracy: 0.4500\n",
      "Epoch 724/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1566 - accuracy: 0.5729 - val_loss: 1.3490 - val_accuracy: 0.4467\n",
      "Epoch 725/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1563 - accuracy: 0.5657 - val_loss: 1.3490 - val_accuracy: 0.4467\n",
      "Epoch 726/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1559 - accuracy: 0.5729 - val_loss: 1.3489 - val_accuracy: 0.4533\n",
      "Epoch 727/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1556 - accuracy: 0.5700 - val_loss: 1.3483 - val_accuracy: 0.4467\n",
      "Epoch 728/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1553 - accuracy: 0.5671 - val_loss: 1.3478 - val_accuracy: 0.4500\n",
      "Epoch 729/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1549 - accuracy: 0.5671 - val_loss: 1.3474 - val_accuracy: 0.4567\n",
      "Epoch 730/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1545 - accuracy: 0.5700 - val_loss: 1.3472 - val_accuracy: 0.4567\n",
      "Epoch 731/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1542 - accuracy: 0.5657 - val_loss: 1.3478 - val_accuracy: 0.4533\n",
      "Epoch 732/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1539 - accuracy: 0.5643 - val_loss: 1.3486 - val_accuracy: 0.4533\n",
      "Epoch 733/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1535 - accuracy: 0.5700 - val_loss: 1.3480 - val_accuracy: 0.4533\n",
      "Epoch 734/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1532 - accuracy: 0.5657 - val_loss: 1.3486 - val_accuracy: 0.4533\n",
      "Epoch 735/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1528 - accuracy: 0.5671 - val_loss: 1.3476 - val_accuracy: 0.4533\n",
      "Epoch 736/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 1.1524 - accuracy: 0.5643 - val_loss: 1.3475 - val_accuracy: 0.4533\n",
      "Epoch 737/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1521 - accuracy: 0.5671 - val_loss: 1.3470 - val_accuracy: 0.4567\n",
      "Epoch 738/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.1516 - accuracy: 0.5686 - val_loss: 1.3475 - val_accuracy: 0.4567\n",
      "Epoch 739/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.1515 - accuracy: 0.5686 - val_loss: 1.3473 - val_accuracy: 0.4567\n",
      "Epoch 740/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1510 - accuracy: 0.5671 - val_loss: 1.3478 - val_accuracy: 0.4567\n",
      "Epoch 741/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.1507 - accuracy: 0.5700 - val_loss: 1.3476 - val_accuracy: 0.4567\n",
      "Epoch 742/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1505 - accuracy: 0.5714 - val_loss: 1.3468 - val_accuracy: 0.4567\n",
      "Epoch 743/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1500 - accuracy: 0.5743 - val_loss: 1.3458 - val_accuracy: 0.4567\n",
      "Epoch 744/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.1497 - accuracy: 0.5686 - val_loss: 1.3456 - val_accuracy: 0.4600\n",
      "Epoch 745/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.1495 - accuracy: 0.5643 - val_loss: 1.3457 - val_accuracy: 0.4600\n",
      "Epoch 746/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.1490 - accuracy: 0.5686 - val_loss: 1.3461 - val_accuracy: 0.4600\n",
      "Epoch 747/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1486 - accuracy: 0.5700 - val_loss: 1.3470 - val_accuracy: 0.4567\n",
      "Epoch 748/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1484 - accuracy: 0.5714 - val_loss: 1.3455 - val_accuracy: 0.4600\n",
      "Epoch 749/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.1479 - accuracy: 0.5729 - val_loss: 1.3451 - val_accuracy: 0.4600\n",
      "Epoch 750/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1476 - accuracy: 0.5714 - val_loss: 1.3451 - val_accuracy: 0.4567\n",
      "Epoch 751/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1474 - accuracy: 0.5729 - val_loss: 1.3446 - val_accuracy: 0.4567\n",
      "Epoch 752/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1470 - accuracy: 0.5700 - val_loss: 1.3452 - val_accuracy: 0.4600\n",
      "Epoch 753/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1468 - accuracy: 0.5686 - val_loss: 1.3453 - val_accuracy: 0.4633\n",
      "Epoch 754/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1464 - accuracy: 0.5743 - val_loss: 1.3446 - val_accuracy: 0.4600\n",
      "Epoch 755/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1460 - accuracy: 0.5671 - val_loss: 1.3447 - val_accuracy: 0.4600\n",
      "Epoch 756/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1457 - accuracy: 0.5686 - val_loss: 1.3443 - val_accuracy: 0.4633\n",
      "Epoch 757/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1452 - accuracy: 0.5714 - val_loss: 1.3441 - val_accuracy: 0.4567\n",
      "Epoch 758/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1451 - accuracy: 0.5714 - val_loss: 1.3438 - val_accuracy: 0.4667\n",
      "Epoch 759/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1446 - accuracy: 0.5729 - val_loss: 1.3449 - val_accuracy: 0.4633\n",
      "Epoch 760/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1443 - accuracy: 0.5714 - val_loss: 1.3445 - val_accuracy: 0.4600\n",
      "Epoch 761/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 1.1439 - accuracy: 0.5714 - val_loss: 1.3442 - val_accuracy: 0.4600\n",
      "Epoch 762/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1436 - accuracy: 0.5729 - val_loss: 1.3442 - val_accuracy: 0.4600\n",
      "Epoch 763/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 1.1435 - accuracy: 0.5686 - val_loss: 1.3438 - val_accuracy: 0.4600\n",
      "Epoch 764/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1431 - accuracy: 0.5771 - val_loss: 1.3437 - val_accuracy: 0.4567\n",
      "Epoch 765/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1427 - accuracy: 0.5671 - val_loss: 1.3436 - val_accuracy: 0.4633\n",
      "Epoch 766/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1423 - accuracy: 0.5743 - val_loss: 1.3426 - val_accuracy: 0.4633\n",
      "Epoch 767/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1420 - accuracy: 0.5700 - val_loss: 1.3431 - val_accuracy: 0.4600\n",
      "Epoch 768/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1417 - accuracy: 0.5700 - val_loss: 1.3441 - val_accuracy: 0.4600\n",
      "Epoch 769/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1415 - accuracy: 0.5743 - val_loss: 1.3434 - val_accuracy: 0.4600\n",
      "Epoch 770/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1409 - accuracy: 0.5757 - val_loss: 1.3432 - val_accuracy: 0.4600\n",
      "Epoch 771/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1406 - accuracy: 0.5700 - val_loss: 1.3429 - val_accuracy: 0.4633\n",
      "Epoch 772/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1403 - accuracy: 0.5686 - val_loss: 1.3426 - val_accuracy: 0.4600\n",
      "Epoch 773/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1399 - accuracy: 0.5729 - val_loss: 1.3436 - val_accuracy: 0.4633\n",
      "Epoch 774/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1398 - accuracy: 0.5757 - val_loss: 1.3422 - val_accuracy: 0.4600\n",
      "Epoch 775/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1396 - accuracy: 0.5714 - val_loss: 1.3420 - val_accuracy: 0.4600\n",
      "Epoch 776/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 1.1389 - accuracy: 0.5714 - val_loss: 1.3425 - val_accuracy: 0.4600\n",
      "Epoch 777/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1387 - accuracy: 0.5743 - val_loss: 1.3420 - val_accuracy: 0.4633\n",
      "Epoch 778/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 1.1385 - accuracy: 0.5743 - val_loss: 1.3422 - val_accuracy: 0.4633\n",
      "Epoch 779/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1382 - accuracy: 0.5757 - val_loss: 1.3415 - val_accuracy: 0.4567\n",
      "Epoch 780/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1378 - accuracy: 0.5729 - val_loss: 1.3420 - val_accuracy: 0.4633\n",
      "Epoch 781/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1374 - accuracy: 0.5771 - val_loss: 1.3412 - val_accuracy: 0.4567\n",
      "Epoch 782/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1372 - accuracy: 0.5757 - val_loss: 1.3412 - val_accuracy: 0.4567\n",
      "Epoch 783/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1368 - accuracy: 0.5729 - val_loss: 1.3410 - val_accuracy: 0.4533\n",
      "Epoch 784/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1365 - accuracy: 0.5786 - val_loss: 1.3415 - val_accuracy: 0.4600\n",
      "Epoch 785/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1361 - accuracy: 0.5786 - val_loss: 1.3405 - val_accuracy: 0.4533\n",
      "Epoch 786/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1358 - accuracy: 0.5771 - val_loss: 1.3402 - val_accuracy: 0.4533\n",
      "Epoch 787/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1355 - accuracy: 0.5714 - val_loss: 1.3407 - val_accuracy: 0.4533\n",
      "Epoch 788/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1352 - accuracy: 0.5771 - val_loss: 1.3413 - val_accuracy: 0.4600\n",
      "Epoch 789/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1348 - accuracy: 0.5771 - val_loss: 1.3405 - val_accuracy: 0.4533\n",
      "Epoch 790/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.1345 - accuracy: 0.5771 - val_loss: 1.3403 - val_accuracy: 0.4533\n",
      "Epoch 791/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1342 - accuracy: 0.5757 - val_loss: 1.3404 - val_accuracy: 0.4533\n",
      "Epoch 792/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1338 - accuracy: 0.5757 - val_loss: 1.3407 - val_accuracy: 0.4533\n",
      "Epoch 793/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1335 - accuracy: 0.5771 - val_loss: 1.3406 - val_accuracy: 0.4533\n",
      "Epoch 794/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1332 - accuracy: 0.5786 - val_loss: 1.3396 - val_accuracy: 0.4533\n",
      "Epoch 795/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1329 - accuracy: 0.5800 - val_loss: 1.3392 - val_accuracy: 0.4567\n",
      "Epoch 796/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1325 - accuracy: 0.5800 - val_loss: 1.3392 - val_accuracy: 0.4567\n",
      "Epoch 797/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1323 - accuracy: 0.5757 - val_loss: 1.3395 - val_accuracy: 0.4533\n",
      "Epoch 798/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1318 - accuracy: 0.5814 - val_loss: 1.3393 - val_accuracy: 0.4500\n",
      "Epoch 799/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1315 - accuracy: 0.5786 - val_loss: 1.3385 - val_accuracy: 0.4500\n",
      "Epoch 800/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 1.1313 - accuracy: 0.5786 - val_loss: 1.3387 - val_accuracy: 0.4533\n",
      "Epoch 801/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1308 - accuracy: 0.5814 - val_loss: 1.3380 - val_accuracy: 0.4567\n",
      "Epoch 802/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1305 - accuracy: 0.5714 - val_loss: 1.3388 - val_accuracy: 0.4533\n",
      "Epoch 803/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 1.1303 - accuracy: 0.5786 - val_loss: 1.3386 - val_accuracy: 0.4467\n",
      "Epoch 804/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1302 - accuracy: 0.5771 - val_loss: 1.3384 - val_accuracy: 0.4533\n",
      "Epoch 805/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1297 - accuracy: 0.5743 - val_loss: 1.3381 - val_accuracy: 0.4533\n",
      "Epoch 806/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1293 - accuracy: 0.5771 - val_loss: 1.3383 - val_accuracy: 0.4567\n",
      "Epoch 807/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1291 - accuracy: 0.5786 - val_loss: 1.3384 - val_accuracy: 0.4567\n",
      "Epoch 808/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.1288 - accuracy: 0.5786 - val_loss: 1.3384 - val_accuracy: 0.4600\n",
      "Epoch 809/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1284 - accuracy: 0.5829 - val_loss: 1.3375 - val_accuracy: 0.4533\n",
      "Epoch 810/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1279 - accuracy: 0.5800 - val_loss: 1.3377 - val_accuracy: 0.4533\n",
      "Epoch 811/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1278 - accuracy: 0.5729 - val_loss: 1.3374 - val_accuracy: 0.4567\n",
      "Epoch 812/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1274 - accuracy: 0.5786 - val_loss: 1.3376 - val_accuracy: 0.4567\n",
      "Epoch 813/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1270 - accuracy: 0.5786 - val_loss: 1.3372 - val_accuracy: 0.4533\n",
      "Epoch 814/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1268 - accuracy: 0.5786 - val_loss: 1.3381 - val_accuracy: 0.4600\n",
      "Epoch 815/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1264 - accuracy: 0.5843 - val_loss: 1.3369 - val_accuracy: 0.4533\n",
      "Epoch 816/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1261 - accuracy: 0.5800 - val_loss: 1.3376 - val_accuracy: 0.4533\n",
      "Epoch 817/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1258 - accuracy: 0.5771 - val_loss: 1.3366 - val_accuracy: 0.4567\n",
      "Epoch 818/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 1.1254 - accuracy: 0.5800 - val_loss: 1.3370 - val_accuracy: 0.4567\n",
      "Epoch 819/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1252 - accuracy: 0.5800 - val_loss: 1.3373 - val_accuracy: 0.4567\n",
      "Epoch 820/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1249 - accuracy: 0.5743 - val_loss: 1.3367 - val_accuracy: 0.4567\n",
      "Epoch 821/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1246 - accuracy: 0.5829 - val_loss: 1.3365 - val_accuracy: 0.4533\n",
      "Epoch 822/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1244 - accuracy: 0.5757 - val_loss: 1.3363 - val_accuracy: 0.4567\n",
      "Epoch 823/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1239 - accuracy: 0.5814 - val_loss: 1.3364 - val_accuracy: 0.4533\n",
      "Epoch 824/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1236 - accuracy: 0.5829 - val_loss: 1.3354 - val_accuracy: 0.4533\n",
      "Epoch 825/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 1.1235 - accuracy: 0.5771 - val_loss: 1.3349 - val_accuracy: 0.4567\n",
      "Epoch 826/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.1230 - accuracy: 0.5800 - val_loss: 1.3360 - val_accuracy: 0.4533\n",
      "Epoch 827/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.1226 - accuracy: 0.5771 - val_loss: 1.3361 - val_accuracy: 0.4500\n",
      "Epoch 828/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1225 - accuracy: 0.5786 - val_loss: 1.3358 - val_accuracy: 0.4533\n",
      "Epoch 829/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 1.1221 - accuracy: 0.5814 - val_loss: 1.3359 - val_accuracy: 0.4567\n",
      "Epoch 830/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.1218 - accuracy: 0.5771 - val_loss: 1.3364 - val_accuracy: 0.4567\n",
      "Epoch 831/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.1215 - accuracy: 0.5771 - val_loss: 1.3354 - val_accuracy: 0.4567\n",
      "Epoch 832/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1212 - accuracy: 0.5800 - val_loss: 1.3360 - val_accuracy: 0.4500\n",
      "Epoch 833/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 1.1208 - accuracy: 0.5800 - val_loss: 1.3357 - val_accuracy: 0.4500\n",
      "Epoch 834/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1206 - accuracy: 0.5800 - val_loss: 1.3351 - val_accuracy: 0.4500\n",
      "Epoch 835/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1202 - accuracy: 0.5786 - val_loss: 1.3350 - val_accuracy: 0.4567\n",
      "Epoch 836/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1199 - accuracy: 0.5800 - val_loss: 1.3351 - val_accuracy: 0.4500\n",
      "Epoch 837/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1197 - accuracy: 0.5757 - val_loss: 1.3350 - val_accuracy: 0.4533\n",
      "Epoch 838/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1193 - accuracy: 0.5843 - val_loss: 1.3346 - val_accuracy: 0.4533\n",
      "Epoch 839/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1190 - accuracy: 0.5771 - val_loss: 1.3339 - val_accuracy: 0.4500\n",
      "Epoch 840/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1189 - accuracy: 0.5800 - val_loss: 1.3342 - val_accuracy: 0.4500\n",
      "Epoch 841/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1184 - accuracy: 0.5786 - val_loss: 1.3336 - val_accuracy: 0.4600\n",
      "Epoch 842/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1181 - accuracy: 0.5800 - val_loss: 1.3340 - val_accuracy: 0.4567\n",
      "Epoch 843/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1178 - accuracy: 0.5829 - val_loss: 1.3335 - val_accuracy: 0.4600\n",
      "Epoch 844/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1176 - accuracy: 0.5786 - val_loss: 1.3334 - val_accuracy: 0.4600\n",
      "Epoch 845/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1173 - accuracy: 0.5800 - val_loss: 1.3337 - val_accuracy: 0.4600\n",
      "Epoch 846/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 1.1170 - accuracy: 0.5829 - val_loss: 1.3341 - val_accuracy: 0.4533\n",
      "Epoch 847/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1168 - accuracy: 0.5800 - val_loss: 1.3336 - val_accuracy: 0.4600\n",
      "Epoch 848/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 1.1165 - accuracy: 0.5786 - val_loss: 1.3334 - val_accuracy: 0.4533\n",
      "Epoch 849/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1161 - accuracy: 0.5800 - val_loss: 1.3330 - val_accuracy: 0.4600\n",
      "Epoch 850/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1158 - accuracy: 0.5814 - val_loss: 1.3327 - val_accuracy: 0.4500\n",
      "Epoch 851/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1154 - accuracy: 0.5814 - val_loss: 1.3323 - val_accuracy: 0.4533\n",
      "Epoch 852/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1151 - accuracy: 0.5829 - val_loss: 1.3325 - val_accuracy: 0.4500\n",
      "Epoch 853/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1149 - accuracy: 0.5800 - val_loss: 1.3334 - val_accuracy: 0.4500\n",
      "Epoch 854/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.1145 - accuracy: 0.5814 - val_loss: 1.3328 - val_accuracy: 0.4567\n",
      "Epoch 855/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1142 - accuracy: 0.5786 - val_loss: 1.3321 - val_accuracy: 0.4600\n",
      "Epoch 856/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1139 - accuracy: 0.5857 - val_loss: 1.3324 - val_accuracy: 0.4600\n",
      "Epoch 857/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1136 - accuracy: 0.5786 - val_loss: 1.3313 - val_accuracy: 0.4600\n",
      "Epoch 858/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1134 - accuracy: 0.5829 - val_loss: 1.3319 - val_accuracy: 0.4600\n",
      "Epoch 859/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1128 - accuracy: 0.5814 - val_loss: 1.3319 - val_accuracy: 0.4567\n",
      "Epoch 860/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1127 - accuracy: 0.5857 - val_loss: 1.3319 - val_accuracy: 0.4500\n",
      "Epoch 861/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1124 - accuracy: 0.5814 - val_loss: 1.3316 - val_accuracy: 0.4500\n",
      "Epoch 862/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1120 - accuracy: 0.5829 - val_loss: 1.3305 - val_accuracy: 0.4567\n",
      "Epoch 863/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1117 - accuracy: 0.5843 - val_loss: 1.3307 - val_accuracy: 0.4500\n",
      "Epoch 864/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1115 - accuracy: 0.5843 - val_loss: 1.3308 - val_accuracy: 0.4500\n",
      "Epoch 865/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1113 - accuracy: 0.5829 - val_loss: 1.3309 - val_accuracy: 0.4567\n",
      "Epoch 866/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1108 - accuracy: 0.5857 - val_loss: 1.3315 - val_accuracy: 0.4500\n",
      "Epoch 867/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1104 - accuracy: 0.5814 - val_loss: 1.3315 - val_accuracy: 0.4467\n",
      "Epoch 868/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1103 - accuracy: 0.5800 - val_loss: 1.3309 - val_accuracy: 0.4467\n",
      "Epoch 869/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1100 - accuracy: 0.5786 - val_loss: 1.3306 - val_accuracy: 0.4500\n",
      "Epoch 870/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.1097 - accuracy: 0.5800 - val_loss: 1.3304 - val_accuracy: 0.4500\n",
      "Epoch 871/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1093 - accuracy: 0.5814 - val_loss: 1.3306 - val_accuracy: 0.4567\n",
      "Epoch 872/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1090 - accuracy: 0.5800 - val_loss: 1.3308 - val_accuracy: 0.4567\n",
      "Epoch 873/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1088 - accuracy: 0.5800 - val_loss: 1.3298 - val_accuracy: 0.4567\n",
      "Epoch 874/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1084 - accuracy: 0.5814 - val_loss: 1.3293 - val_accuracy: 0.4600\n",
      "Epoch 875/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1084 - accuracy: 0.5800 - val_loss: 1.3295 - val_accuracy: 0.4567\n",
      "Epoch 876/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1080 - accuracy: 0.5857 - val_loss: 1.3293 - val_accuracy: 0.4533\n",
      "Epoch 877/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1076 - accuracy: 0.5814 - val_loss: 1.3289 - val_accuracy: 0.4533\n",
      "Epoch 878/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1074 - accuracy: 0.5814 - val_loss: 1.3289 - val_accuracy: 0.4600\n",
      "Epoch 879/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1069 - accuracy: 0.5857 - val_loss: 1.3290 - val_accuracy: 0.4567\n",
      "Epoch 880/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1067 - accuracy: 0.5871 - val_loss: 1.3285 - val_accuracy: 0.4533\n",
      "Epoch 881/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1065 - accuracy: 0.5857 - val_loss: 1.3285 - val_accuracy: 0.4533\n",
      "Epoch 882/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1063 - accuracy: 0.5857 - val_loss: 1.3281 - val_accuracy: 0.4533\n",
      "Epoch 883/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.1059 - accuracy: 0.5814 - val_loss: 1.3277 - val_accuracy: 0.4600\n",
      "Epoch 884/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1055 - accuracy: 0.5871 - val_loss: 1.3279 - val_accuracy: 0.4533\n",
      "Epoch 885/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.1053 - accuracy: 0.5871 - val_loss: 1.3285 - val_accuracy: 0.4500\n",
      "Epoch 886/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1051 - accuracy: 0.5814 - val_loss: 1.3279 - val_accuracy: 0.4567\n",
      "Epoch 887/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.1047 - accuracy: 0.5829 - val_loss: 1.3284 - val_accuracy: 0.4600\n",
      "Epoch 888/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1044 - accuracy: 0.5886 - val_loss: 1.3278 - val_accuracy: 0.4633\n",
      "Epoch 889/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1042 - accuracy: 0.5843 - val_loss: 1.3275 - val_accuracy: 0.4667\n",
      "Epoch 890/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1039 - accuracy: 0.5829 - val_loss: 1.3277 - val_accuracy: 0.4533\n",
      "Epoch 891/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1034 - accuracy: 0.5800 - val_loss: 1.3266 - val_accuracy: 0.4667\n",
      "Epoch 892/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1034 - accuracy: 0.5829 - val_loss: 1.3265 - val_accuracy: 0.4667\n",
      "Epoch 893/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1030 - accuracy: 0.5871 - val_loss: 1.3273 - val_accuracy: 0.4567\n",
      "Epoch 894/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.1026 - accuracy: 0.5857 - val_loss: 1.3263 - val_accuracy: 0.4633\n",
      "Epoch 895/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1024 - accuracy: 0.5871 - val_loss: 1.3262 - val_accuracy: 0.4600\n",
      "Epoch 896/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1020 - accuracy: 0.5857 - val_loss: 1.3268 - val_accuracy: 0.4533\n",
      "Epoch 897/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1018 - accuracy: 0.5886 - val_loss: 1.3268 - val_accuracy: 0.4500\n",
      "Epoch 898/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1014 - accuracy: 0.5829 - val_loss: 1.3268 - val_accuracy: 0.4500\n",
      "Epoch 899/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.1013 - accuracy: 0.5871 - val_loss: 1.3269 - val_accuracy: 0.4500\n",
      "Epoch 900/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1010 - accuracy: 0.5871 - val_loss: 1.3270 - val_accuracy: 0.4500\n",
      "Epoch 901/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.1008 - accuracy: 0.5857 - val_loss: 1.3263 - val_accuracy: 0.4533\n",
      "Epoch 902/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1004 - accuracy: 0.5829 - val_loss: 1.3256 - val_accuracy: 0.4533\n",
      "Epoch 903/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1000 - accuracy: 0.5814 - val_loss: 1.3245 - val_accuracy: 0.4567\n",
      "Epoch 904/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0998 - accuracy: 0.5929 - val_loss: 1.3259 - val_accuracy: 0.4500\n",
      "Epoch 905/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0997 - accuracy: 0.5871 - val_loss: 1.3256 - val_accuracy: 0.4567\n",
      "Epoch 906/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0993 - accuracy: 0.5857 - val_loss: 1.3248 - val_accuracy: 0.4567\n",
      "Epoch 907/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.0991 - accuracy: 0.5857 - val_loss: 1.3250 - val_accuracy: 0.4567\n",
      "Epoch 908/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0988 - accuracy: 0.5814 - val_loss: 1.3252 - val_accuracy: 0.4600\n",
      "Epoch 909/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0986 - accuracy: 0.5871 - val_loss: 1.3251 - val_accuracy: 0.4567\n",
      "Epoch 910/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.0980 - accuracy: 0.5843 - val_loss: 1.3240 - val_accuracy: 0.4567\n",
      "Epoch 911/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.0980 - accuracy: 0.5857 - val_loss: 1.3245 - val_accuracy: 0.4533\n",
      "Epoch 912/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.0976 - accuracy: 0.5871 - val_loss: 1.3240 - val_accuracy: 0.4567\n",
      "Epoch 913/3000\n",
      "700/700 [==============================] - 0s 88us/sample - loss: 1.0974 - accuracy: 0.5857 - val_loss: 1.3249 - val_accuracy: 0.4533\n",
      "Epoch 914/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.0970 - accuracy: 0.5829 - val_loss: 1.3245 - val_accuracy: 0.4567\n",
      "Epoch 915/3000\n",
      "700/700 [==============================] - 0s 92us/sample - loss: 1.0968 - accuracy: 0.5914 - val_loss: 1.3246 - val_accuracy: 0.4467\n",
      "Epoch 916/3000\n",
      "700/700 [==============================] - 0s 86us/sample - loss: 1.0965 - accuracy: 0.5886 - val_loss: 1.3236 - val_accuracy: 0.4567\n",
      "Epoch 917/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.0963 - accuracy: 0.5929 - val_loss: 1.3243 - val_accuracy: 0.4467\n",
      "Epoch 918/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.0961 - accuracy: 0.5857 - val_loss: 1.3231 - val_accuracy: 0.4500\n",
      "Epoch 919/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.0958 - accuracy: 0.5886 - val_loss: 1.3228 - val_accuracy: 0.4500\n",
      "Epoch 920/3000\n",
      "700/700 [==============================] - 0s 88us/sample - loss: 1.0956 - accuracy: 0.5886 - val_loss: 1.3228 - val_accuracy: 0.4500\n",
      "Epoch 921/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.0952 - accuracy: 0.5857 - val_loss: 1.3225 - val_accuracy: 0.4567\n",
      "Epoch 922/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.0949 - accuracy: 0.5871 - val_loss: 1.3230 - val_accuracy: 0.4467\n",
      "Epoch 923/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.0946 - accuracy: 0.5900 - val_loss: 1.3224 - val_accuracy: 0.4500\n",
      "Epoch 924/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.0945 - accuracy: 0.5957 - val_loss: 1.3229 - val_accuracy: 0.4500\n",
      "Epoch 925/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.0942 - accuracy: 0.5900 - val_loss: 1.3227 - val_accuracy: 0.4500\n",
      "Epoch 926/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.0939 - accuracy: 0.5914 - val_loss: 1.3222 - val_accuracy: 0.4467\n",
      "Epoch 927/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0935 - accuracy: 0.5929 - val_loss: 1.3229 - val_accuracy: 0.4433\n",
      "Epoch 928/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0933 - accuracy: 0.5900 - val_loss: 1.3226 - val_accuracy: 0.4500\n",
      "Epoch 929/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0933 - accuracy: 0.5929 - val_loss: 1.3223 - val_accuracy: 0.4567\n",
      "Epoch 930/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0927 - accuracy: 0.5900 - val_loss: 1.3221 - val_accuracy: 0.4600\n",
      "Epoch 931/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.0926 - accuracy: 0.5943 - val_loss: 1.3222 - val_accuracy: 0.4600\n",
      "Epoch 932/3000\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 1.0923 - accuracy: 0.5957 - val_loss: 1.3221 - val_accuracy: 0.4600\n",
      "Epoch 933/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0921 - accuracy: 0.5943 - val_loss: 1.3214 - val_accuracy: 0.4633\n",
      "Epoch 934/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0917 - accuracy: 0.5914 - val_loss: 1.3218 - val_accuracy: 0.4600\n",
      "Epoch 935/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0915 - accuracy: 0.5929 - val_loss: 1.3218 - val_accuracy: 0.4567\n",
      "Epoch 936/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0913 - accuracy: 0.5929 - val_loss: 1.3216 - val_accuracy: 0.4600\n",
      "Epoch 937/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.0910 - accuracy: 0.5943 - val_loss: 1.3220 - val_accuracy: 0.4567\n",
      "Epoch 938/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0908 - accuracy: 0.5929 - val_loss: 1.3213 - val_accuracy: 0.4600\n",
      "Epoch 939/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.0904 - accuracy: 0.5943 - val_loss: 1.3213 - val_accuracy: 0.4600\n",
      "Epoch 940/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0902 - accuracy: 0.5957 - val_loss: 1.3220 - val_accuracy: 0.4533\n",
      "Epoch 941/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0898 - accuracy: 0.5971 - val_loss: 1.3208 - val_accuracy: 0.4567\n",
      "Epoch 942/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0897 - accuracy: 0.5986 - val_loss: 1.3211 - val_accuracy: 0.4533\n",
      "Epoch 943/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0894 - accuracy: 0.5929 - val_loss: 1.3200 - val_accuracy: 0.4567\n",
      "Epoch 944/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0892 - accuracy: 0.5971 - val_loss: 1.3207 - val_accuracy: 0.4533\n",
      "Epoch 945/3000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 1.0889 - accuracy: 0.5971 - val_loss: 1.3205 - val_accuracy: 0.4567\n",
      "Epoch 946/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.0886 - accuracy: 0.5943 - val_loss: 1.3204 - val_accuracy: 0.4600\n",
      "Epoch 947/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.0883 - accuracy: 0.5929 - val_loss: 1.3199 - val_accuracy: 0.4567\n",
      "Epoch 948/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.0880 - accuracy: 0.5986 - val_loss: 1.3204 - val_accuracy: 0.4533\n",
      "Epoch 949/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.0880 - accuracy: 0.5957 - val_loss: 1.3200 - val_accuracy: 0.4500\n",
      "Epoch 950/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.0875 - accuracy: 0.5986 - val_loss: 1.3201 - val_accuracy: 0.4500\n",
      "Epoch 951/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.0873 - accuracy: 0.5957 - val_loss: 1.3191 - val_accuracy: 0.4633\n",
      "Epoch 952/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0871 - accuracy: 0.5957 - val_loss: 1.3199 - val_accuracy: 0.4500\n",
      "Epoch 953/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.0869 - accuracy: 0.5986 - val_loss: 1.3200 - val_accuracy: 0.4533\n",
      "Epoch 954/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.0866 - accuracy: 0.5943 - val_loss: 1.3201 - val_accuracy: 0.4533\n",
      "Epoch 955/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0865 - accuracy: 0.5971 - val_loss: 1.3188 - val_accuracy: 0.4600\n",
      "Epoch 956/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.0862 - accuracy: 0.5986 - val_loss: 1.3183 - val_accuracy: 0.4633\n",
      "Epoch 957/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.0858 - accuracy: 0.5986 - val_loss: 1.3182 - val_accuracy: 0.4600\n",
      "Epoch 958/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.0857 - accuracy: 0.5971 - val_loss: 1.3181 - val_accuracy: 0.4633\n",
      "Epoch 959/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.0855 - accuracy: 0.5971 - val_loss: 1.3188 - val_accuracy: 0.4633\n",
      "Epoch 960/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0851 - accuracy: 0.5957 - val_loss: 1.3182 - val_accuracy: 0.4600\n",
      "Epoch 961/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.0849 - accuracy: 0.5986 - val_loss: 1.3182 - val_accuracy: 0.4533\n",
      "Epoch 962/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0845 - accuracy: 0.5943 - val_loss: 1.3187 - val_accuracy: 0.4500\n",
      "Epoch 963/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.0843 - accuracy: 0.5971 - val_loss: 1.3185 - val_accuracy: 0.4500\n",
      "Epoch 964/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.0841 - accuracy: 0.5971 - val_loss: 1.3181 - val_accuracy: 0.4533\n",
      "Epoch 965/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.0838 - accuracy: 0.5986 - val_loss: 1.3182 - val_accuracy: 0.4533\n",
      "Epoch 966/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.0836 - accuracy: 0.5986 - val_loss: 1.3175 - val_accuracy: 0.4500\n",
      "Epoch 967/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.0835 - accuracy: 0.6014 - val_loss: 1.3178 - val_accuracy: 0.4500\n",
      "Epoch 968/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.0831 - accuracy: 0.5971 - val_loss: 1.3172 - val_accuracy: 0.4500\n",
      "Epoch 969/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.0828 - accuracy: 0.5957 - val_loss: 1.3169 - val_accuracy: 0.4500\n",
      "Epoch 970/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.0826 - accuracy: 0.5971 - val_loss: 1.3177 - val_accuracy: 0.4467\n",
      "Epoch 971/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.0825 - accuracy: 0.5929 - val_loss: 1.3172 - val_accuracy: 0.4500\n",
      "Epoch 972/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.0820 - accuracy: 0.5986 - val_loss: 1.3174 - val_accuracy: 0.4533\n",
      "Epoch 973/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0818 - accuracy: 0.5986 - val_loss: 1.3181 - val_accuracy: 0.4500\n",
      "Epoch 974/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0816 - accuracy: 0.5986 - val_loss: 1.3175 - val_accuracy: 0.4467\n",
      "Epoch 975/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0815 - accuracy: 0.5929 - val_loss: 1.3171 - val_accuracy: 0.4500\n",
      "Epoch 976/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0812 - accuracy: 0.5957 - val_loss: 1.3171 - val_accuracy: 0.4500\n",
      "Epoch 977/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0808 - accuracy: 0.5914 - val_loss: 1.3164 - val_accuracy: 0.4533\n",
      "Epoch 978/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0806 - accuracy: 0.5943 - val_loss: 1.3171 - val_accuracy: 0.4533\n",
      "Epoch 979/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.0805 - accuracy: 0.5971 - val_loss: 1.3159 - val_accuracy: 0.4500\n",
      "Epoch 980/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0803 - accuracy: 0.5986 - val_loss: 1.3159 - val_accuracy: 0.4500\n",
      "Epoch 981/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.0798 - accuracy: 0.6000 - val_loss: 1.3167 - val_accuracy: 0.4500\n",
      "Epoch 982/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0798 - accuracy: 0.5986 - val_loss: 1.3161 - val_accuracy: 0.4533\n",
      "Epoch 983/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.0796 - accuracy: 0.5957 - val_loss: 1.3159 - val_accuracy: 0.4500\n",
      "Epoch 984/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0792 - accuracy: 0.5943 - val_loss: 1.3157 - val_accuracy: 0.4500\n",
      "Epoch 985/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.0790 - accuracy: 0.5971 - val_loss: 1.3156 - val_accuracy: 0.4500\n",
      "Epoch 986/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0787 - accuracy: 0.5957 - val_loss: 1.3154 - val_accuracy: 0.4533\n",
      "Epoch 987/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0786 - accuracy: 0.5986 - val_loss: 1.3164 - val_accuracy: 0.4533\n",
      "Epoch 988/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0784 - accuracy: 0.5957 - val_loss: 1.3160 - val_accuracy: 0.4500\n",
      "Epoch 989/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0781 - accuracy: 0.5986 - val_loss: 1.3165 - val_accuracy: 0.4500\n",
      "Epoch 990/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0777 - accuracy: 0.5986 - val_loss: 1.3165 - val_accuracy: 0.4500\n",
      "Epoch 991/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0775 - accuracy: 0.5943 - val_loss: 1.3162 - val_accuracy: 0.4500\n",
      "Epoch 992/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0774 - accuracy: 0.5957 - val_loss: 1.3155 - val_accuracy: 0.4500\n",
      "Epoch 993/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0770 - accuracy: 0.5971 - val_loss: 1.3161 - val_accuracy: 0.4467\n",
      "Epoch 994/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0768 - accuracy: 0.5957 - val_loss: 1.3159 - val_accuracy: 0.4467\n",
      "Epoch 995/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0766 - accuracy: 0.5986 - val_loss: 1.3161 - val_accuracy: 0.4500\n",
      "Epoch 996/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0763 - accuracy: 0.5971 - val_loss: 1.3166 - val_accuracy: 0.4500\n",
      "Epoch 997/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0763 - accuracy: 0.6000 - val_loss: 1.3158 - val_accuracy: 0.4500\n",
      "Epoch 998/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0760 - accuracy: 0.5971 - val_loss: 1.3147 - val_accuracy: 0.4500\n",
      "Epoch 999/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0756 - accuracy: 0.5971 - val_loss: 1.3152 - val_accuracy: 0.4500\n",
      "Epoch 1000/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0754 - accuracy: 0.5943 - val_loss: 1.3150 - val_accuracy: 0.4500\n",
      "Epoch 1001/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0751 - accuracy: 0.5914 - val_loss: 1.3143 - val_accuracy: 0.4500\n",
      "Epoch 1002/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0748 - accuracy: 0.5957 - val_loss: 1.3148 - val_accuracy: 0.4500\n",
      "Epoch 1003/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0748 - accuracy: 0.5957 - val_loss: 1.3139 - val_accuracy: 0.4533\n",
      "Epoch 1004/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.0745 - accuracy: 0.5943 - val_loss: 1.3133 - val_accuracy: 0.4567\n",
      "Epoch 1005/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0742 - accuracy: 0.5986 - val_loss: 1.3140 - val_accuracy: 0.4567\n",
      "Epoch 1006/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0740 - accuracy: 0.5986 - val_loss: 1.3151 - val_accuracy: 0.4467\n",
      "Epoch 1007/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.0737 - accuracy: 0.5900 - val_loss: 1.3138 - val_accuracy: 0.4500\n",
      "Epoch 1008/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.0737 - accuracy: 0.5957 - val_loss: 1.3134 - val_accuracy: 0.4500\n",
      "Epoch 1009/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0733 - accuracy: 0.5943 - val_loss: 1.3135 - val_accuracy: 0.4500\n",
      "Epoch 1010/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.0732 - accuracy: 0.5971 - val_loss: 1.3138 - val_accuracy: 0.4500\n",
      "Epoch 1011/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0728 - accuracy: 0.5971 - val_loss: 1.3137 - val_accuracy: 0.4500\n",
      "Epoch 1012/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0724 - accuracy: 0.6014 - val_loss: 1.3124 - val_accuracy: 0.4500\n",
      "Epoch 1013/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0725 - accuracy: 0.5957 - val_loss: 1.3126 - val_accuracy: 0.4500\n",
      "Epoch 1014/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.0722 - accuracy: 0.6000 - val_loss: 1.3127 - val_accuracy: 0.4500\n",
      "Epoch 1015/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0721 - accuracy: 0.6000 - val_loss: 1.3127 - val_accuracy: 0.4500\n",
      "Epoch 1016/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.0717 - accuracy: 0.5971 - val_loss: 1.3127 - val_accuracy: 0.4500\n",
      "Epoch 1017/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.0715 - accuracy: 0.6000 - val_loss: 1.3129 - val_accuracy: 0.4467\n",
      "Epoch 1018/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.0713 - accuracy: 0.5957 - val_loss: 1.3133 - val_accuracy: 0.4500\n",
      "Epoch 1019/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.0711 - accuracy: 0.6000 - val_loss: 1.3129 - val_accuracy: 0.4500\n",
      "Epoch 1020/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.0707 - accuracy: 0.5971 - val_loss: 1.3122 - val_accuracy: 0.4500\n",
      "Epoch 1021/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.0705 - accuracy: 0.6014 - val_loss: 1.3131 - val_accuracy: 0.4500\n",
      "Epoch 1022/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.0706 - accuracy: 0.5971 - val_loss: 1.3131 - val_accuracy: 0.4500\n",
      "Epoch 1023/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.0700 - accuracy: 0.6014 - val_loss: 1.3126 - val_accuracy: 0.4500\n",
      "Epoch 1024/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.0699 - accuracy: 0.6000 - val_loss: 1.3132 - val_accuracy: 0.4533\n",
      "Epoch 1025/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.0697 - accuracy: 0.6000 - val_loss: 1.3124 - val_accuracy: 0.4500\n",
      "Epoch 1026/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.0694 - accuracy: 0.6000 - val_loss: 1.3122 - val_accuracy: 0.4500\n",
      "Epoch 1027/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.0691 - accuracy: 0.6043 - val_loss: 1.3132 - val_accuracy: 0.4500\n",
      "Epoch 1028/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.0691 - accuracy: 0.5957 - val_loss: 1.3126 - val_accuracy: 0.4533\n",
      "Epoch 1029/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.0688 - accuracy: 0.5986 - val_loss: 1.3126 - val_accuracy: 0.4533\n",
      "Epoch 1030/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.0686 - accuracy: 0.6000 - val_loss: 1.3122 - val_accuracy: 0.4533\n",
      "Epoch 1031/3000\n",
      "700/700 [==============================] - 0s 102us/sample - loss: 1.0684 - accuracy: 0.5986 - val_loss: 1.3119 - val_accuracy: 0.4533\n",
      "Epoch 1032/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0682 - accuracy: 0.6043 - val_loss: 1.3116 - val_accuracy: 0.4500\n",
      "Epoch 1033/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0679 - accuracy: 0.6000 - val_loss: 1.3124 - val_accuracy: 0.4500\n",
      "Epoch 1034/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 1.0677 - accuracy: 0.6014 - val_loss: 1.3112 - val_accuracy: 0.4500\n",
      "Epoch 1035/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0674 - accuracy: 0.5986 - val_loss: 1.3121 - val_accuracy: 0.4533\n",
      "Epoch 1036/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0672 - accuracy: 0.5971 - val_loss: 1.3112 - val_accuracy: 0.4500\n",
      "Epoch 1037/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.0672 - accuracy: 0.5986 - val_loss: 1.3116 - val_accuracy: 0.4500\n",
      "Epoch 1038/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.0669 - accuracy: 0.5986 - val_loss: 1.3120 - val_accuracy: 0.4500\n",
      "Epoch 1039/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.0666 - accuracy: 0.5986 - val_loss: 1.3112 - val_accuracy: 0.4500\n",
      "Epoch 1040/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0665 - accuracy: 0.6014 - val_loss: 1.3108 - val_accuracy: 0.4500\n",
      "Epoch 1041/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0661 - accuracy: 0.6100 - val_loss: 1.3111 - val_accuracy: 0.4533\n",
      "Epoch 1042/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.0660 - accuracy: 0.6014 - val_loss: 1.3110 - val_accuracy: 0.4467\n",
      "Epoch 1043/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.0656 - accuracy: 0.6014 - val_loss: 1.3109 - val_accuracy: 0.4467\n",
      "Epoch 1044/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.0655 - accuracy: 0.6029 - val_loss: 1.3111 - val_accuracy: 0.4500\n",
      "Epoch 1045/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0652 - accuracy: 0.6029 - val_loss: 1.3106 - val_accuracy: 0.4467\n",
      "Epoch 1046/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.0651 - accuracy: 0.6057 - val_loss: 1.3112 - val_accuracy: 0.4467\n",
      "Epoch 1047/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0648 - accuracy: 0.6000 - val_loss: 1.3098 - val_accuracy: 0.4500\n",
      "Epoch 1048/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0646 - accuracy: 0.6071 - val_loss: 1.3104 - val_accuracy: 0.4467\n",
      "Epoch 1049/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0643 - accuracy: 0.6000 - val_loss: 1.3104 - val_accuracy: 0.4433\n",
      "Epoch 1050/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.0643 - accuracy: 0.6029 - val_loss: 1.3099 - val_accuracy: 0.4500\n",
      "Epoch 1051/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0639 - accuracy: 0.6029 - val_loss: 1.3098 - val_accuracy: 0.4500\n",
      "Epoch 1052/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0637 - accuracy: 0.6043 - val_loss: 1.3108 - val_accuracy: 0.4467\n",
      "Epoch 1053/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0636 - accuracy: 0.6029 - val_loss: 1.3111 - val_accuracy: 0.4467\n",
      "Epoch 1054/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0634 - accuracy: 0.5971 - val_loss: 1.3101 - val_accuracy: 0.4500\n",
      "Epoch 1055/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0630 - accuracy: 0.6057 - val_loss: 1.3098 - val_accuracy: 0.4500\n",
      "Epoch 1056/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0628 - accuracy: 0.6043 - val_loss: 1.3095 - val_accuracy: 0.4500\n",
      "Epoch 1057/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0625 - accuracy: 0.6057 - val_loss: 1.3092 - val_accuracy: 0.4500\n",
      "Epoch 1058/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0624 - accuracy: 0.6071 - val_loss: 1.3092 - val_accuracy: 0.4500\n",
      "Epoch 1059/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.0623 - accuracy: 0.6057 - val_loss: 1.3102 - val_accuracy: 0.4500\n",
      "Epoch 1060/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0619 - accuracy: 0.6057 - val_loss: 1.3102 - val_accuracy: 0.4467\n",
      "Epoch 1061/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0619 - accuracy: 0.6114 - val_loss: 1.3099 - val_accuracy: 0.4500\n",
      "Epoch 1062/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0615 - accuracy: 0.6029 - val_loss: 1.3105 - val_accuracy: 0.4467\n",
      "Epoch 1063/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0613 - accuracy: 0.6000 - val_loss: 1.3104 - val_accuracy: 0.4467\n",
      "Epoch 1064/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0611 - accuracy: 0.6071 - val_loss: 1.3105 - val_accuracy: 0.4467\n",
      "Epoch 1065/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.0609 - accuracy: 0.6043 - val_loss: 1.3099 - val_accuracy: 0.4467\n",
      "Epoch 1066/3000\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 1.0607 - accuracy: 0.6029 - val_loss: 1.3088 - val_accuracy: 0.4467\n",
      "Epoch 1067/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.0605 - accuracy: 0.6071 - val_loss: 1.3092 - val_accuracy: 0.4500\n",
      "Epoch 1068/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0600 - accuracy: 0.6029 - val_loss: 1.3089 - val_accuracy: 0.4433\n",
      "Epoch 1069/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0600 - accuracy: 0.6071 - val_loss: 1.3088 - val_accuracy: 0.4433\n",
      "Epoch 1070/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0598 - accuracy: 0.6043 - val_loss: 1.3086 - val_accuracy: 0.4433\n",
      "Epoch 1071/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0596 - accuracy: 0.6086 - val_loss: 1.3088 - val_accuracy: 0.4400\n",
      "Epoch 1072/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0592 - accuracy: 0.6057 - val_loss: 1.3094 - val_accuracy: 0.4400\n",
      "Epoch 1073/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0590 - accuracy: 0.6029 - val_loss: 1.3084 - val_accuracy: 0.4433\n",
      "Epoch 1074/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0590 - accuracy: 0.6100 - val_loss: 1.3084 - val_accuracy: 0.4467\n",
      "Epoch 1075/3000\n",
      "700/700 [==============================] - 0s 86us/sample - loss: 1.0587 - accuracy: 0.6043 - val_loss: 1.3081 - val_accuracy: 0.4467\n",
      "Epoch 1076/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.0585 - accuracy: 0.6071 - val_loss: 1.3087 - val_accuracy: 0.4433\n",
      "Epoch 1077/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.0582 - accuracy: 0.6000 - val_loss: 1.3087 - val_accuracy: 0.4433\n",
      "Epoch 1078/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.0581 - accuracy: 0.6029 - val_loss: 1.3083 - val_accuracy: 0.4433\n",
      "Epoch 1079/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.0577 - accuracy: 0.6071 - val_loss: 1.3077 - val_accuracy: 0.4433\n",
      "Epoch 1080/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0575 - accuracy: 0.6100 - val_loss: 1.3085 - val_accuracy: 0.4400\n",
      "Epoch 1081/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0574 - accuracy: 0.6086 - val_loss: 1.3091 - val_accuracy: 0.4400\n",
      "Epoch 1082/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 1.0573 - accuracy: 0.6057 - val_loss: 1.3088 - val_accuracy: 0.4400\n",
      "Epoch 1083/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0569 - accuracy: 0.6071 - val_loss: 1.3079 - val_accuracy: 0.4433\n",
      "Epoch 1084/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.0568 - accuracy: 0.6071 - val_loss: 1.3077 - val_accuracy: 0.4433\n",
      "Epoch 1085/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.0564 - accuracy: 0.6086 - val_loss: 1.3071 - val_accuracy: 0.4433\n",
      "Epoch 1086/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.0563 - accuracy: 0.6129 - val_loss: 1.3079 - val_accuracy: 0.4433\n",
      "Epoch 1087/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.0560 - accuracy: 0.6000 - val_loss: 1.3070 - val_accuracy: 0.4433\n",
      "Epoch 1088/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0560 - accuracy: 0.6014 - val_loss: 1.3073 - val_accuracy: 0.4433\n",
      "Epoch 1089/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0558 - accuracy: 0.6071 - val_loss: 1.3066 - val_accuracy: 0.4433\n",
      "Epoch 1090/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.0555 - accuracy: 0.6057 - val_loss: 1.3076 - val_accuracy: 0.4400\n",
      "Epoch 1091/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.0552 - accuracy: 0.6057 - val_loss: 1.3079 - val_accuracy: 0.4400\n",
      "Epoch 1092/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.0551 - accuracy: 0.6071 - val_loss: 1.3074 - val_accuracy: 0.4400\n",
      "Epoch 1093/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0548 - accuracy: 0.6100 - val_loss: 1.3073 - val_accuracy: 0.4400\n",
      "Epoch 1094/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0547 - accuracy: 0.6043 - val_loss: 1.3068 - val_accuracy: 0.4500\n",
      "Epoch 1095/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0545 - accuracy: 0.6071 - val_loss: 1.3066 - val_accuracy: 0.4500\n",
      "Epoch 1096/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0543 - accuracy: 0.6000 - val_loss: 1.3061 - val_accuracy: 0.4400\n",
      "Epoch 1097/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0539 - accuracy: 0.6086 - val_loss: 1.3060 - val_accuracy: 0.4400\n",
      "Epoch 1098/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0539 - accuracy: 0.6057 - val_loss: 1.3059 - val_accuracy: 0.4467\n",
      "Epoch 1099/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0534 - accuracy: 0.6071 - val_loss: 1.3070 - val_accuracy: 0.4400\n",
      "Epoch 1100/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0534 - accuracy: 0.6086 - val_loss: 1.3075 - val_accuracy: 0.4400\n",
      "Epoch 1101/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.0531 - accuracy: 0.6043 - val_loss: 1.3068 - val_accuracy: 0.4433\n",
      "Epoch 1102/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0528 - accuracy: 0.6114 - val_loss: 1.3067 - val_accuracy: 0.4433\n",
      "Epoch 1103/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.0528 - accuracy: 0.6043 - val_loss: 1.3068 - val_accuracy: 0.4400\n",
      "Epoch 1104/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0525 - accuracy: 0.6071 - val_loss: 1.3061 - val_accuracy: 0.4433\n",
      "Epoch 1105/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0522 - accuracy: 0.6114 - val_loss: 1.3070 - val_accuracy: 0.4400\n",
      "Epoch 1106/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0521 - accuracy: 0.6057 - val_loss: 1.3064 - val_accuracy: 0.4433\n",
      "Epoch 1107/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0517 - accuracy: 0.6114 - val_loss: 1.3068 - val_accuracy: 0.4400\n",
      "Epoch 1108/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0518 - accuracy: 0.6071 - val_loss: 1.3067 - val_accuracy: 0.4400\n",
      "Epoch 1109/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0515 - accuracy: 0.6057 - val_loss: 1.3070 - val_accuracy: 0.4400\n",
      "Epoch 1110/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0512 - accuracy: 0.6100 - val_loss: 1.3072 - val_accuracy: 0.4467\n",
      "Epoch 1111/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0510 - accuracy: 0.6043 - val_loss: 1.3064 - val_accuracy: 0.4467\n",
      "Epoch 1112/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0507 - accuracy: 0.6029 - val_loss: 1.3069 - val_accuracy: 0.4467\n",
      "Epoch 1113/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0504 - accuracy: 0.6057 - val_loss: 1.3063 - val_accuracy: 0.4433\n",
      "Epoch 1114/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0503 - accuracy: 0.6043 - val_loss: 1.3052 - val_accuracy: 0.4433\n",
      "Epoch 1115/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0503 - accuracy: 0.6100 - val_loss: 1.3060 - val_accuracy: 0.4400\n",
      "Epoch 1116/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.0499 - accuracy: 0.6057 - val_loss: 1.3057 - val_accuracy: 0.4433\n",
      "Epoch 1117/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0497 - accuracy: 0.6114 - val_loss: 1.3054 - val_accuracy: 0.4433\n",
      "Epoch 1118/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0498 - accuracy: 0.6100 - val_loss: 1.3057 - val_accuracy: 0.4467\n",
      "Epoch 1119/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0492 - accuracy: 0.6114 - val_loss: 1.3053 - val_accuracy: 0.4500\n",
      "Epoch 1120/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.0490 - accuracy: 0.6071 - val_loss: 1.3043 - val_accuracy: 0.4467\n",
      "Epoch 1121/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0489 - accuracy: 0.6129 - val_loss: 1.3050 - val_accuracy: 0.4467\n",
      "Epoch 1122/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0488 - accuracy: 0.6043 - val_loss: 1.3051 - val_accuracy: 0.4500\n",
      "Epoch 1123/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 1.0487 - accuracy: 0.6100 - val_loss: 1.3046 - val_accuracy: 0.4467\n",
      "Epoch 1124/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0483 - accuracy: 0.6071 - val_loss: 1.3048 - val_accuracy: 0.4467\n",
      "Epoch 1125/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0481 - accuracy: 0.6114 - val_loss: 1.3056 - val_accuracy: 0.4400\n",
      "Epoch 1126/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0479 - accuracy: 0.6100 - val_loss: 1.3050 - val_accuracy: 0.4467\n",
      "Epoch 1127/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0476 - accuracy: 0.6100 - val_loss: 1.3050 - val_accuracy: 0.4433\n",
      "Epoch 1128/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0476 - accuracy: 0.6114 - val_loss: 1.3047 - val_accuracy: 0.4433\n",
      "Epoch 1129/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.0472 - accuracy: 0.6043 - val_loss: 1.3046 - val_accuracy: 0.4500\n",
      "Epoch 1130/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.0470 - accuracy: 0.6100 - val_loss: 1.3048 - val_accuracy: 0.4467\n",
      "Epoch 1131/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0469 - accuracy: 0.6100 - val_loss: 1.3041 - val_accuracy: 0.4433\n",
      "Epoch 1132/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0465 - accuracy: 0.6043 - val_loss: 1.3042 - val_accuracy: 0.4433\n",
      "Epoch 1133/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0463 - accuracy: 0.6086 - val_loss: 1.3047 - val_accuracy: 0.4467\n",
      "Epoch 1134/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0462 - accuracy: 0.6100 - val_loss: 1.3046 - val_accuracy: 0.4433\n",
      "Epoch 1135/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0460 - accuracy: 0.6114 - val_loss: 1.3049 - val_accuracy: 0.4433\n",
      "Epoch 1136/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 1.0457 - accuracy: 0.6057 - val_loss: 1.3042 - val_accuracy: 0.4500\n",
      "Epoch 1137/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0456 - accuracy: 0.6157 - val_loss: 1.3040 - val_accuracy: 0.4500\n",
      "Epoch 1138/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0454 - accuracy: 0.6043 - val_loss: 1.3035 - val_accuracy: 0.4467\n",
      "Epoch 1139/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0451 - accuracy: 0.6086 - val_loss: 1.3038 - val_accuracy: 0.4500\n",
      "Epoch 1140/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0451 - accuracy: 0.6114 - val_loss: 1.3036 - val_accuracy: 0.4467\n",
      "Epoch 1141/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0448 - accuracy: 0.6100 - val_loss: 1.3034 - val_accuracy: 0.4467\n",
      "Epoch 1142/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0445 - accuracy: 0.6086 - val_loss: 1.3033 - val_accuracy: 0.4467\n",
      "Epoch 1143/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0444 - accuracy: 0.6114 - val_loss: 1.3035 - val_accuracy: 0.4467\n",
      "Epoch 1144/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.0441 - accuracy: 0.6100 - val_loss: 1.3039 - val_accuracy: 0.4467\n",
      "Epoch 1145/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0440 - accuracy: 0.6186 - val_loss: 1.3036 - val_accuracy: 0.4467\n",
      "Epoch 1146/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.0437 - accuracy: 0.6114 - val_loss: 1.3030 - val_accuracy: 0.4467\n",
      "Epoch 1147/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.0435 - accuracy: 0.6100 - val_loss: 1.3035 - val_accuracy: 0.4467\n",
      "Epoch 1148/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.0432 - accuracy: 0.6057 - val_loss: 1.3022 - val_accuracy: 0.4467\n",
      "Epoch 1149/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0431 - accuracy: 0.6100 - val_loss: 1.3020 - val_accuracy: 0.4500\n",
      "Epoch 1150/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0430 - accuracy: 0.6114 - val_loss: 1.3025 - val_accuracy: 0.4467\n",
      "Epoch 1151/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0428 - accuracy: 0.6143 - val_loss: 1.3029 - val_accuracy: 0.4500\n",
      "Epoch 1152/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0426 - accuracy: 0.6129 - val_loss: 1.3026 - val_accuracy: 0.4500\n",
      "Epoch 1153/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0424 - accuracy: 0.6100 - val_loss: 1.3024 - val_accuracy: 0.4500\n",
      "Epoch 1154/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0422 - accuracy: 0.6057 - val_loss: 1.3022 - val_accuracy: 0.4467\n",
      "Epoch 1155/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0420 - accuracy: 0.6114 - val_loss: 1.3027 - val_accuracy: 0.4500\n",
      "Epoch 1156/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0418 - accuracy: 0.6143 - val_loss: 1.3032 - val_accuracy: 0.4500\n",
      "Epoch 1157/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.0415 - accuracy: 0.6114 - val_loss: 1.3027 - val_accuracy: 0.4500\n",
      "Epoch 1158/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.0412 - accuracy: 0.6100 - val_loss: 1.3033 - val_accuracy: 0.4467\n",
      "Epoch 1159/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.0411 - accuracy: 0.6100 - val_loss: 1.3023 - val_accuracy: 0.4467\n",
      "Epoch 1160/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0409 - accuracy: 0.6100 - val_loss: 1.3026 - val_accuracy: 0.4500\n",
      "Epoch 1161/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 1.0408 - accuracy: 0.6143 - val_loss: 1.3028 - val_accuracy: 0.4500\n",
      "Epoch 1162/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0408 - accuracy: 0.6143 - val_loss: 1.3027 - val_accuracy: 0.4533\n",
      "Epoch 1163/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0403 - accuracy: 0.6114 - val_loss: 1.3026 - val_accuracy: 0.4533\n",
      "Epoch 1164/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0400 - accuracy: 0.6143 - val_loss: 1.3027 - val_accuracy: 0.4533\n",
      "Epoch 1165/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0398 - accuracy: 0.6143 - val_loss: 1.3029 - val_accuracy: 0.4533\n",
      "Epoch 1166/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 1.0399 - accuracy: 0.6100 - val_loss: 1.3028 - val_accuracy: 0.4533\n",
      "Epoch 1167/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0394 - accuracy: 0.6043 - val_loss: 1.3012 - val_accuracy: 0.4500\n",
      "Epoch 1168/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0395 - accuracy: 0.6171 - val_loss: 1.3016 - val_accuracy: 0.4500\n",
      "Epoch 1169/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0390 - accuracy: 0.6114 - val_loss: 1.3009 - val_accuracy: 0.4467\n",
      "Epoch 1170/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0390 - accuracy: 0.6143 - val_loss: 1.3016 - val_accuracy: 0.4533\n",
      "Epoch 1171/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0386 - accuracy: 0.6143 - val_loss: 1.3012 - val_accuracy: 0.4533\n",
      "Epoch 1172/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0387 - accuracy: 0.6157 - val_loss: 1.3016 - val_accuracy: 0.4500\n",
      "Epoch 1173/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0383 - accuracy: 0.6157 - val_loss: 1.3022 - val_accuracy: 0.4500\n",
      "Epoch 1174/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0382 - accuracy: 0.6143 - val_loss: 1.3019 - val_accuracy: 0.4533\n",
      "Epoch 1175/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 1.0379 - accuracy: 0.6157 - val_loss: 1.3017 - val_accuracy: 0.4533\n",
      "Epoch 1176/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0377 - accuracy: 0.6129 - val_loss: 1.3023 - val_accuracy: 0.4533\n",
      "Epoch 1177/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0375 - accuracy: 0.6143 - val_loss: 1.3024 - val_accuracy: 0.4533\n",
      "Epoch 1178/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0373 - accuracy: 0.6143 - val_loss: 1.3017 - val_accuracy: 0.4567\n",
      "Epoch 1179/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 1.0371 - accuracy: 0.6129 - val_loss: 1.3008 - val_accuracy: 0.4533\n",
      "Epoch 1180/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0369 - accuracy: 0.6171 - val_loss: 1.3012 - val_accuracy: 0.4533\n",
      "Epoch 1181/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0367 - accuracy: 0.6129 - val_loss: 1.3006 - val_accuracy: 0.4533\n",
      "Epoch 1182/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0365 - accuracy: 0.6129 - val_loss: 1.3009 - val_accuracy: 0.4533\n",
      "Epoch 1183/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0364 - accuracy: 0.6129 - val_loss: 1.3007 - val_accuracy: 0.4567\n",
      "Epoch 1184/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0361 - accuracy: 0.6171 - val_loss: 1.3014 - val_accuracy: 0.4567\n",
      "Epoch 1185/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0359 - accuracy: 0.6171 - val_loss: 1.3017 - val_accuracy: 0.4567\n",
      "Epoch 1186/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0357 - accuracy: 0.6129 - val_loss: 1.3009 - val_accuracy: 0.4567\n",
      "Epoch 1187/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0354 - accuracy: 0.6114 - val_loss: 1.3013 - val_accuracy: 0.4567\n",
      "Epoch 1188/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0353 - accuracy: 0.6129 - val_loss: 1.3013 - val_accuracy: 0.4567\n",
      "Epoch 1189/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0351 - accuracy: 0.6129 - val_loss: 1.3008 - val_accuracy: 0.4567\n",
      "Epoch 1190/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0349 - accuracy: 0.6129 - val_loss: 1.3020 - val_accuracy: 0.4500\n",
      "Epoch 1191/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0347 - accuracy: 0.6143 - val_loss: 1.3004 - val_accuracy: 0.4567\n",
      "Epoch 1192/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0347 - accuracy: 0.6114 - val_loss: 1.3011 - val_accuracy: 0.4533\n",
      "Epoch 1193/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0343 - accuracy: 0.6186 - val_loss: 1.3012 - val_accuracy: 0.4500\n",
      "Epoch 1194/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0342 - accuracy: 0.6171 - val_loss: 1.3007 - val_accuracy: 0.4500\n",
      "Epoch 1195/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0340 - accuracy: 0.6157 - val_loss: 1.3004 - val_accuracy: 0.4467\n",
      "Epoch 1196/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0338 - accuracy: 0.6143 - val_loss: 1.3001 - val_accuracy: 0.4500\n",
      "Epoch 1197/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0336 - accuracy: 0.6157 - val_loss: 1.3001 - val_accuracy: 0.4500\n",
      "Epoch 1198/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0333 - accuracy: 0.6157 - val_loss: 1.2997 - val_accuracy: 0.4533\n",
      "Epoch 1199/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0332 - accuracy: 0.6143 - val_loss: 1.2999 - val_accuracy: 0.4533\n",
      "Epoch 1200/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0329 - accuracy: 0.6129 - val_loss: 1.2998 - val_accuracy: 0.4500\n",
      "Epoch 1201/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0326 - accuracy: 0.6171 - val_loss: 1.3008 - val_accuracy: 0.4533\n",
      "Epoch 1202/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0326 - accuracy: 0.6129 - val_loss: 1.3004 - val_accuracy: 0.4533\n",
      "Epoch 1203/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0324 - accuracy: 0.6157 - val_loss: 1.3001 - val_accuracy: 0.4533\n",
      "Epoch 1204/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0323 - accuracy: 0.6143 - val_loss: 1.2997 - val_accuracy: 0.4500\n",
      "Epoch 1205/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.0319 - accuracy: 0.6200 - val_loss: 1.3002 - val_accuracy: 0.4500\n",
      "Epoch 1206/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0317 - accuracy: 0.6157 - val_loss: 1.2992 - val_accuracy: 0.4500\n",
      "Epoch 1207/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0317 - accuracy: 0.6129 - val_loss: 1.2990 - val_accuracy: 0.4500\n",
      "Epoch 1208/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0315 - accuracy: 0.6171 - val_loss: 1.3002 - val_accuracy: 0.4533\n",
      "Epoch 1209/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0313 - accuracy: 0.6129 - val_loss: 1.3004 - val_accuracy: 0.4533\n",
      "Epoch 1210/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0310 - accuracy: 0.6129 - val_loss: 1.3002 - val_accuracy: 0.4533\n",
      "Epoch 1211/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.0308 - accuracy: 0.6114 - val_loss: 1.3008 - val_accuracy: 0.4500\n",
      "Epoch 1212/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.0307 - accuracy: 0.6157 - val_loss: 1.3000 - val_accuracy: 0.4533\n",
      "Epoch 1213/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0305 - accuracy: 0.6171 - val_loss: 1.2998 - val_accuracy: 0.4533\n",
      "Epoch 1214/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0301 - accuracy: 0.6157 - val_loss: 1.2998 - val_accuracy: 0.4533\n",
      "Epoch 1215/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.0300 - accuracy: 0.6100 - val_loss: 1.2990 - val_accuracy: 0.4500\n",
      "Epoch 1216/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0299 - accuracy: 0.6143 - val_loss: 1.2996 - val_accuracy: 0.4533\n",
      "Epoch 1217/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0296 - accuracy: 0.6157 - val_loss: 1.3003 - val_accuracy: 0.4500\n",
      "Epoch 1218/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0294 - accuracy: 0.6143 - val_loss: 1.2995 - val_accuracy: 0.4533\n",
      "Epoch 1219/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0293 - accuracy: 0.6157 - val_loss: 1.2990 - val_accuracy: 0.4500\n",
      "Epoch 1220/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0292 - accuracy: 0.6186 - val_loss: 1.2988 - val_accuracy: 0.4500\n",
      "Epoch 1221/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0288 - accuracy: 0.6143 - val_loss: 1.2989 - val_accuracy: 0.4533\n",
      "Epoch 1222/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0287 - accuracy: 0.6143 - val_loss: 1.2989 - val_accuracy: 0.4533\n",
      "Epoch 1223/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0285 - accuracy: 0.6214 - val_loss: 1.2991 - val_accuracy: 0.4533\n",
      "Epoch 1224/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0283 - accuracy: 0.6114 - val_loss: 1.2986 - val_accuracy: 0.4533\n",
      "Epoch 1225/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0282 - accuracy: 0.6157 - val_loss: 1.2986 - val_accuracy: 0.4533\n",
      "Epoch 1226/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0279 - accuracy: 0.6171 - val_loss: 1.2993 - val_accuracy: 0.4567\n",
      "Epoch 1227/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0277 - accuracy: 0.6171 - val_loss: 1.2991 - val_accuracy: 0.4567\n",
      "Epoch 1228/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0275 - accuracy: 0.6186 - val_loss: 1.2998 - val_accuracy: 0.4533\n",
      "Epoch 1229/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0271 - accuracy: 0.6186 - val_loss: 1.2999 - val_accuracy: 0.4533\n",
      "Epoch 1230/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0272 - accuracy: 0.6157 - val_loss: 1.2993 - val_accuracy: 0.4567\n",
      "Epoch 1231/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0270 - accuracy: 0.6214 - val_loss: 1.2998 - val_accuracy: 0.4533\n",
      "Epoch 1232/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.0269 - accuracy: 0.6186 - val_loss: 1.2989 - val_accuracy: 0.4567\n",
      "Epoch 1233/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.0265 - accuracy: 0.6186 - val_loss: 1.2990 - val_accuracy: 0.4567\n",
      "Epoch 1234/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.0265 - accuracy: 0.6171 - val_loss: 1.2995 - val_accuracy: 0.4533\n",
      "Epoch 1235/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.0261 - accuracy: 0.6186 - val_loss: 1.3000 - val_accuracy: 0.4533\n",
      "Epoch 1236/3000\n",
      "700/700 [==============================] - 0s 88us/sample - loss: 1.0261 - accuracy: 0.6200 - val_loss: 1.2988 - val_accuracy: 0.4567\n",
      "Epoch 1237/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0259 - accuracy: 0.6171 - val_loss: 1.2984 - val_accuracy: 0.4567\n",
      "Epoch 1238/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0258 - accuracy: 0.6171 - val_loss: 1.2986 - val_accuracy: 0.4533\n",
      "Epoch 1239/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0255 - accuracy: 0.6171 - val_loss: 1.2982 - val_accuracy: 0.4533\n",
      "Epoch 1240/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0253 - accuracy: 0.6171 - val_loss: 1.2991 - val_accuracy: 0.4533\n",
      "Epoch 1241/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0251 - accuracy: 0.6171 - val_loss: 1.2996 - val_accuracy: 0.4567\n",
      "Epoch 1242/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0251 - accuracy: 0.6186 - val_loss: 1.2990 - val_accuracy: 0.4533\n",
      "Epoch 1243/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0247 - accuracy: 0.6171 - val_loss: 1.2999 - val_accuracy: 0.4600\n",
      "Epoch 1244/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0245 - accuracy: 0.6200 - val_loss: 1.2995 - val_accuracy: 0.4600\n",
      "Epoch 1245/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0243 - accuracy: 0.6186 - val_loss: 1.2989 - val_accuracy: 0.4533\n",
      "Epoch 1246/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0241 - accuracy: 0.6186 - val_loss: 1.2984 - val_accuracy: 0.4533\n",
      "Epoch 1247/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0238 - accuracy: 0.6171 - val_loss: 1.2976 - val_accuracy: 0.4533\n",
      "Epoch 1248/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0238 - accuracy: 0.6214 - val_loss: 1.2979 - val_accuracy: 0.4533\n",
      "Epoch 1249/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0236 - accuracy: 0.6186 - val_loss: 1.2979 - val_accuracy: 0.4533\n",
      "Epoch 1250/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0234 - accuracy: 0.6171 - val_loss: 1.2969 - val_accuracy: 0.4533\n",
      "Epoch 1251/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.0231 - accuracy: 0.6186 - val_loss: 1.2985 - val_accuracy: 0.4500\n",
      "Epoch 1252/3000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 1.0228 - accuracy: 0.6171 - val_loss: 1.2988 - val_accuracy: 0.4567\n",
      "Epoch 1253/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0230 - accuracy: 0.6214 - val_loss: 1.2981 - val_accuracy: 0.4500\n",
      "Epoch 1254/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 1.0227 - accuracy: 0.6171 - val_loss: 1.2985 - val_accuracy: 0.4500\n",
      "Epoch 1255/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0226 - accuracy: 0.6157 - val_loss: 1.2984 - val_accuracy: 0.4533\n",
      "Epoch 1256/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0223 - accuracy: 0.6143 - val_loss: 1.2980 - val_accuracy: 0.4500\n",
      "Epoch 1257/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0221 - accuracy: 0.6214 - val_loss: 1.2983 - val_accuracy: 0.4500\n",
      "Epoch 1258/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.0218 - accuracy: 0.6186 - val_loss: 1.2976 - val_accuracy: 0.4533\n",
      "Epoch 1259/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.0217 - accuracy: 0.6171 - val_loss: 1.2975 - val_accuracy: 0.4600\n",
      "Epoch 1260/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0214 - accuracy: 0.6171 - val_loss: 1.2972 - val_accuracy: 0.4567\n",
      "Epoch 1261/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0214 - accuracy: 0.6171 - val_loss: 1.2979 - val_accuracy: 0.4500\n",
      "Epoch 1262/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0210 - accuracy: 0.6243 - val_loss: 1.2990 - val_accuracy: 0.4567\n",
      "Epoch 1263/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0212 - accuracy: 0.6214 - val_loss: 1.2978 - val_accuracy: 0.4500\n",
      "Epoch 1264/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0208 - accuracy: 0.6200 - val_loss: 1.2962 - val_accuracy: 0.4567\n",
      "Epoch 1265/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0205 - accuracy: 0.6214 - val_loss: 1.2981 - val_accuracy: 0.4500\n",
      "Epoch 1266/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0204 - accuracy: 0.6186 - val_loss: 1.2985 - val_accuracy: 0.4533\n",
      "Epoch 1267/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0202 - accuracy: 0.6200 - val_loss: 1.2980 - val_accuracy: 0.4567\n",
      "Epoch 1268/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0201 - accuracy: 0.6214 - val_loss: 1.2976 - val_accuracy: 0.4567\n",
      "Epoch 1269/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0198 - accuracy: 0.6200 - val_loss: 1.2978 - val_accuracy: 0.4567\n",
      "Epoch 1270/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.0198 - accuracy: 0.6200 - val_loss: 1.2973 - val_accuracy: 0.4533\n",
      "Epoch 1271/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0195 - accuracy: 0.6229 - val_loss: 1.2968 - val_accuracy: 0.4567\n",
      "Epoch 1272/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0194 - accuracy: 0.6229 - val_loss: 1.2976 - val_accuracy: 0.4533\n",
      "Epoch 1273/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0191 - accuracy: 0.6186 - val_loss: 1.2973 - val_accuracy: 0.4533\n",
      "Epoch 1274/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.0190 - accuracy: 0.6229 - val_loss: 1.2972 - val_accuracy: 0.4533\n",
      "Epoch 1275/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0187 - accuracy: 0.6229 - val_loss: 1.2969 - val_accuracy: 0.4533\n",
      "Epoch 1276/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0186 - accuracy: 0.6229 - val_loss: 1.2975 - val_accuracy: 0.4567\n",
      "Epoch 1277/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.0184 - accuracy: 0.6229 - val_loss: 1.2973 - val_accuracy: 0.4567\n",
      "Epoch 1278/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0182 - accuracy: 0.6171 - val_loss: 1.2970 - val_accuracy: 0.4533\n",
      "Epoch 1279/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0179 - accuracy: 0.6243 - val_loss: 1.2978 - val_accuracy: 0.4600\n",
      "Epoch 1280/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0179 - accuracy: 0.6229 - val_loss: 1.2977 - val_accuracy: 0.4567\n",
      "Epoch 1281/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0176 - accuracy: 0.6171 - val_loss: 1.2967 - val_accuracy: 0.4567\n",
      "Epoch 1282/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0176 - accuracy: 0.6229 - val_loss: 1.2968 - val_accuracy: 0.4533\n",
      "Epoch 1283/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0174 - accuracy: 0.6214 - val_loss: 1.2966 - val_accuracy: 0.4567\n",
      "Epoch 1284/3000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 1.0171 - accuracy: 0.6243 - val_loss: 1.2969 - val_accuracy: 0.4533\n",
      "Epoch 1285/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.0169 - accuracy: 0.6229 - val_loss: 1.2973 - val_accuracy: 0.4533\n",
      "Epoch 1286/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0168 - accuracy: 0.6229 - val_loss: 1.2978 - val_accuracy: 0.4567\n",
      "Epoch 1287/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0166 - accuracy: 0.6257 - val_loss: 1.2976 - val_accuracy: 0.4533\n",
      "Epoch 1288/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0164 - accuracy: 0.6243 - val_loss: 1.2970 - val_accuracy: 0.4500\n",
      "Epoch 1289/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0161 - accuracy: 0.6286 - val_loss: 1.2982 - val_accuracy: 0.4567\n",
      "Epoch 1290/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0160 - accuracy: 0.6243 - val_loss: 1.2971 - val_accuracy: 0.4533\n",
      "Epoch 1291/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.0156 - accuracy: 0.6257 - val_loss: 1.2985 - val_accuracy: 0.4567\n",
      "Epoch 1292/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0156 - accuracy: 0.6214 - val_loss: 1.2968 - val_accuracy: 0.4533\n",
      "Epoch 1293/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0154 - accuracy: 0.6257 - val_loss: 1.2970 - val_accuracy: 0.4533\n",
      "Epoch 1294/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0152 - accuracy: 0.6257 - val_loss: 1.2969 - val_accuracy: 0.4533\n",
      "Epoch 1295/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0150 - accuracy: 0.6214 - val_loss: 1.2960 - val_accuracy: 0.4500\n",
      "Epoch 1296/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0149 - accuracy: 0.6229 - val_loss: 1.2961 - val_accuracy: 0.4533\n",
      "Epoch 1297/3000\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 1.0146 - accuracy: 0.6271 - val_loss: 1.2970 - val_accuracy: 0.4533\n",
      "Epoch 1298/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.0145 - accuracy: 0.6229 - val_loss: 1.2969 - val_accuracy: 0.4567\n",
      "Epoch 1299/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0144 - accuracy: 0.6257 - val_loss: 1.2968 - val_accuracy: 0.4533\n",
      "Epoch 1300/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0142 - accuracy: 0.6257 - val_loss: 1.2970 - val_accuracy: 0.4567\n",
      "Epoch 1301/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0141 - accuracy: 0.6257 - val_loss: 1.2969 - val_accuracy: 0.4533\n",
      "Epoch 1302/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0140 - accuracy: 0.6286 - val_loss: 1.2970 - val_accuracy: 0.4533\n",
      "Epoch 1303/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0138 - accuracy: 0.6243 - val_loss: 1.2965 - val_accuracy: 0.4533\n",
      "Epoch 1304/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.0137 - accuracy: 0.6229 - val_loss: 1.2971 - val_accuracy: 0.4567\n",
      "Epoch 1305/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0132 - accuracy: 0.6286 - val_loss: 1.2973 - val_accuracy: 0.4567\n",
      "Epoch 1306/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0131 - accuracy: 0.6243 - val_loss: 1.2972 - val_accuracy: 0.4567\n",
      "Epoch 1307/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0129 - accuracy: 0.6286 - val_loss: 1.2978 - val_accuracy: 0.4567\n",
      "Epoch 1308/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0127 - accuracy: 0.6243 - val_loss: 1.2960 - val_accuracy: 0.4533\n",
      "Epoch 1309/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0125 - accuracy: 0.6257 - val_loss: 1.2957 - val_accuracy: 0.4533\n",
      "Epoch 1310/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0122 - accuracy: 0.6286 - val_loss: 1.2975 - val_accuracy: 0.4567\n",
      "Epoch 1311/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0121 - accuracy: 0.6243 - val_loss: 1.2971 - val_accuracy: 0.4567\n",
      "Epoch 1312/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0120 - accuracy: 0.6286 - val_loss: 1.2973 - val_accuracy: 0.4567\n",
      "Epoch 1313/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0118 - accuracy: 0.6214 - val_loss: 1.2955 - val_accuracy: 0.4533\n",
      "Epoch 1314/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0117 - accuracy: 0.6257 - val_loss: 1.2955 - val_accuracy: 0.4533\n",
      "Epoch 1315/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0113 - accuracy: 0.6257 - val_loss: 1.2970 - val_accuracy: 0.4567\n",
      "Epoch 1316/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0112 - accuracy: 0.6286 - val_loss: 1.2972 - val_accuracy: 0.4567\n",
      "Epoch 1317/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.0111 - accuracy: 0.6257 - val_loss: 1.2971 - val_accuracy: 0.4567\n",
      "Epoch 1318/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.0107 - accuracy: 0.6271 - val_loss: 1.2961 - val_accuracy: 0.4567\n",
      "Epoch 1319/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.0105 - accuracy: 0.6329 - val_loss: 1.2963 - val_accuracy: 0.4567\n",
      "Epoch 1320/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0106 - accuracy: 0.6300 - val_loss: 1.2965 - val_accuracy: 0.4567\n",
      "Epoch 1321/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0103 - accuracy: 0.6257 - val_loss: 1.2965 - val_accuracy: 0.4567\n",
      "Epoch 1322/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0100 - accuracy: 0.6257 - val_loss: 1.2972 - val_accuracy: 0.4567\n",
      "Epoch 1323/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0097 - accuracy: 0.6300 - val_loss: 1.2971 - val_accuracy: 0.4567\n",
      "Epoch 1324/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0097 - accuracy: 0.6271 - val_loss: 1.2956 - val_accuracy: 0.4567\n",
      "Epoch 1325/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0095 - accuracy: 0.6314 - val_loss: 1.2959 - val_accuracy: 0.4567\n",
      "Epoch 1326/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.0092 - accuracy: 0.6314 - val_loss: 1.2958 - val_accuracy: 0.4567\n",
      "Epoch 1327/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0090 - accuracy: 0.6286 - val_loss: 1.2958 - val_accuracy: 0.4567\n",
      "Epoch 1328/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0089 - accuracy: 0.6286 - val_loss: 1.2961 - val_accuracy: 0.4567\n",
      "Epoch 1329/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0085 - accuracy: 0.6271 - val_loss: 1.2961 - val_accuracy: 0.4567\n",
      "Epoch 1330/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0084 - accuracy: 0.6271 - val_loss: 1.2965 - val_accuracy: 0.4600\n",
      "Epoch 1331/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.0082 - accuracy: 0.6314 - val_loss: 1.2970 - val_accuracy: 0.4600\n",
      "Epoch 1332/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.0081 - accuracy: 0.6243 - val_loss: 1.2951 - val_accuracy: 0.4533\n",
      "Epoch 1333/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0077 - accuracy: 0.6286 - val_loss: 1.2943 - val_accuracy: 0.4500\n",
      "Epoch 1334/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0077 - accuracy: 0.6286 - val_loss: 1.2953 - val_accuracy: 0.4533\n",
      "Epoch 1335/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0075 - accuracy: 0.6257 - val_loss: 1.2949 - val_accuracy: 0.4533\n",
      "Epoch 1336/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.0072 - accuracy: 0.6314 - val_loss: 1.2958 - val_accuracy: 0.4567\n",
      "Epoch 1337/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0070 - accuracy: 0.6271 - val_loss: 1.2952 - val_accuracy: 0.4567\n",
      "Epoch 1338/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0070 - accuracy: 0.6271 - val_loss: 1.2948 - val_accuracy: 0.4533\n",
      "Epoch 1339/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0067 - accuracy: 0.6286 - val_loss: 1.2944 - val_accuracy: 0.4567\n",
      "Epoch 1340/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0065 - accuracy: 0.6271 - val_loss: 1.2946 - val_accuracy: 0.4533\n",
      "Epoch 1341/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0062 - accuracy: 0.6271 - val_loss: 1.2949 - val_accuracy: 0.4567\n",
      "Epoch 1342/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0063 - accuracy: 0.6300 - val_loss: 1.2951 - val_accuracy: 0.4567\n",
      "Epoch 1343/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0058 - accuracy: 0.6271 - val_loss: 1.2957 - val_accuracy: 0.4567\n",
      "Epoch 1344/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0057 - accuracy: 0.6314 - val_loss: 1.2953 - val_accuracy: 0.4567\n",
      "Epoch 1345/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0057 - accuracy: 0.6271 - val_loss: 1.2952 - val_accuracy: 0.4533\n",
      "Epoch 1346/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0054 - accuracy: 0.6271 - val_loss: 1.2955 - val_accuracy: 0.4567\n",
      "Epoch 1347/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0050 - accuracy: 0.6257 - val_loss: 1.2944 - val_accuracy: 0.4533\n",
      "Epoch 1348/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0050 - accuracy: 0.6257 - val_loss: 1.2935 - val_accuracy: 0.4533\n",
      "Epoch 1349/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0048 - accuracy: 0.6314 - val_loss: 1.2948 - val_accuracy: 0.4567\n",
      "Epoch 1350/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0046 - accuracy: 0.6243 - val_loss: 1.2945 - val_accuracy: 0.4567\n",
      "Epoch 1351/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.0045 - accuracy: 0.6286 - val_loss: 1.2946 - val_accuracy: 0.4567\n",
      "Epoch 1352/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0041 - accuracy: 0.6329 - val_loss: 1.2953 - val_accuracy: 0.4567\n",
      "Epoch 1353/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0039 - accuracy: 0.6271 - val_loss: 1.2957 - val_accuracy: 0.4567\n",
      "Epoch 1354/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0038 - accuracy: 0.6300 - val_loss: 1.2962 - val_accuracy: 0.4567\n",
      "Epoch 1355/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0039 - accuracy: 0.6243 - val_loss: 1.2958 - val_accuracy: 0.4567\n",
      "Epoch 1356/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0033 - accuracy: 0.6300 - val_loss: 1.2948 - val_accuracy: 0.4567\n",
      "Epoch 1357/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.0031 - accuracy: 0.6271 - val_loss: 1.2950 - val_accuracy: 0.4567\n",
      "Epoch 1358/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0031 - accuracy: 0.6286 - val_loss: 1.2941 - val_accuracy: 0.4567\n",
      "Epoch 1359/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0030 - accuracy: 0.6286 - val_loss: 1.2948 - val_accuracy: 0.4567\n",
      "Epoch 1360/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0027 - accuracy: 0.6271 - val_loss: 1.2936 - val_accuracy: 0.4567\n",
      "Epoch 1361/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0024 - accuracy: 0.6286 - val_loss: 1.2959 - val_accuracy: 0.4567\n",
      "Epoch 1362/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0024 - accuracy: 0.6300 - val_loss: 1.2954 - val_accuracy: 0.4567\n",
      "Epoch 1363/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0023 - accuracy: 0.6271 - val_loss: 1.2945 - val_accuracy: 0.4567\n",
      "Epoch 1364/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0019 - accuracy: 0.6343 - val_loss: 1.2953 - val_accuracy: 0.4567\n",
      "Epoch 1365/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.0018 - accuracy: 0.6286 - val_loss: 1.2944 - val_accuracy: 0.4567\n",
      "Epoch 1366/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.0016 - accuracy: 0.6286 - val_loss: 1.2953 - val_accuracy: 0.4567\n",
      "Epoch 1367/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0013 - accuracy: 0.6271 - val_loss: 1.2953 - val_accuracy: 0.4567\n",
      "Epoch 1368/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.0012 - accuracy: 0.6271 - val_loss: 1.2955 - val_accuracy: 0.4567\n",
      "Epoch 1369/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0010 - accuracy: 0.6229 - val_loss: 1.2944 - val_accuracy: 0.4567\n",
      "Epoch 1370/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0009 - accuracy: 0.6300 - val_loss: 1.2959 - val_accuracy: 0.4567\n",
      "Epoch 1371/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.0008 - accuracy: 0.6271 - val_loss: 1.2949 - val_accuracy: 0.4567\n",
      "Epoch 1372/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0004 - accuracy: 0.6300 - val_loss: 1.2943 - val_accuracy: 0.4567\n",
      "Epoch 1373/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0003 - accuracy: 0.6300 - val_loss: 1.2934 - val_accuracy: 0.4567\n",
      "Epoch 1374/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.0000 - accuracy: 0.6300 - val_loss: 1.2936 - val_accuracy: 0.4567\n",
      "Epoch 1375/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.0002 - accuracy: 0.6300 - val_loss: 1.2943 - val_accuracy: 0.4567\n",
      "Epoch 1376/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9998 - accuracy: 0.6300 - val_loss: 1.2945 - val_accuracy: 0.4567\n",
      "Epoch 1377/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9997 - accuracy: 0.6271 - val_loss: 1.2945 - val_accuracy: 0.4567\n",
      "Epoch 1378/3000\n",
      "700/700 [==============================] - 0s 126us/sample - loss: 0.9994 - accuracy: 0.6343 - val_loss: 1.2946 - val_accuracy: 0.4567\n",
      "Epoch 1379/3000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 0.9990 - accuracy: 0.6286 - val_loss: 1.2954 - val_accuracy: 0.4567\n",
      "Epoch 1380/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.9990 - accuracy: 0.6271 - val_loss: 1.2950 - val_accuracy: 0.4567\n",
      "Epoch 1381/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9990 - accuracy: 0.6271 - val_loss: 1.2943 - val_accuracy: 0.4567\n",
      "Epoch 1382/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.9985 - accuracy: 0.6300 - val_loss: 1.2942 - val_accuracy: 0.4567\n",
      "Epoch 1383/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.9985 - accuracy: 0.6257 - val_loss: 1.2945 - val_accuracy: 0.4567\n",
      "Epoch 1384/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9982 - accuracy: 0.6329 - val_loss: 1.2936 - val_accuracy: 0.4600\n",
      "Epoch 1385/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9982 - accuracy: 0.6300 - val_loss: 1.2942 - val_accuracy: 0.4567\n",
      "Epoch 1386/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9980 - accuracy: 0.6300 - val_loss: 1.2940 - val_accuracy: 0.4567\n",
      "Epoch 1387/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9977 - accuracy: 0.6214 - val_loss: 1.2937 - val_accuracy: 0.4600\n",
      "Epoch 1388/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9977 - accuracy: 0.6271 - val_loss: 1.2943 - val_accuracy: 0.4567\n",
      "Epoch 1389/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9973 - accuracy: 0.6257 - val_loss: 1.2927 - val_accuracy: 0.4600\n",
      "Epoch 1390/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.9973 - accuracy: 0.6329 - val_loss: 1.2934 - val_accuracy: 0.4567\n",
      "Epoch 1391/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9969 - accuracy: 0.6343 - val_loss: 1.2937 - val_accuracy: 0.4567\n",
      "Epoch 1392/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9969 - accuracy: 0.6229 - val_loss: 1.2931 - val_accuracy: 0.4567\n",
      "Epoch 1393/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9967 - accuracy: 0.6329 - val_loss: 1.2940 - val_accuracy: 0.4567\n",
      "Epoch 1394/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9964 - accuracy: 0.6314 - val_loss: 1.2942 - val_accuracy: 0.4567\n",
      "Epoch 1395/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9962 - accuracy: 0.6300 - val_loss: 1.2934 - val_accuracy: 0.4600\n",
      "Epoch 1396/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.9960 - accuracy: 0.6286 - val_loss: 1.2951 - val_accuracy: 0.4567\n",
      "Epoch 1397/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9958 - accuracy: 0.6314 - val_loss: 1.2943 - val_accuracy: 0.4567\n",
      "Epoch 1398/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.9956 - accuracy: 0.6329 - val_loss: 1.2932 - val_accuracy: 0.4600\n",
      "Epoch 1399/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9956 - accuracy: 0.6286 - val_loss: 1.2929 - val_accuracy: 0.4633\n",
      "Epoch 1400/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9954 - accuracy: 0.6257 - val_loss: 1.2936 - val_accuracy: 0.4633\n",
      "Epoch 1401/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.9952 - accuracy: 0.6314 - val_loss: 1.2934 - val_accuracy: 0.4600\n",
      "Epoch 1402/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.9949 - accuracy: 0.6314 - val_loss: 1.2940 - val_accuracy: 0.4567\n",
      "Epoch 1403/3000\n",
      "700/700 [==============================] - 0s 102us/sample - loss: 0.9946 - accuracy: 0.6286 - val_loss: 1.2945 - val_accuracy: 0.4600\n",
      "Epoch 1404/3000\n",
      "700/700 [==============================] - 0s 87us/sample - loss: 0.9947 - accuracy: 0.6329 - val_loss: 1.2940 - val_accuracy: 0.4600\n",
      "Epoch 1405/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.9944 - accuracy: 0.6329 - val_loss: 1.2932 - val_accuracy: 0.4633\n",
      "Epoch 1406/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9943 - accuracy: 0.6286 - val_loss: 1.2931 - val_accuracy: 0.4633\n",
      "Epoch 1407/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9941 - accuracy: 0.6300 - val_loss: 1.2936 - val_accuracy: 0.4600\n",
      "Epoch 1408/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9939 - accuracy: 0.6300 - val_loss: 1.2938 - val_accuracy: 0.4567\n",
      "Epoch 1409/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 0.9936 - accuracy: 0.6343 - val_loss: 1.2949 - val_accuracy: 0.4567\n",
      "Epoch 1410/3000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 0.9936 - accuracy: 0.6300 - val_loss: 1.2944 - val_accuracy: 0.4567\n",
      "Epoch 1411/3000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 0.9935 - accuracy: 0.6314 - val_loss: 1.2932 - val_accuracy: 0.4600\n",
      "Epoch 1412/3000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 0.9930 - accuracy: 0.6314 - val_loss: 1.2945 - val_accuracy: 0.4567\n",
      "Epoch 1413/3000\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 0.9930 - accuracy: 0.6286 - val_loss: 1.2931 - val_accuracy: 0.4600\n",
      "Epoch 1414/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 0.9929 - accuracy: 0.6329 - val_loss: 1.2933 - val_accuracy: 0.4600\n",
      "Epoch 1415/3000\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 0.9926 - accuracy: 0.6343 - val_loss: 1.2937 - val_accuracy: 0.4567\n",
      "Epoch 1416/3000\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 0.9924 - accuracy: 0.6300 - val_loss: 1.2934 - val_accuracy: 0.4600\n",
      "Epoch 1417/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.9921 - accuracy: 0.6357 - val_loss: 1.2932 - val_accuracy: 0.4533\n",
      "Epoch 1418/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9921 - accuracy: 0.6271 - val_loss: 1.2936 - val_accuracy: 0.4533\n",
      "Epoch 1419/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9919 - accuracy: 0.6300 - val_loss: 1.2944 - val_accuracy: 0.4533\n",
      "Epoch 1420/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9918 - accuracy: 0.6314 - val_loss: 1.2941 - val_accuracy: 0.4533\n",
      "Epoch 1421/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9916 - accuracy: 0.6300 - val_loss: 1.2939 - val_accuracy: 0.4567\n",
      "Epoch 1422/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9915 - accuracy: 0.6314 - val_loss: 1.2926 - val_accuracy: 0.4567\n",
      "Epoch 1423/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9910 - accuracy: 0.6314 - val_loss: 1.2938 - val_accuracy: 0.4533\n",
      "Epoch 1424/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.9911 - accuracy: 0.6300 - val_loss: 1.2937 - val_accuracy: 0.4533\n",
      "Epoch 1425/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9908 - accuracy: 0.6357 - val_loss: 1.2933 - val_accuracy: 0.4567\n",
      "Epoch 1426/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9906 - accuracy: 0.6314 - val_loss: 1.2936 - val_accuracy: 0.4567\n",
      "Epoch 1427/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9904 - accuracy: 0.6343 - val_loss: 1.2925 - val_accuracy: 0.4533\n",
      "Epoch 1428/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9904 - accuracy: 0.6329 - val_loss: 1.2928 - val_accuracy: 0.4567\n",
      "Epoch 1429/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9901 - accuracy: 0.6300 - val_loss: 1.2923 - val_accuracy: 0.4700\n",
      "Epoch 1430/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9901 - accuracy: 0.6300 - val_loss: 1.2926 - val_accuracy: 0.4633\n",
      "Epoch 1431/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9897 - accuracy: 0.6329 - val_loss: 1.2932 - val_accuracy: 0.4567\n",
      "Epoch 1432/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9895 - accuracy: 0.6343 - val_loss: 1.2928 - val_accuracy: 0.4567\n",
      "Epoch 1433/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9894 - accuracy: 0.6314 - val_loss: 1.2934 - val_accuracy: 0.4533\n",
      "Epoch 1434/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9892 - accuracy: 0.6300 - val_loss: 1.2929 - val_accuracy: 0.4600\n",
      "Epoch 1435/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9889 - accuracy: 0.6343 - val_loss: 1.2934 - val_accuracy: 0.4567\n",
      "Epoch 1436/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.9888 - accuracy: 0.6329 - val_loss: 1.2936 - val_accuracy: 0.4533\n",
      "Epoch 1437/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9886 - accuracy: 0.6314 - val_loss: 1.2924 - val_accuracy: 0.4633\n",
      "Epoch 1438/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9885 - accuracy: 0.6371 - val_loss: 1.2914 - val_accuracy: 0.4700\n",
      "Epoch 1439/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9882 - accuracy: 0.6343 - val_loss: 1.2926 - val_accuracy: 0.4667\n",
      "Epoch 1440/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9881 - accuracy: 0.6343 - val_loss: 1.2916 - val_accuracy: 0.4700\n",
      "Epoch 1441/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9880 - accuracy: 0.6314 - val_loss: 1.2929 - val_accuracy: 0.4667\n",
      "Epoch 1442/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9877 - accuracy: 0.6314 - val_loss: 1.2919 - val_accuracy: 0.4700\n",
      "Epoch 1443/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9876 - accuracy: 0.6371 - val_loss: 1.2924 - val_accuracy: 0.4667\n",
      "Epoch 1444/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9875 - accuracy: 0.6343 - val_loss: 1.2921 - val_accuracy: 0.4667\n",
      "Epoch 1445/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9871 - accuracy: 0.6329 - val_loss: 1.2922 - val_accuracy: 0.4633\n",
      "Epoch 1446/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9869 - accuracy: 0.6357 - val_loss: 1.2920 - val_accuracy: 0.4667\n",
      "Epoch 1447/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.9868 - accuracy: 0.6357 - val_loss: 1.2934 - val_accuracy: 0.4600\n",
      "Epoch 1448/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9867 - accuracy: 0.6357 - val_loss: 1.2917 - val_accuracy: 0.4700\n",
      "Epoch 1449/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9864 - accuracy: 0.6343 - val_loss: 1.2918 - val_accuracy: 0.4667\n",
      "Epoch 1450/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.9863 - accuracy: 0.6371 - val_loss: 1.2927 - val_accuracy: 0.4633\n",
      "Epoch 1451/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.9860 - accuracy: 0.6371 - val_loss: 1.2914 - val_accuracy: 0.4700\n",
      "Epoch 1452/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9863 - accuracy: 0.6314 - val_loss: 1.2915 - val_accuracy: 0.4700\n",
      "Epoch 1453/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.9859 - accuracy: 0.6357 - val_loss: 1.2921 - val_accuracy: 0.4667\n",
      "Epoch 1454/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.9858 - accuracy: 0.6371 - val_loss: 1.2918 - val_accuracy: 0.4700\n",
      "Epoch 1455/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.9855 - accuracy: 0.6357 - val_loss: 1.2926 - val_accuracy: 0.4667\n",
      "Epoch 1456/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.9853 - accuracy: 0.6400 - val_loss: 1.2927 - val_accuracy: 0.4633\n",
      "Epoch 1457/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9850 - accuracy: 0.6400 - val_loss: 1.2927 - val_accuracy: 0.4633\n",
      "Epoch 1458/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9850 - accuracy: 0.6343 - val_loss: 1.2917 - val_accuracy: 0.4667\n",
      "Epoch 1459/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9848 - accuracy: 0.6357 - val_loss: 1.2921 - val_accuracy: 0.4633\n",
      "Epoch 1460/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.9844 - accuracy: 0.6386 - val_loss: 1.2915 - val_accuracy: 0.4700\n",
      "Epoch 1461/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.9845 - accuracy: 0.6357 - val_loss: 1.2919 - val_accuracy: 0.4667\n",
      "Epoch 1462/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.9842 - accuracy: 0.6400 - val_loss: 1.2911 - val_accuracy: 0.4700\n",
      "Epoch 1463/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.9841 - accuracy: 0.6414 - val_loss: 1.2923 - val_accuracy: 0.4600\n",
      "Epoch 1464/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9840 - accuracy: 0.6343 - val_loss: 1.2920 - val_accuracy: 0.4633\n",
      "Epoch 1465/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9837 - accuracy: 0.6343 - val_loss: 1.2920 - val_accuracy: 0.4667\n",
      "Epoch 1466/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9835 - accuracy: 0.6329 - val_loss: 1.2917 - val_accuracy: 0.4700\n",
      "Epoch 1467/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9833 - accuracy: 0.6371 - val_loss: 1.2920 - val_accuracy: 0.4667\n",
      "Epoch 1468/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9832 - accuracy: 0.6371 - val_loss: 1.2928 - val_accuracy: 0.4633\n",
      "Epoch 1469/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 0.9829 - accuracy: 0.6371 - val_loss: 1.2932 - val_accuracy: 0.4567\n",
      "Epoch 1470/3000\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 0.9828 - accuracy: 0.6357 - val_loss: 1.2919 - val_accuracy: 0.4667\n",
      "Epoch 1471/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9827 - accuracy: 0.6357 - val_loss: 1.2916 - val_accuracy: 0.4633\n",
      "Epoch 1472/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9824 - accuracy: 0.6386 - val_loss: 1.2926 - val_accuracy: 0.4600\n",
      "Epoch 1473/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9823 - accuracy: 0.6371 - val_loss: 1.2923 - val_accuracy: 0.4633\n",
      "Epoch 1474/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9821 - accuracy: 0.6371 - val_loss: 1.2923 - val_accuracy: 0.4633\n",
      "Epoch 1475/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.9821 - accuracy: 0.6371 - val_loss: 1.2913 - val_accuracy: 0.4700\n",
      "Epoch 1476/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.9819 - accuracy: 0.6371 - val_loss: 1.2910 - val_accuracy: 0.4700\n",
      "Epoch 1477/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9818 - accuracy: 0.6343 - val_loss: 1.2920 - val_accuracy: 0.4633\n",
      "Epoch 1478/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9815 - accuracy: 0.6400 - val_loss: 1.2926 - val_accuracy: 0.4600\n",
      "Epoch 1479/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9813 - accuracy: 0.6357 - val_loss: 1.2914 - val_accuracy: 0.4700\n",
      "Epoch 1480/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9813 - accuracy: 0.6400 - val_loss: 1.2922 - val_accuracy: 0.4667\n",
      "Epoch 1481/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.9808 - accuracy: 0.6414 - val_loss: 1.2916 - val_accuracy: 0.4700\n",
      "Epoch 1482/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9806 - accuracy: 0.6371 - val_loss: 1.2904 - val_accuracy: 0.4700\n",
      "Epoch 1483/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9806 - accuracy: 0.6414 - val_loss: 1.2907 - val_accuracy: 0.4700\n",
      "Epoch 1484/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9804 - accuracy: 0.6329 - val_loss: 1.2911 - val_accuracy: 0.4700\n",
      "Epoch 1485/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9802 - accuracy: 0.6386 - val_loss: 1.2917 - val_accuracy: 0.4600\n",
      "Epoch 1486/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9802 - accuracy: 0.6386 - val_loss: 1.2918 - val_accuracy: 0.4633\n",
      "Epoch 1487/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9800 - accuracy: 0.6386 - val_loss: 1.2910 - val_accuracy: 0.4700\n",
      "Epoch 1488/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9798 - accuracy: 0.6371 - val_loss: 1.2912 - val_accuracy: 0.4700\n",
      "Epoch 1489/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9796 - accuracy: 0.6429 - val_loss: 1.2904 - val_accuracy: 0.4733\n",
      "Epoch 1490/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9795 - accuracy: 0.6414 - val_loss: 1.2905 - val_accuracy: 0.4733\n",
      "Epoch 1491/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9792 - accuracy: 0.6371 - val_loss: 1.2926 - val_accuracy: 0.4633\n",
      "Epoch 1492/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9791 - accuracy: 0.6371 - val_loss: 1.2923 - val_accuracy: 0.4667\n",
      "Epoch 1493/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9790 - accuracy: 0.6357 - val_loss: 1.2917 - val_accuracy: 0.4700\n",
      "Epoch 1494/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9788 - accuracy: 0.6386 - val_loss: 1.2926 - val_accuracy: 0.4633\n",
      "Epoch 1495/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9785 - accuracy: 0.6414 - val_loss: 1.2911 - val_accuracy: 0.4700\n",
      "Epoch 1496/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9785 - accuracy: 0.6386 - val_loss: 1.2912 - val_accuracy: 0.4700\n",
      "Epoch 1497/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9784 - accuracy: 0.6343 - val_loss: 1.2908 - val_accuracy: 0.4700\n",
      "Epoch 1498/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9780 - accuracy: 0.6357 - val_loss: 1.2915 - val_accuracy: 0.4700\n",
      "Epoch 1499/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9779 - accuracy: 0.6329 - val_loss: 1.2913 - val_accuracy: 0.4667\n",
      "Epoch 1500/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.9778 - accuracy: 0.6371 - val_loss: 1.2914 - val_accuracy: 0.4700\n",
      "Epoch 1501/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9776 - accuracy: 0.6357 - val_loss: 1.2908 - val_accuracy: 0.4700\n",
      "Epoch 1502/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9775 - accuracy: 0.6357 - val_loss: 1.2911 - val_accuracy: 0.4700\n",
      "Epoch 1503/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9772 - accuracy: 0.6329 - val_loss: 1.2901 - val_accuracy: 0.4733\n",
      "Epoch 1504/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9771 - accuracy: 0.6371 - val_loss: 1.2909 - val_accuracy: 0.4733\n",
      "Epoch 1505/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9769 - accuracy: 0.6386 - val_loss: 1.2919 - val_accuracy: 0.4667\n",
      "Epoch 1506/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9767 - accuracy: 0.6314 - val_loss: 1.2908 - val_accuracy: 0.4700\n",
      "Epoch 1507/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9764 - accuracy: 0.6357 - val_loss: 1.2898 - val_accuracy: 0.4733\n",
      "Epoch 1508/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9764 - accuracy: 0.6386 - val_loss: 1.2900 - val_accuracy: 0.4767\n",
      "Epoch 1509/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9763 - accuracy: 0.6400 - val_loss: 1.2898 - val_accuracy: 0.4733\n",
      "Epoch 1510/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9760 - accuracy: 0.6400 - val_loss: 1.2911 - val_accuracy: 0.4667\n",
      "Epoch 1511/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9760 - accuracy: 0.6400 - val_loss: 1.2911 - val_accuracy: 0.4667\n",
      "Epoch 1512/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9757 - accuracy: 0.6414 - val_loss: 1.2920 - val_accuracy: 0.4633\n",
      "Epoch 1513/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9758 - accuracy: 0.6371 - val_loss: 1.2917 - val_accuracy: 0.4633\n",
      "Epoch 1514/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9753 - accuracy: 0.6400 - val_loss: 1.2918 - val_accuracy: 0.4633\n",
      "Epoch 1515/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9752 - accuracy: 0.6414 - val_loss: 1.2912 - val_accuracy: 0.4733\n",
      "Epoch 1516/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9752 - accuracy: 0.6414 - val_loss: 1.2916 - val_accuracy: 0.4700\n",
      "Epoch 1517/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9750 - accuracy: 0.6371 - val_loss: 1.2904 - val_accuracy: 0.4733\n",
      "Epoch 1518/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9748 - accuracy: 0.6357 - val_loss: 1.2904 - val_accuracy: 0.4733\n",
      "Epoch 1519/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9748 - accuracy: 0.6400 - val_loss: 1.2909 - val_accuracy: 0.4733\n",
      "Epoch 1520/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9747 - accuracy: 0.6371 - val_loss: 1.2909 - val_accuracy: 0.4733\n",
      "Epoch 1521/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9741 - accuracy: 0.6400 - val_loss: 1.2914 - val_accuracy: 0.4700\n",
      "Epoch 1522/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9741 - accuracy: 0.6400 - val_loss: 1.2902 - val_accuracy: 0.4733\n",
      "Epoch 1523/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9740 - accuracy: 0.6429 - val_loss: 1.2909 - val_accuracy: 0.4733\n",
      "Epoch 1524/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9738 - accuracy: 0.6386 - val_loss: 1.2908 - val_accuracy: 0.4733\n",
      "Epoch 1525/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9738 - accuracy: 0.6400 - val_loss: 1.2909 - val_accuracy: 0.4733\n",
      "Epoch 1526/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9734 - accuracy: 0.6414 - val_loss: 1.2907 - val_accuracy: 0.4767\n",
      "Epoch 1527/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9732 - accuracy: 0.6414 - val_loss: 1.2912 - val_accuracy: 0.4700\n",
      "Epoch 1528/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9732 - accuracy: 0.6429 - val_loss: 1.2912 - val_accuracy: 0.4700\n",
      "Epoch 1529/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9729 - accuracy: 0.6414 - val_loss: 1.2903 - val_accuracy: 0.4733\n",
      "Epoch 1530/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9731 - accuracy: 0.6414 - val_loss: 1.2916 - val_accuracy: 0.4667\n",
      "Epoch 1531/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.9727 - accuracy: 0.6371 - val_loss: 1.2906 - val_accuracy: 0.4733\n",
      "Epoch 1532/3000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 0.9724 - accuracy: 0.6414 - val_loss: 1.2907 - val_accuracy: 0.4733\n",
      "Epoch 1533/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.9722 - accuracy: 0.6414 - val_loss: 1.2910 - val_accuracy: 0.4733\n",
      "Epoch 1534/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.9722 - accuracy: 0.6400 - val_loss: 1.2912 - val_accuracy: 0.4733\n",
      "Epoch 1535/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9722 - accuracy: 0.6386 - val_loss: 1.2913 - val_accuracy: 0.4733\n",
      "Epoch 1536/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9717 - accuracy: 0.6429 - val_loss: 1.2909 - val_accuracy: 0.4733\n",
      "Epoch 1537/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.9718 - accuracy: 0.6414 - val_loss: 1.2909 - val_accuracy: 0.4733\n",
      "Epoch 1538/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9715 - accuracy: 0.6414 - val_loss: 1.2903 - val_accuracy: 0.4733\n",
      "Epoch 1539/3000\n",
      "700/700 [==============================] - 0s 98us/sample - loss: 0.9713 - accuracy: 0.6429 - val_loss: 1.2908 - val_accuracy: 0.4767\n",
      "Epoch 1540/3000\n",
      "700/700 [==============================] - 0s 95us/sample - loss: 0.9710 - accuracy: 0.6443 - val_loss: 1.2907 - val_accuracy: 0.4733\n",
      "Epoch 1541/3000\n",
      "700/700 [==============================] - 0s 94us/sample - loss: 0.9710 - accuracy: 0.6414 - val_loss: 1.2913 - val_accuracy: 0.4733\n",
      "Epoch 1542/3000\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 0.9707 - accuracy: 0.6443 - val_loss: 1.2908 - val_accuracy: 0.4733\n",
      "Epoch 1543/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.9706 - accuracy: 0.6429 - val_loss: 1.2902 - val_accuracy: 0.4733\n",
      "Epoch 1544/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.9707 - accuracy: 0.6400 - val_loss: 1.2904 - val_accuracy: 0.4733\n",
      "Epoch 1545/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.9704 - accuracy: 0.6400 - val_loss: 1.2905 - val_accuracy: 0.4733\n",
      "Epoch 1546/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9700 - accuracy: 0.6457 - val_loss: 1.2908 - val_accuracy: 0.4700\n",
      "Epoch 1547/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9701 - accuracy: 0.6400 - val_loss: 1.2897 - val_accuracy: 0.4733\n",
      "Epoch 1548/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9699 - accuracy: 0.6414 - val_loss: 1.2902 - val_accuracy: 0.4733\n",
      "Epoch 1549/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.9697 - accuracy: 0.6429 - val_loss: 1.2906 - val_accuracy: 0.4733\n",
      "Epoch 1550/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.9697 - accuracy: 0.6429 - val_loss: 1.2912 - val_accuracy: 0.4700\n",
      "Epoch 1551/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9695 - accuracy: 0.6457 - val_loss: 1.2911 - val_accuracy: 0.4700\n",
      "Epoch 1552/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9690 - accuracy: 0.6414 - val_loss: 1.2924 - val_accuracy: 0.4633\n",
      "Epoch 1553/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9690 - accuracy: 0.6443 - val_loss: 1.2924 - val_accuracy: 0.4633\n",
      "Epoch 1554/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9689 - accuracy: 0.6471 - val_loss: 1.2908 - val_accuracy: 0.4733\n",
      "Epoch 1555/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.9687 - accuracy: 0.6471 - val_loss: 1.2901 - val_accuracy: 0.4700\n",
      "Epoch 1556/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.9687 - accuracy: 0.6443 - val_loss: 1.2907 - val_accuracy: 0.4733\n",
      "Epoch 1557/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9684 - accuracy: 0.6486 - val_loss: 1.2906 - val_accuracy: 0.4733\n",
      "Epoch 1558/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.9681 - accuracy: 0.6457 - val_loss: 1.2898 - val_accuracy: 0.4700\n",
      "Epoch 1559/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9682 - accuracy: 0.6500 - val_loss: 1.2909 - val_accuracy: 0.4733\n",
      "Epoch 1560/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9679 - accuracy: 0.6500 - val_loss: 1.2910 - val_accuracy: 0.4733\n",
      "Epoch 1561/3000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 0.9679 - accuracy: 0.6457 - val_loss: 1.2913 - val_accuracy: 0.4700\n",
      "Epoch 1562/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.9677 - accuracy: 0.6457 - val_loss: 1.2920 - val_accuracy: 0.4633\n",
      "Epoch 1563/3000\n",
      "700/700 [==============================] - 0s 86us/sample - loss: 0.9675 - accuracy: 0.6500 - val_loss: 1.2918 - val_accuracy: 0.4667\n",
      "Epoch 1564/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9672 - accuracy: 0.6471 - val_loss: 1.2920 - val_accuracy: 0.4667\n",
      "Epoch 1565/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9672 - accuracy: 0.6486 - val_loss: 1.2907 - val_accuracy: 0.4733\n",
      "Epoch 1566/3000\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 0.9670 - accuracy: 0.6486 - val_loss: 1.2904 - val_accuracy: 0.4733\n",
      "Epoch 1567/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9670 - accuracy: 0.6486 - val_loss: 1.2902 - val_accuracy: 0.4733\n",
      "Epoch 1568/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9667 - accuracy: 0.6443 - val_loss: 1.2906 - val_accuracy: 0.4733\n",
      "Epoch 1569/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9667 - accuracy: 0.6486 - val_loss: 1.2908 - val_accuracy: 0.4733\n",
      "Epoch 1570/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9665 - accuracy: 0.6443 - val_loss: 1.2911 - val_accuracy: 0.4733\n",
      "Epoch 1571/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9662 - accuracy: 0.6543 - val_loss: 1.2919 - val_accuracy: 0.4667\n",
      "Epoch 1572/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9660 - accuracy: 0.6514 - val_loss: 1.2906 - val_accuracy: 0.4700\n",
      "Epoch 1573/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9659 - accuracy: 0.6457 - val_loss: 1.2908 - val_accuracy: 0.4733\n",
      "Epoch 1574/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9658 - accuracy: 0.6457 - val_loss: 1.2915 - val_accuracy: 0.4700\n",
      "Epoch 1575/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9657 - accuracy: 0.6529 - val_loss: 1.2902 - val_accuracy: 0.4733\n",
      "Epoch 1576/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9656 - accuracy: 0.6529 - val_loss: 1.2910 - val_accuracy: 0.4700\n",
      "Epoch 1577/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9653 - accuracy: 0.6457 - val_loss: 1.2898 - val_accuracy: 0.4700\n",
      "Epoch 1578/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9651 - accuracy: 0.6457 - val_loss: 1.2888 - val_accuracy: 0.4700\n",
      "Epoch 1579/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9650 - accuracy: 0.6457 - val_loss: 1.2902 - val_accuracy: 0.4700\n",
      "Epoch 1580/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9648 - accuracy: 0.6486 - val_loss: 1.2907 - val_accuracy: 0.4700\n",
      "Epoch 1581/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9646 - accuracy: 0.6486 - val_loss: 1.2909 - val_accuracy: 0.4700\n",
      "Epoch 1582/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9645 - accuracy: 0.6514 - val_loss: 1.2911 - val_accuracy: 0.4700\n",
      "Epoch 1583/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9643 - accuracy: 0.6486 - val_loss: 1.2901 - val_accuracy: 0.4700\n",
      "Epoch 1584/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.9641 - accuracy: 0.6457 - val_loss: 1.2903 - val_accuracy: 0.4733\n",
      "Epoch 1585/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9639 - accuracy: 0.6443 - val_loss: 1.2923 - val_accuracy: 0.4667\n",
      "Epoch 1586/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9640 - accuracy: 0.6529 - val_loss: 1.2908 - val_accuracy: 0.4733\n",
      "Epoch 1587/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9639 - accuracy: 0.6443 - val_loss: 1.2899 - val_accuracy: 0.4700\n",
      "Epoch 1588/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9635 - accuracy: 0.6443 - val_loss: 1.2905 - val_accuracy: 0.4733\n",
      "Epoch 1589/3000\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 0.9634 - accuracy: 0.6500 - val_loss: 1.2907 - val_accuracy: 0.4733\n",
      "Epoch 1590/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.9631 - accuracy: 0.6471 - val_loss: 1.2922 - val_accuracy: 0.4667\n",
      "Epoch 1591/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.9632 - accuracy: 0.6557 - val_loss: 1.2909 - val_accuracy: 0.4733\n",
      "Epoch 1592/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 0.9630 - accuracy: 0.6529 - val_loss: 1.2909 - val_accuracy: 0.4733\n",
      "Epoch 1593/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9628 - accuracy: 0.6486 - val_loss: 1.2903 - val_accuracy: 0.4767\n",
      "Epoch 1594/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9626 - accuracy: 0.6486 - val_loss: 1.2898 - val_accuracy: 0.4733\n",
      "Epoch 1595/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9623 - accuracy: 0.6543 - val_loss: 1.2899 - val_accuracy: 0.4733\n",
      "Epoch 1596/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9622 - accuracy: 0.6500 - val_loss: 1.2902 - val_accuracy: 0.4733\n",
      "Epoch 1597/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9621 - accuracy: 0.6557 - val_loss: 1.2901 - val_accuracy: 0.4733\n",
      "Epoch 1598/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9618 - accuracy: 0.6529 - val_loss: 1.2898 - val_accuracy: 0.4733\n",
      "Epoch 1599/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9616 - accuracy: 0.6571 - val_loss: 1.2884 - val_accuracy: 0.4700\n",
      "Epoch 1600/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9616 - accuracy: 0.6500 - val_loss: 1.2890 - val_accuracy: 0.4733\n",
      "Epoch 1601/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9612 - accuracy: 0.6543 - val_loss: 1.2888 - val_accuracy: 0.4733\n",
      "Epoch 1602/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9611 - accuracy: 0.6471 - val_loss: 1.2905 - val_accuracy: 0.4767\n",
      "Epoch 1603/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.9609 - accuracy: 0.6514 - val_loss: 1.2892 - val_accuracy: 0.4700\n",
      "Epoch 1604/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.9607 - accuracy: 0.6457 - val_loss: 1.2893 - val_accuracy: 0.4700\n",
      "Epoch 1605/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 0.9607 - accuracy: 0.6500 - val_loss: 1.2904 - val_accuracy: 0.4733\n",
      "Epoch 1606/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9605 - accuracy: 0.6514 - val_loss: 1.2897 - val_accuracy: 0.4733\n",
      "Epoch 1607/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9603 - accuracy: 0.6543 - val_loss: 1.2893 - val_accuracy: 0.4700\n",
      "Epoch 1608/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.9602 - accuracy: 0.6586 - val_loss: 1.2895 - val_accuracy: 0.4733\n",
      "Epoch 1609/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9600 - accuracy: 0.6514 - val_loss: 1.2905 - val_accuracy: 0.4733\n",
      "Epoch 1610/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.9598 - accuracy: 0.6500 - val_loss: 1.2902 - val_accuracy: 0.4733\n",
      "Epoch 1611/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9596 - accuracy: 0.6529 - val_loss: 1.2895 - val_accuracy: 0.4700\n",
      "Epoch 1612/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9594 - accuracy: 0.6529 - val_loss: 1.2903 - val_accuracy: 0.4733\n",
      "Epoch 1613/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9593 - accuracy: 0.6514 - val_loss: 1.2894 - val_accuracy: 0.4733\n",
      "Epoch 1614/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 0.9591 - accuracy: 0.6500 - val_loss: 1.2901 - val_accuracy: 0.4733\n",
      "Epoch 1615/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9591 - accuracy: 0.6543 - val_loss: 1.2894 - val_accuracy: 0.4700\n",
      "Epoch 1616/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.9587 - accuracy: 0.6500 - val_loss: 1.2887 - val_accuracy: 0.4700\n",
      "Epoch 1617/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.9585 - accuracy: 0.6529 - val_loss: 1.2888 - val_accuracy: 0.4733\n",
      "Epoch 1618/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 0.9585 - accuracy: 0.6529 - val_loss: 1.2889 - val_accuracy: 0.4700\n",
      "Epoch 1619/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.9583 - accuracy: 0.6486 - val_loss: 1.2897 - val_accuracy: 0.4700\n",
      "Epoch 1620/3000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 0.9583 - accuracy: 0.6486 - val_loss: 1.2892 - val_accuracy: 0.4700\n",
      "Epoch 1621/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 0.9580 - accuracy: 0.6514 - val_loss: 1.2895 - val_accuracy: 0.4700\n",
      "Epoch 1622/3000\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 0.9576 - accuracy: 0.6529 - val_loss: 1.2902 - val_accuracy: 0.4700\n",
      "Epoch 1623/3000\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 0.9576 - accuracy: 0.6514 - val_loss: 1.2904 - val_accuracy: 0.4733\n",
      "Epoch 1624/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.9575 - accuracy: 0.6514 - val_loss: 1.2906 - val_accuracy: 0.4733\n",
      "Epoch 1625/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9571 - accuracy: 0.6529 - val_loss: 1.2904 - val_accuracy: 0.4767\n",
      "Epoch 1626/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9570 - accuracy: 0.6529 - val_loss: 1.2893 - val_accuracy: 0.4700\n",
      "Epoch 1627/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 0.9569 - accuracy: 0.6500 - val_loss: 1.2901 - val_accuracy: 0.4800\n",
      "Epoch 1628/3000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 0.9567 - accuracy: 0.6557 - val_loss: 1.2911 - val_accuracy: 0.4767\n",
      "Epoch 1629/3000\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 0.9567 - accuracy: 0.6543 - val_loss: 1.2893 - val_accuracy: 0.4767\n",
      "Epoch 1630/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9564 - accuracy: 0.6514 - val_loss: 1.2910 - val_accuracy: 0.4767\n",
      "Epoch 1631/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9564 - accuracy: 0.6514 - val_loss: 1.2902 - val_accuracy: 0.4767\n",
      "Epoch 1632/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9561 - accuracy: 0.6571 - val_loss: 1.2896 - val_accuracy: 0.4767\n",
      "Epoch 1633/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9558 - accuracy: 0.6543 - val_loss: 1.2912 - val_accuracy: 0.4800\n",
      "Epoch 1634/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.9559 - accuracy: 0.6514 - val_loss: 1.2907 - val_accuracy: 0.4833\n",
      "Epoch 1635/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9557 - accuracy: 0.6543 - val_loss: 1.2898 - val_accuracy: 0.4767\n",
      "Epoch 1636/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9556 - accuracy: 0.6543 - val_loss: 1.2898 - val_accuracy: 0.4767\n",
      "Epoch 1637/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9554 - accuracy: 0.6500 - val_loss: 1.2899 - val_accuracy: 0.4767\n",
      "Epoch 1638/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.9551 - accuracy: 0.6500 - val_loss: 1.2905 - val_accuracy: 0.4833\n",
      "Epoch 1639/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9550 - accuracy: 0.6529 - val_loss: 1.2893 - val_accuracy: 0.4767\n",
      "Epoch 1640/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9547 - accuracy: 0.6471 - val_loss: 1.2909 - val_accuracy: 0.4767\n",
      "Epoch 1641/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9548 - accuracy: 0.6486 - val_loss: 1.2905 - val_accuracy: 0.4767\n",
      "Epoch 1642/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 0.9546 - accuracy: 0.6543 - val_loss: 1.2901 - val_accuracy: 0.4700\n",
      "Epoch 1643/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.9545 - accuracy: 0.6543 - val_loss: 1.2900 - val_accuracy: 0.4733\n",
      "Epoch 1644/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9542 - accuracy: 0.6557 - val_loss: 1.2902 - val_accuracy: 0.4733\n",
      "Epoch 1645/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9542 - accuracy: 0.6529 - val_loss: 1.2900 - val_accuracy: 0.4733\n",
      "Epoch 1646/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9540 - accuracy: 0.6543 - val_loss: 1.2901 - val_accuracy: 0.4733\n",
      "Epoch 1647/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9535 - accuracy: 0.6543 - val_loss: 1.2889 - val_accuracy: 0.4700\n",
      "Epoch 1648/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9535 - accuracy: 0.6529 - val_loss: 1.2896 - val_accuracy: 0.4800\n",
      "Epoch 1649/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9534 - accuracy: 0.6529 - val_loss: 1.2902 - val_accuracy: 0.4767\n",
      "Epoch 1650/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9533 - accuracy: 0.6529 - val_loss: 1.2897 - val_accuracy: 0.4733\n",
      "Epoch 1651/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9531 - accuracy: 0.6529 - val_loss: 1.2893 - val_accuracy: 0.4767\n",
      "Epoch 1652/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9529 - accuracy: 0.6529 - val_loss: 1.2902 - val_accuracy: 0.4800\n",
      "Epoch 1653/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9529 - accuracy: 0.6529 - val_loss: 1.2899 - val_accuracy: 0.4800\n",
      "Epoch 1654/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 0.9527 - accuracy: 0.6543 - val_loss: 1.2897 - val_accuracy: 0.4800\n",
      "Epoch 1655/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.9525 - accuracy: 0.6529 - val_loss: 1.2901 - val_accuracy: 0.4833\n",
      "Epoch 1656/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.9522 - accuracy: 0.6529 - val_loss: 1.2910 - val_accuracy: 0.4833\n",
      "Epoch 1657/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9520 - accuracy: 0.6529 - val_loss: 1.2911 - val_accuracy: 0.4733\n",
      "Epoch 1658/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9520 - accuracy: 0.6557 - val_loss: 1.2904 - val_accuracy: 0.4800\n",
      "Epoch 1659/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9519 - accuracy: 0.6514 - val_loss: 1.2893 - val_accuracy: 0.4767\n",
      "Epoch 1660/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.9517 - accuracy: 0.6557 - val_loss: 1.2903 - val_accuracy: 0.4767\n",
      "Epoch 1661/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.9514 - accuracy: 0.6514 - val_loss: 1.2909 - val_accuracy: 0.4800\n",
      "Epoch 1662/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9515 - accuracy: 0.6514 - val_loss: 1.2909 - val_accuracy: 0.4767\n",
      "Epoch 1663/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.9513 - accuracy: 0.6557 - val_loss: 1.2904 - val_accuracy: 0.4767\n",
      "Epoch 1664/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9511 - accuracy: 0.6543 - val_loss: 1.2900 - val_accuracy: 0.4800\n",
      "Epoch 1665/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.9509 - accuracy: 0.6543 - val_loss: 1.2898 - val_accuracy: 0.4767\n",
      "Epoch 1666/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9508 - accuracy: 0.6557 - val_loss: 1.2906 - val_accuracy: 0.4767\n",
      "Epoch 1667/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9505 - accuracy: 0.6500 - val_loss: 1.2894 - val_accuracy: 0.4767\n",
      "Epoch 1668/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9504 - accuracy: 0.6514 - val_loss: 1.2897 - val_accuracy: 0.4767\n",
      "Epoch 1669/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9501 - accuracy: 0.6529 - val_loss: 1.2887 - val_accuracy: 0.4767\n",
      "Epoch 1670/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9500 - accuracy: 0.6557 - val_loss: 1.2891 - val_accuracy: 0.4733\n",
      "Epoch 1671/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.9499 - accuracy: 0.6586 - val_loss: 1.2890 - val_accuracy: 0.4767\n",
      "Epoch 1672/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.9498 - accuracy: 0.6529 - val_loss: 1.2892 - val_accuracy: 0.4800\n",
      "Epoch 1673/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9497 - accuracy: 0.6557 - val_loss: 1.2895 - val_accuracy: 0.4800\n",
      "Epoch 1674/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9494 - accuracy: 0.6514 - val_loss: 1.2910 - val_accuracy: 0.4800\n",
      "Epoch 1675/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9491 - accuracy: 0.6514 - val_loss: 1.2901 - val_accuracy: 0.4800\n",
      "Epoch 1676/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9491 - accuracy: 0.6514 - val_loss: 1.2916 - val_accuracy: 0.4667\n",
      "Epoch 1677/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9492 - accuracy: 0.6557 - val_loss: 1.2901 - val_accuracy: 0.4800\n",
      "Epoch 1678/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9489 - accuracy: 0.6543 - val_loss: 1.2899 - val_accuracy: 0.4733\n",
      "Epoch 1679/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9489 - accuracy: 0.6586 - val_loss: 1.2896 - val_accuracy: 0.4767\n",
      "Epoch 1680/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.9485 - accuracy: 0.6529 - val_loss: 1.2898 - val_accuracy: 0.4733\n",
      "Epoch 1681/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.9485 - accuracy: 0.6557 - val_loss: 1.2902 - val_accuracy: 0.4767\n",
      "Epoch 1682/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9483 - accuracy: 0.6543 - val_loss: 1.2898 - val_accuracy: 0.4733\n",
      "Epoch 1683/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9480 - accuracy: 0.6571 - val_loss: 1.2903 - val_accuracy: 0.4833\n",
      "Epoch 1684/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9479 - accuracy: 0.6514 - val_loss: 1.2896 - val_accuracy: 0.4800\n",
      "Epoch 1685/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9477 - accuracy: 0.6543 - val_loss: 1.2879 - val_accuracy: 0.4800\n",
      "Epoch 1686/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9477 - accuracy: 0.6529 - val_loss: 1.2897 - val_accuracy: 0.4800\n",
      "Epoch 1687/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9474 - accuracy: 0.6529 - val_loss: 1.2892 - val_accuracy: 0.4767\n",
      "Epoch 1688/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9474 - accuracy: 0.6571 - val_loss: 1.2895 - val_accuracy: 0.4767\n",
      "Epoch 1689/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.9473 - accuracy: 0.6529 - val_loss: 1.2889 - val_accuracy: 0.4767\n",
      "Epoch 1690/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9471 - accuracy: 0.6514 - val_loss: 1.2894 - val_accuracy: 0.4800\n",
      "Epoch 1691/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9468 - accuracy: 0.6557 - val_loss: 1.2898 - val_accuracy: 0.4767\n",
      "Epoch 1692/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9467 - accuracy: 0.6586 - val_loss: 1.2899 - val_accuracy: 0.4767\n",
      "Epoch 1693/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9467 - accuracy: 0.6543 - val_loss: 1.2897 - val_accuracy: 0.4767\n",
      "Epoch 1694/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9464 - accuracy: 0.6529 - val_loss: 1.2897 - val_accuracy: 0.4767\n",
      "Epoch 1695/3000\n",
      "700/700 [==============================] - 0s 98us/sample - loss: 0.9462 - accuracy: 0.6600 - val_loss: 1.2892 - val_accuracy: 0.4767\n",
      "Epoch 1696/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9460 - accuracy: 0.6543 - val_loss: 1.2904 - val_accuracy: 0.4800\n",
      "Epoch 1697/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9460 - accuracy: 0.6557 - val_loss: 1.2901 - val_accuracy: 0.4800\n",
      "Epoch 1698/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.9459 - accuracy: 0.6543 - val_loss: 1.2892 - val_accuracy: 0.4800\n",
      "Epoch 1699/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.9456 - accuracy: 0.6543 - val_loss: 1.2884 - val_accuracy: 0.4800\n",
      "Epoch 1700/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9456 - accuracy: 0.6486 - val_loss: 1.2891 - val_accuracy: 0.4767\n",
      "Epoch 1701/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.9451 - accuracy: 0.6543 - val_loss: 1.2880 - val_accuracy: 0.4767\n",
      "Epoch 1702/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9453 - accuracy: 0.6571 - val_loss: 1.2887 - val_accuracy: 0.4767\n",
      "Epoch 1703/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9451 - accuracy: 0.6557 - val_loss: 1.2892 - val_accuracy: 0.4800\n",
      "Epoch 1704/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9450 - accuracy: 0.6557 - val_loss: 1.2899 - val_accuracy: 0.4833\n",
      "Epoch 1705/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.9449 - accuracy: 0.6600 - val_loss: 1.2899 - val_accuracy: 0.4833\n",
      "Epoch 1706/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.9447 - accuracy: 0.6514 - val_loss: 1.2894 - val_accuracy: 0.4800\n",
      "Epoch 1707/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9444 - accuracy: 0.6571 - val_loss: 1.2890 - val_accuracy: 0.4800\n",
      "Epoch 1708/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9444 - accuracy: 0.6586 - val_loss: 1.2889 - val_accuracy: 0.4767\n",
      "Epoch 1709/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9442 - accuracy: 0.6586 - val_loss: 1.2889 - val_accuracy: 0.4800\n",
      "Epoch 1710/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9440 - accuracy: 0.6614 - val_loss: 1.2883 - val_accuracy: 0.4800\n",
      "Epoch 1711/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9438 - accuracy: 0.6557 - val_loss: 1.2907 - val_accuracy: 0.4833\n",
      "Epoch 1712/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9438 - accuracy: 0.6586 - val_loss: 1.2893 - val_accuracy: 0.4833\n",
      "Epoch 1713/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9435 - accuracy: 0.6571 - val_loss: 1.2896 - val_accuracy: 0.4800\n",
      "Epoch 1714/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.9435 - accuracy: 0.6586 - val_loss: 1.2904 - val_accuracy: 0.4833\n",
      "Epoch 1715/3000\n",
      "700/700 [==============================] - 0s 87us/sample - loss: 0.9434 - accuracy: 0.6586 - val_loss: 1.2899 - val_accuracy: 0.4800\n",
      "Epoch 1716/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.9432 - accuracy: 0.6557 - val_loss: 1.2898 - val_accuracy: 0.4767\n",
      "Epoch 1717/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.9430 - accuracy: 0.6600 - val_loss: 1.2897 - val_accuracy: 0.4833\n",
      "Epoch 1718/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9427 - accuracy: 0.6571 - val_loss: 1.2887 - val_accuracy: 0.4767\n",
      "Epoch 1719/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9428 - accuracy: 0.6571 - val_loss: 1.2883 - val_accuracy: 0.4733\n",
      "Epoch 1720/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9425 - accuracy: 0.6586 - val_loss: 1.2879 - val_accuracy: 0.4733\n",
      "Epoch 1721/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.9425 - accuracy: 0.6586 - val_loss: 1.2891 - val_accuracy: 0.4733\n",
      "Epoch 1722/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.9423 - accuracy: 0.6586 - val_loss: 1.2896 - val_accuracy: 0.4800\n",
      "Epoch 1723/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9421 - accuracy: 0.6586 - val_loss: 1.2896 - val_accuracy: 0.4767\n",
      "Epoch 1724/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9421 - accuracy: 0.6586 - val_loss: 1.2898 - val_accuracy: 0.4733\n",
      "Epoch 1725/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9419 - accuracy: 0.6571 - val_loss: 1.2893 - val_accuracy: 0.4700\n",
      "Epoch 1726/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9417 - accuracy: 0.6586 - val_loss: 1.2900 - val_accuracy: 0.4800\n",
      "Epoch 1727/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9416 - accuracy: 0.6529 - val_loss: 1.2897 - val_accuracy: 0.4833\n",
      "Epoch 1728/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9415 - accuracy: 0.6600 - val_loss: 1.2891 - val_accuracy: 0.4733\n",
      "Epoch 1729/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9412 - accuracy: 0.6571 - val_loss: 1.2898 - val_accuracy: 0.4800\n",
      "Epoch 1730/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9412 - accuracy: 0.6543 - val_loss: 1.2900 - val_accuracy: 0.4833\n",
      "Epoch 1731/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 0.9409 - accuracy: 0.6600 - val_loss: 1.2895 - val_accuracy: 0.4767\n",
      "Epoch 1732/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.9408 - accuracy: 0.6571 - val_loss: 1.2898 - val_accuracy: 0.4733\n",
      "Epoch 1733/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.9406 - accuracy: 0.6586 - val_loss: 1.2898 - val_accuracy: 0.4767\n",
      "Epoch 1734/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9408 - accuracy: 0.6571 - val_loss: 1.2891 - val_accuracy: 0.4733\n",
      "Epoch 1735/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9403 - accuracy: 0.6586 - val_loss: 1.2892 - val_accuracy: 0.4733\n",
      "Epoch 1736/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9403 - accuracy: 0.6543 - val_loss: 1.2892 - val_accuracy: 0.4700\n",
      "Epoch 1737/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9402 - accuracy: 0.6543 - val_loss: 1.2897 - val_accuracy: 0.4800\n",
      "Epoch 1738/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9399 - accuracy: 0.6571 - val_loss: 1.2905 - val_accuracy: 0.4833\n",
      "Epoch 1739/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9399 - accuracy: 0.6586 - val_loss: 1.2895 - val_accuracy: 0.4733\n",
      "Epoch 1740/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.9397 - accuracy: 0.6557 - val_loss: 1.2899 - val_accuracy: 0.4733\n",
      "Epoch 1741/3000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 0.9394 - accuracy: 0.6571 - val_loss: 1.2905 - val_accuracy: 0.4733\n",
      "Epoch 1742/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.9395 - accuracy: 0.6600 - val_loss: 1.2897 - val_accuracy: 0.4733\n",
      "Epoch 1743/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9392 - accuracy: 0.6600 - val_loss: 1.2899 - val_accuracy: 0.4700\n",
      "Epoch 1744/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9389 - accuracy: 0.6557 - val_loss: 1.2890 - val_accuracy: 0.4767\n",
      "Epoch 1745/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9391 - accuracy: 0.6557 - val_loss: 1.2892 - val_accuracy: 0.4767\n",
      "Epoch 1746/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9389 - accuracy: 0.6600 - val_loss: 1.2894 - val_accuracy: 0.4733\n",
      "Epoch 1747/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9388 - accuracy: 0.6614 - val_loss: 1.2894 - val_accuracy: 0.4767\n",
      "Epoch 1748/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9385 - accuracy: 0.6586 - val_loss: 1.2897 - val_accuracy: 0.4767\n",
      "Epoch 1749/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9383 - accuracy: 0.6614 - val_loss: 1.2888 - val_accuracy: 0.4733\n",
      "Epoch 1750/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 0.9382 - accuracy: 0.6543 - val_loss: 1.2897 - val_accuracy: 0.4800\n",
      "Epoch 1751/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9380 - accuracy: 0.6543 - val_loss: 1.2892 - val_accuracy: 0.4733\n",
      "Epoch 1752/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9381 - accuracy: 0.6586 - val_loss: 1.2906 - val_accuracy: 0.4767\n",
      "Epoch 1753/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9377 - accuracy: 0.6557 - val_loss: 1.2903 - val_accuracy: 0.4800\n",
      "Epoch 1754/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9377 - accuracy: 0.6600 - val_loss: 1.2904 - val_accuracy: 0.4800\n",
      "Epoch 1755/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9376 - accuracy: 0.6571 - val_loss: 1.2896 - val_accuracy: 0.4767\n",
      "Epoch 1756/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9376 - accuracy: 0.6557 - val_loss: 1.2901 - val_accuracy: 0.4800\n",
      "Epoch 1757/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9372 - accuracy: 0.6571 - val_loss: 1.2892 - val_accuracy: 0.4767\n",
      "Epoch 1758/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9372 - accuracy: 0.6600 - val_loss: 1.2899 - val_accuracy: 0.4800\n",
      "Epoch 1759/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9369 - accuracy: 0.6600 - val_loss: 1.2905 - val_accuracy: 0.4800\n",
      "Epoch 1760/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9369 - accuracy: 0.6557 - val_loss: 1.2898 - val_accuracy: 0.4767\n",
      "Epoch 1761/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9365 - accuracy: 0.6571 - val_loss: 1.2906 - val_accuracy: 0.4800\n",
      "Epoch 1762/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9366 - accuracy: 0.6600 - val_loss: 1.2904 - val_accuracy: 0.4767\n",
      "Epoch 1763/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.9363 - accuracy: 0.6600 - val_loss: 1.2914 - val_accuracy: 0.4733\n",
      "Epoch 1764/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9363 - accuracy: 0.6557 - val_loss: 1.2895 - val_accuracy: 0.4733\n",
      "Epoch 1765/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9362 - accuracy: 0.6586 - val_loss: 1.2888 - val_accuracy: 0.4733\n",
      "Epoch 1766/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9360 - accuracy: 0.6557 - val_loss: 1.2898 - val_accuracy: 0.4733\n",
      "Epoch 1767/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 0.9359 - accuracy: 0.6586 - val_loss: 1.2904 - val_accuracy: 0.4767\n",
      "Epoch 1768/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9357 - accuracy: 0.6586 - val_loss: 1.2900 - val_accuracy: 0.4733\n",
      "Epoch 1769/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9356 - accuracy: 0.6586 - val_loss: 1.2895 - val_accuracy: 0.4733\n",
      "Epoch 1770/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9356 - accuracy: 0.6586 - val_loss: 1.2904 - val_accuracy: 0.4767\n",
      "Epoch 1771/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9353 - accuracy: 0.6571 - val_loss: 1.2899 - val_accuracy: 0.4767\n",
      "Epoch 1772/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9353 - accuracy: 0.6557 - val_loss: 1.2906 - val_accuracy: 0.4800\n",
      "Epoch 1773/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9350 - accuracy: 0.6600 - val_loss: 1.2895 - val_accuracy: 0.4767\n",
      "Epoch 1774/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9349 - accuracy: 0.6586 - val_loss: 1.2905 - val_accuracy: 0.4800\n",
      "Epoch 1775/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9347 - accuracy: 0.6586 - val_loss: 1.2909 - val_accuracy: 0.4800\n",
      "Epoch 1776/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9344 - accuracy: 0.6557 - val_loss: 1.2913 - val_accuracy: 0.4800\n",
      "Epoch 1777/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9346 - accuracy: 0.6557 - val_loss: 1.2901 - val_accuracy: 0.4767\n",
      "Epoch 1778/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9343 - accuracy: 0.6571 - val_loss: 1.2906 - val_accuracy: 0.4800\n",
      "Epoch 1779/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9342 - accuracy: 0.6586 - val_loss: 1.2912 - val_accuracy: 0.4767\n",
      "Epoch 1780/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.9341 - accuracy: 0.6614 - val_loss: 1.2894 - val_accuracy: 0.4767\n",
      "Epoch 1781/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9339 - accuracy: 0.6586 - val_loss: 1.2885 - val_accuracy: 0.4700\n",
      "Epoch 1782/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9340 - accuracy: 0.6600 - val_loss: 1.2903 - val_accuracy: 0.4767\n",
      "Epoch 1783/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9335 - accuracy: 0.6571 - val_loss: 1.2895 - val_accuracy: 0.4733\n",
      "Epoch 1784/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9336 - accuracy: 0.6614 - val_loss: 1.2901 - val_accuracy: 0.4767\n",
      "Epoch 1785/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 0.9334 - accuracy: 0.6629 - val_loss: 1.2902 - val_accuracy: 0.4767\n",
      "Epoch 1786/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9333 - accuracy: 0.6600 - val_loss: 1.2903 - val_accuracy: 0.4733\n",
      "Epoch 1787/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9331 - accuracy: 0.6586 - val_loss: 1.2914 - val_accuracy: 0.4800\n",
      "Epoch 1788/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9332 - accuracy: 0.6586 - val_loss: 1.2916 - val_accuracy: 0.4800\n",
      "Epoch 1789/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 0.9331 - accuracy: 0.6586 - val_loss: 1.2904 - val_accuracy: 0.4767\n",
      "Epoch 1790/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9326 - accuracy: 0.6571 - val_loss: 1.2906 - val_accuracy: 0.4767\n",
      "Epoch 1791/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9327 - accuracy: 0.6614 - val_loss: 1.2907 - val_accuracy: 0.4767\n",
      "Epoch 1792/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9325 - accuracy: 0.6643 - val_loss: 1.2912 - val_accuracy: 0.4800\n",
      "Epoch 1793/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9323 - accuracy: 0.6586 - val_loss: 1.2900 - val_accuracy: 0.4733\n",
      "Epoch 1794/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9321 - accuracy: 0.6586 - val_loss: 1.2897 - val_accuracy: 0.4733\n",
      "Epoch 1795/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9321 - accuracy: 0.6571 - val_loss: 1.2900 - val_accuracy: 0.4733\n",
      "Epoch 1796/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9318 - accuracy: 0.6571 - val_loss: 1.2898 - val_accuracy: 0.4733\n",
      "Epoch 1797/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9319 - accuracy: 0.6629 - val_loss: 1.2909 - val_accuracy: 0.4767\n",
      "Epoch 1798/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 0.9315 - accuracy: 0.6586 - val_loss: 1.2898 - val_accuracy: 0.4733\n",
      "Epoch 1799/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9315 - accuracy: 0.6643 - val_loss: 1.2908 - val_accuracy: 0.4767\n",
      "Epoch 1800/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.9312 - accuracy: 0.6600 - val_loss: 1.2912 - val_accuracy: 0.4767\n",
      "Epoch 1801/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9313 - accuracy: 0.6586 - val_loss: 1.2902 - val_accuracy: 0.4767\n",
      "Epoch 1802/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9311 - accuracy: 0.6600 - val_loss: 1.2905 - val_accuracy: 0.4767\n",
      "Epoch 1803/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 0.9310 - accuracy: 0.6586 - val_loss: 1.2905 - val_accuracy: 0.4733\n",
      "Epoch 1804/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9308 - accuracy: 0.6614 - val_loss: 1.2911 - val_accuracy: 0.4767\n",
      "Epoch 1805/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 0.9307 - accuracy: 0.6557 - val_loss: 1.2912 - val_accuracy: 0.4767\n",
      "Epoch 1806/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9304 - accuracy: 0.6571 - val_loss: 1.2897 - val_accuracy: 0.4733\n",
      "Epoch 1807/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9305 - accuracy: 0.6629 - val_loss: 1.2914 - val_accuracy: 0.4767\n",
      "Epoch 1808/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9303 - accuracy: 0.6600 - val_loss: 1.2910 - val_accuracy: 0.4767\n",
      "Epoch 1809/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 0.9302 - accuracy: 0.6600 - val_loss: 1.2907 - val_accuracy: 0.4767\n",
      "Epoch 1810/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9300 - accuracy: 0.6571 - val_loss: 1.2904 - val_accuracy: 0.4767\n",
      "Epoch 1811/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.9299 - accuracy: 0.6571 - val_loss: 1.2906 - val_accuracy: 0.4767\n",
      "Epoch 1812/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9298 - accuracy: 0.6600 - val_loss: 1.2904 - val_accuracy: 0.4733\n",
      "Epoch 1813/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9296 - accuracy: 0.6600 - val_loss: 1.2917 - val_accuracy: 0.4833\n",
      "Epoch 1814/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9294 - accuracy: 0.6629 - val_loss: 1.2910 - val_accuracy: 0.4733\n",
      "Epoch 1815/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9295 - accuracy: 0.6571 - val_loss: 1.2913 - val_accuracy: 0.4767\n",
      "Epoch 1816/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9292 - accuracy: 0.6543 - val_loss: 1.2913 - val_accuracy: 0.4767\n",
      "Epoch 1817/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9291 - accuracy: 0.6614 - val_loss: 1.2911 - val_accuracy: 0.4733\n",
      "Epoch 1818/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9289 - accuracy: 0.6614 - val_loss: 1.2910 - val_accuracy: 0.4733\n",
      "Epoch 1819/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9288 - accuracy: 0.6543 - val_loss: 1.2912 - val_accuracy: 0.4767\n",
      "Epoch 1820/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 0.9286 - accuracy: 0.6614 - val_loss: 1.2904 - val_accuracy: 0.4733\n",
      "Epoch 1821/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9287 - accuracy: 0.6557 - val_loss: 1.2909 - val_accuracy: 0.4733\n",
      "Epoch 1822/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9283 - accuracy: 0.6600 - val_loss: 1.2906 - val_accuracy: 0.4733\n",
      "Epoch 1823/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9283 - accuracy: 0.6643 - val_loss: 1.2921 - val_accuracy: 0.4800\n",
      "Epoch 1824/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9282 - accuracy: 0.6643 - val_loss: 1.2913 - val_accuracy: 0.4767\n",
      "Epoch 1825/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9280 - accuracy: 0.6629 - val_loss: 1.2915 - val_accuracy: 0.4800\n",
      "Epoch 1826/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9279 - accuracy: 0.6600 - val_loss: 1.2909 - val_accuracy: 0.4733\n",
      "Epoch 1827/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9276 - accuracy: 0.6586 - val_loss: 1.2913 - val_accuracy: 0.4733\n",
      "Epoch 1828/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9275 - accuracy: 0.6629 - val_loss: 1.2910 - val_accuracy: 0.4733\n",
      "Epoch 1829/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9275 - accuracy: 0.6629 - val_loss: 1.2914 - val_accuracy: 0.4733\n",
      "Epoch 1830/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9273 - accuracy: 0.6614 - val_loss: 1.2903 - val_accuracy: 0.4733\n",
      "Epoch 1831/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9270 - accuracy: 0.6614 - val_loss: 1.2920 - val_accuracy: 0.4767\n",
      "Epoch 1832/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9271 - accuracy: 0.6586 - val_loss: 1.2919 - val_accuracy: 0.4800\n",
      "Epoch 1833/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9270 - accuracy: 0.6543 - val_loss: 1.2908 - val_accuracy: 0.4767\n",
      "Epoch 1834/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9268 - accuracy: 0.6629 - val_loss: 1.2922 - val_accuracy: 0.4767\n",
      "Epoch 1835/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9267 - accuracy: 0.6614 - val_loss: 1.2906 - val_accuracy: 0.4700\n",
      "Epoch 1836/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9268 - accuracy: 0.6629 - val_loss: 1.2911 - val_accuracy: 0.4733\n",
      "Epoch 1837/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9263 - accuracy: 0.6600 - val_loss: 1.2898 - val_accuracy: 0.4733\n",
      "Epoch 1838/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.9263 - accuracy: 0.6586 - val_loss: 1.2916 - val_accuracy: 0.4733\n",
      "Epoch 1839/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.9260 - accuracy: 0.6586 - val_loss: 1.2909 - val_accuracy: 0.4733\n",
      "Epoch 1840/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.9261 - accuracy: 0.6571 - val_loss: 1.2922 - val_accuracy: 0.4767\n",
      "Epoch 1841/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.9260 - accuracy: 0.6629 - val_loss: 1.2925 - val_accuracy: 0.4767\n",
      "Epoch 1842/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.9258 - accuracy: 0.6600 - val_loss: 1.2921 - val_accuracy: 0.4733\n",
      "Epoch 1843/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9258 - accuracy: 0.6629 - val_loss: 1.2916 - val_accuracy: 0.4733\n",
      "Epoch 1844/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9255 - accuracy: 0.6643 - val_loss: 1.2918 - val_accuracy: 0.4767\n",
      "Epoch 1845/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9254 - accuracy: 0.6557 - val_loss: 1.2916 - val_accuracy: 0.4767\n",
      "Epoch 1846/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.9254 - accuracy: 0.6629 - val_loss: 1.2917 - val_accuracy: 0.4767\n",
      "Epoch 1847/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9253 - accuracy: 0.6557 - val_loss: 1.2923 - val_accuracy: 0.4767\n",
      "Epoch 1848/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.9251 - accuracy: 0.6600 - val_loss: 1.2919 - val_accuracy: 0.4767\n",
      "Epoch 1849/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9249 - accuracy: 0.6600 - val_loss: 1.2918 - val_accuracy: 0.4767\n",
      "Epoch 1850/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9248 - accuracy: 0.6586 - val_loss: 1.2920 - val_accuracy: 0.4733\n",
      "Epoch 1851/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 0.9245 - accuracy: 0.6614 - val_loss: 1.2914 - val_accuracy: 0.4700\n",
      "Epoch 1852/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 0.9245 - accuracy: 0.6629 - val_loss: 1.2917 - val_accuracy: 0.4733\n",
      "Epoch 1853/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9244 - accuracy: 0.6586 - val_loss: 1.2918 - val_accuracy: 0.4700\n",
      "Epoch 1854/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9242 - accuracy: 0.6571 - val_loss: 1.2928 - val_accuracy: 0.4767\n",
      "Epoch 1855/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9242 - accuracy: 0.6571 - val_loss: 1.2923 - val_accuracy: 0.4767\n",
      "Epoch 1856/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 0.9239 - accuracy: 0.6571 - val_loss: 1.2916 - val_accuracy: 0.4733\n",
      "Epoch 1857/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.9239 - accuracy: 0.6614 - val_loss: 1.2926 - val_accuracy: 0.4700\n",
      "Epoch 1858/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.9238 - accuracy: 0.6629 - val_loss: 1.2926 - val_accuracy: 0.4733\n",
      "Epoch 1859/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9236 - accuracy: 0.6614 - val_loss: 1.2928 - val_accuracy: 0.4733\n",
      "Epoch 1860/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9236 - accuracy: 0.6614 - val_loss: 1.2928 - val_accuracy: 0.4700\n",
      "Epoch 1861/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9235 - accuracy: 0.6586 - val_loss: 1.2923 - val_accuracy: 0.4700\n",
      "Epoch 1862/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9233 - accuracy: 0.6557 - val_loss: 1.2926 - val_accuracy: 0.4700\n",
      "Epoch 1863/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9232 - accuracy: 0.6614 - val_loss: 1.2929 - val_accuracy: 0.4733\n",
      "Epoch 1864/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9231 - accuracy: 0.6600 - val_loss: 1.2928 - val_accuracy: 0.4700\n",
      "Epoch 1865/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9227 - accuracy: 0.6629 - val_loss: 1.2920 - val_accuracy: 0.4733\n",
      "Epoch 1866/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9227 - accuracy: 0.6600 - val_loss: 1.2926 - val_accuracy: 0.4733\n",
      "Epoch 1867/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9225 - accuracy: 0.6657 - val_loss: 1.2925 - val_accuracy: 0.4700\n",
      "Epoch 1868/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9227 - accuracy: 0.6614 - val_loss: 1.2927 - val_accuracy: 0.4700\n",
      "Epoch 1869/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9224 - accuracy: 0.6571 - val_loss: 1.2929 - val_accuracy: 0.4700\n",
      "Epoch 1870/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9220 - accuracy: 0.6657 - val_loss: 1.2920 - val_accuracy: 0.4733\n",
      "Epoch 1871/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9224 - accuracy: 0.6586 - val_loss: 1.2929 - val_accuracy: 0.4700\n",
      "Epoch 1872/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9219 - accuracy: 0.6614 - val_loss: 1.2930 - val_accuracy: 0.4733\n",
      "Epoch 1873/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9217 - accuracy: 0.6629 - val_loss: 1.2924 - val_accuracy: 0.4733\n",
      "Epoch 1874/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9217 - accuracy: 0.6643 - val_loss: 1.2931 - val_accuracy: 0.4700\n",
      "Epoch 1875/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9215 - accuracy: 0.6629 - val_loss: 1.2939 - val_accuracy: 0.4733\n",
      "Epoch 1876/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9215 - accuracy: 0.6657 - val_loss: 1.2932 - val_accuracy: 0.4733\n",
      "Epoch 1877/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9212 - accuracy: 0.6629 - val_loss: 1.2934 - val_accuracy: 0.4733\n",
      "Epoch 1878/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9214 - accuracy: 0.6643 - val_loss: 1.2942 - val_accuracy: 0.4700\n",
      "Epoch 1879/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9212 - accuracy: 0.6671 - val_loss: 1.2938 - val_accuracy: 0.4733\n",
      "Epoch 1880/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9209 - accuracy: 0.6657 - val_loss: 1.2944 - val_accuracy: 0.4700\n",
      "Epoch 1881/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9208 - accuracy: 0.6643 - val_loss: 1.2932 - val_accuracy: 0.4767\n",
      "Epoch 1882/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9204 - accuracy: 0.6643 - val_loss: 1.2945 - val_accuracy: 0.4700\n",
      "Epoch 1883/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9207 - accuracy: 0.6671 - val_loss: 1.2937 - val_accuracy: 0.4733\n",
      "Epoch 1884/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9202 - accuracy: 0.6643 - val_loss: 1.2937 - val_accuracy: 0.4733\n",
      "Epoch 1885/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.9202 - accuracy: 0.6614 - val_loss: 1.2932 - val_accuracy: 0.4733\n",
      "Epoch 1886/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9200 - accuracy: 0.6614 - val_loss: 1.2931 - val_accuracy: 0.4767\n",
      "Epoch 1887/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.9200 - accuracy: 0.6657 - val_loss: 1.2940 - val_accuracy: 0.4700\n",
      "Epoch 1888/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.9200 - accuracy: 0.6629 - val_loss: 1.2943 - val_accuracy: 0.4733\n",
      "Epoch 1889/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9197 - accuracy: 0.6657 - val_loss: 1.2936 - val_accuracy: 0.4767\n",
      "Epoch 1890/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9196 - accuracy: 0.6643 - val_loss: 1.2934 - val_accuracy: 0.4733\n",
      "Epoch 1891/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.9195 - accuracy: 0.6557 - val_loss: 1.2946 - val_accuracy: 0.4733\n",
      "Epoch 1892/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9194 - accuracy: 0.6629 - val_loss: 1.2941 - val_accuracy: 0.4733\n",
      "Epoch 1893/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9192 - accuracy: 0.6700 - val_loss: 1.2942 - val_accuracy: 0.4733\n",
      "Epoch 1894/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9192 - accuracy: 0.6629 - val_loss: 1.2938 - val_accuracy: 0.4767\n",
      "Epoch 1895/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.9190 - accuracy: 0.6671 - val_loss: 1.2941 - val_accuracy: 0.4767\n",
      "Epoch 1896/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9188 - accuracy: 0.6686 - val_loss: 1.2939 - val_accuracy: 0.4767\n",
      "Epoch 1897/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9187 - accuracy: 0.6686 - val_loss: 1.2941 - val_accuracy: 0.4767\n",
      "Epoch 1898/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9186 - accuracy: 0.6614 - val_loss: 1.2948 - val_accuracy: 0.4700\n",
      "Epoch 1899/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.9185 - accuracy: 0.6657 - val_loss: 1.2942 - val_accuracy: 0.4767\n",
      "Epoch 1900/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9182 - accuracy: 0.6686 - val_loss: 1.2931 - val_accuracy: 0.4767\n",
      "Epoch 1901/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9181 - accuracy: 0.6657 - val_loss: 1.2941 - val_accuracy: 0.4767\n",
      "Epoch 1902/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9182 - accuracy: 0.6671 - val_loss: 1.2946 - val_accuracy: 0.4767\n",
      "Epoch 1903/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.9181 - accuracy: 0.6614 - val_loss: 1.2947 - val_accuracy: 0.4767\n",
      "Epoch 1904/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9177 - accuracy: 0.6586 - val_loss: 1.2959 - val_accuracy: 0.4700\n",
      "Epoch 1905/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9177 - accuracy: 0.6743 - val_loss: 1.2944 - val_accuracy: 0.4767\n",
      "Epoch 1906/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9177 - accuracy: 0.6643 - val_loss: 1.2952 - val_accuracy: 0.4700\n",
      "Epoch 1907/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.9174 - accuracy: 0.6671 - val_loss: 1.2939 - val_accuracy: 0.4767\n",
      "Epoch 1908/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9174 - accuracy: 0.6671 - val_loss: 1.2940 - val_accuracy: 0.4767\n",
      "Epoch 1909/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9171 - accuracy: 0.6671 - val_loss: 1.2952 - val_accuracy: 0.4700\n",
      "Epoch 1910/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 0.9170 - accuracy: 0.6686 - val_loss: 1.2945 - val_accuracy: 0.4700\n",
      "Epoch 1911/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9170 - accuracy: 0.6643 - val_loss: 1.2956 - val_accuracy: 0.4700\n",
      "Epoch 1912/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9167 - accuracy: 0.6714 - val_loss: 1.2937 - val_accuracy: 0.4767\n",
      "Epoch 1913/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9167 - accuracy: 0.6614 - val_loss: 1.2952 - val_accuracy: 0.4733\n",
      "Epoch 1914/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9166 - accuracy: 0.6671 - val_loss: 1.2964 - val_accuracy: 0.4700\n",
      "Epoch 1915/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9166 - accuracy: 0.6629 - val_loss: 1.2958 - val_accuracy: 0.4700\n",
      "Epoch 1916/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9165 - accuracy: 0.6700 - val_loss: 1.2957 - val_accuracy: 0.4733\n",
      "Epoch 1917/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9163 - accuracy: 0.6643 - val_loss: 1.2952 - val_accuracy: 0.4767\n",
      "Epoch 1918/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.9162 - accuracy: 0.6643 - val_loss: 1.2952 - val_accuracy: 0.4767\n",
      "Epoch 1919/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9159 - accuracy: 0.6700 - val_loss: 1.2949 - val_accuracy: 0.4767\n",
      "Epoch 1920/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9158 - accuracy: 0.6729 - val_loss: 1.2953 - val_accuracy: 0.4733\n",
      "Epoch 1921/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9159 - accuracy: 0.6700 - val_loss: 1.2952 - val_accuracy: 0.4733\n",
      "Epoch 1922/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9155 - accuracy: 0.6700 - val_loss: 1.2949 - val_accuracy: 0.4733\n",
      "Epoch 1923/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9156 - accuracy: 0.6714 - val_loss: 1.2948 - val_accuracy: 0.4767\n",
      "Epoch 1924/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9154 - accuracy: 0.6643 - val_loss: 1.2953 - val_accuracy: 0.4767\n",
      "Epoch 1925/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9153 - accuracy: 0.6700 - val_loss: 1.2954 - val_accuracy: 0.4767\n",
      "Epoch 1926/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9151 - accuracy: 0.6671 - val_loss: 1.2959 - val_accuracy: 0.4733\n",
      "Epoch 1927/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9149 - accuracy: 0.6657 - val_loss: 1.2965 - val_accuracy: 0.4700\n",
      "Epoch 1928/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.9148 - accuracy: 0.6714 - val_loss: 1.2953 - val_accuracy: 0.4767\n",
      "Epoch 1929/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9147 - accuracy: 0.6657 - val_loss: 1.2968 - val_accuracy: 0.4700\n",
      "Epoch 1930/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9146 - accuracy: 0.6700 - val_loss: 1.2969 - val_accuracy: 0.4700\n",
      "Epoch 1931/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.9145 - accuracy: 0.6714 - val_loss: 1.2955 - val_accuracy: 0.4733\n",
      "Epoch 1932/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9144 - accuracy: 0.6686 - val_loss: 1.2947 - val_accuracy: 0.4733\n",
      "Epoch 1933/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9143 - accuracy: 0.6643 - val_loss: 1.2964 - val_accuracy: 0.4733\n",
      "Epoch 1934/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9141 - accuracy: 0.6700 - val_loss: 1.2950 - val_accuracy: 0.4767\n",
      "Epoch 1935/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9141 - accuracy: 0.6700 - val_loss: 1.2959 - val_accuracy: 0.4733\n",
      "Epoch 1936/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.9141 - accuracy: 0.6700 - val_loss: 1.2957 - val_accuracy: 0.4767\n",
      "Epoch 1937/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9137 - accuracy: 0.6714 - val_loss: 1.2959 - val_accuracy: 0.4733\n",
      "Epoch 1938/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9136 - accuracy: 0.6686 - val_loss: 1.2964 - val_accuracy: 0.4733\n",
      "Epoch 1939/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.9136 - accuracy: 0.6729 - val_loss: 1.2959 - val_accuracy: 0.4733\n",
      "Epoch 1940/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9134 - accuracy: 0.6671 - val_loss: 1.2962 - val_accuracy: 0.4733\n",
      "Epoch 1941/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9133 - accuracy: 0.6629 - val_loss: 1.2957 - val_accuracy: 0.4733\n",
      "Epoch 1942/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9131 - accuracy: 0.6729 - val_loss: 1.2962 - val_accuracy: 0.4733\n",
      "Epoch 1943/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.9130 - accuracy: 0.6729 - val_loss: 1.2966 - val_accuracy: 0.4733\n",
      "Epoch 1944/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.9128 - accuracy: 0.6686 - val_loss: 1.2972 - val_accuracy: 0.4733\n",
      "Epoch 1945/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9127 - accuracy: 0.6686 - val_loss: 1.2978 - val_accuracy: 0.4700\n",
      "Epoch 1946/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9127 - accuracy: 0.6700 - val_loss: 1.2959 - val_accuracy: 0.4767\n",
      "Epoch 1947/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 0.9126 - accuracy: 0.6714 - val_loss: 1.2970 - val_accuracy: 0.4733\n",
      "Epoch 1948/3000\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 0.9124 - accuracy: 0.6714 - val_loss: 1.2975 - val_accuracy: 0.4733\n",
      "Epoch 1949/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.9123 - accuracy: 0.6729 - val_loss: 1.2966 - val_accuracy: 0.4733\n",
      "Epoch 1950/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9121 - accuracy: 0.6714 - val_loss: 1.2972 - val_accuracy: 0.4733\n",
      "Epoch 1951/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9123 - accuracy: 0.6700 - val_loss: 1.2966 - val_accuracy: 0.4733\n",
      "Epoch 1952/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9119 - accuracy: 0.6700 - val_loss: 1.2962 - val_accuracy: 0.4733\n",
      "Epoch 1953/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9117 - accuracy: 0.6686 - val_loss: 1.2965 - val_accuracy: 0.4733\n",
      "Epoch 1954/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9117 - accuracy: 0.6714 - val_loss: 1.2966 - val_accuracy: 0.4733\n",
      "Epoch 1955/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9114 - accuracy: 0.6700 - val_loss: 1.2967 - val_accuracy: 0.4733\n",
      "Epoch 1956/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9117 - accuracy: 0.6743 - val_loss: 1.2970 - val_accuracy: 0.4733\n",
      "Epoch 1957/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9113 - accuracy: 0.6700 - val_loss: 1.2970 - val_accuracy: 0.4733\n",
      "Epoch 1958/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9111 - accuracy: 0.6700 - val_loss: 1.2967 - val_accuracy: 0.4700\n",
      "Epoch 1959/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9111 - accuracy: 0.6714 - val_loss: 1.2969 - val_accuracy: 0.4733\n",
      "Epoch 1960/3000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 0.9109 - accuracy: 0.6700 - val_loss: 1.2981 - val_accuracy: 0.4733\n",
      "Epoch 1961/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.9109 - accuracy: 0.6686 - val_loss: 1.2971 - val_accuracy: 0.4700\n",
      "Epoch 1962/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9108 - accuracy: 0.6671 - val_loss: 1.2980 - val_accuracy: 0.4733\n",
      "Epoch 1963/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9105 - accuracy: 0.6729 - val_loss: 1.2974 - val_accuracy: 0.4733\n",
      "Epoch 1964/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9105 - accuracy: 0.6700 - val_loss: 1.2979 - val_accuracy: 0.4733\n",
      "Epoch 1965/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9103 - accuracy: 0.6729 - val_loss: 1.2964 - val_accuracy: 0.4700\n",
      "Epoch 1966/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9103 - accuracy: 0.6714 - val_loss: 1.2970 - val_accuracy: 0.4733\n",
      "Epoch 1967/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9101 - accuracy: 0.6757 - val_loss: 1.2977 - val_accuracy: 0.4733\n",
      "Epoch 1968/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9099 - accuracy: 0.6714 - val_loss: 1.2975 - val_accuracy: 0.4700\n",
      "Epoch 1969/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 0.9098 - accuracy: 0.6743 - val_loss: 1.2983 - val_accuracy: 0.4733\n",
      "Epoch 1970/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9099 - accuracy: 0.6729 - val_loss: 1.2979 - val_accuracy: 0.4700\n",
      "Epoch 1971/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9096 - accuracy: 0.6743 - val_loss: 1.2974 - val_accuracy: 0.4700\n",
      "Epoch 1972/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9096 - accuracy: 0.6714 - val_loss: 1.2982 - val_accuracy: 0.4700\n",
      "Epoch 1973/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9095 - accuracy: 0.6743 - val_loss: 1.2980 - val_accuracy: 0.4700\n",
      "Epoch 1974/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9093 - accuracy: 0.6743 - val_loss: 1.2976 - val_accuracy: 0.4700\n",
      "Epoch 1975/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 0.9092 - accuracy: 0.6729 - val_loss: 1.2984 - val_accuracy: 0.4700\n",
      "Epoch 1976/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9089 - accuracy: 0.6700 - val_loss: 1.2971 - val_accuracy: 0.4700\n",
      "Epoch 1977/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9091 - accuracy: 0.6729 - val_loss: 1.2973 - val_accuracy: 0.4700\n",
      "Epoch 1978/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9087 - accuracy: 0.6743 - val_loss: 1.2982 - val_accuracy: 0.4700\n",
      "Epoch 1979/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9087 - accuracy: 0.6743 - val_loss: 1.2983 - val_accuracy: 0.4700\n",
      "Epoch 1980/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9085 - accuracy: 0.6757 - val_loss: 1.2991 - val_accuracy: 0.4700\n",
      "Epoch 1981/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9085 - accuracy: 0.6729 - val_loss: 1.2987 - val_accuracy: 0.4700\n",
      "Epoch 1982/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9083 - accuracy: 0.6700 - val_loss: 1.2978 - val_accuracy: 0.4700\n",
      "Epoch 1983/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9083 - accuracy: 0.6743 - val_loss: 1.2986 - val_accuracy: 0.4700\n",
      "Epoch 1984/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9081 - accuracy: 0.6700 - val_loss: 1.2983 - val_accuracy: 0.4700\n",
      "Epoch 1985/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9079 - accuracy: 0.6757 - val_loss: 1.2987 - val_accuracy: 0.4700\n",
      "Epoch 1986/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9080 - accuracy: 0.6743 - val_loss: 1.2985 - val_accuracy: 0.4700\n",
      "Epoch 1987/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.9076 - accuracy: 0.6786 - val_loss: 1.2977 - val_accuracy: 0.4700\n",
      "Epoch 1988/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9076 - accuracy: 0.6743 - val_loss: 1.2996 - val_accuracy: 0.4700\n",
      "Epoch 1989/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9073 - accuracy: 0.6714 - val_loss: 1.2990 - val_accuracy: 0.4700\n",
      "Epoch 1990/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9071 - accuracy: 0.6700 - val_loss: 1.3006 - val_accuracy: 0.4700\n",
      "Epoch 1991/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9073 - accuracy: 0.6743 - val_loss: 1.2994 - val_accuracy: 0.4700\n",
      "Epoch 1992/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9072 - accuracy: 0.6757 - val_loss: 1.2992 - val_accuracy: 0.4700\n",
      "Epoch 1993/3000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 0.9071 - accuracy: 0.6743 - val_loss: 1.2990 - val_accuracy: 0.4700\n",
      "Epoch 1994/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.9068 - accuracy: 0.6757 - val_loss: 1.2989 - val_accuracy: 0.4700\n",
      "Epoch 1995/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.9067 - accuracy: 0.6700 - val_loss: 1.3000 - val_accuracy: 0.4700\n",
      "Epoch 1996/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9067 - accuracy: 0.6743 - val_loss: 1.2990 - val_accuracy: 0.4700\n",
      "Epoch 1997/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9065 - accuracy: 0.6729 - val_loss: 1.2997 - val_accuracy: 0.4700\n",
      "Epoch 1998/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9065 - accuracy: 0.6729 - val_loss: 1.2993 - val_accuracy: 0.4700\n",
      "Epoch 1999/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9062 - accuracy: 0.6757 - val_loss: 1.3005 - val_accuracy: 0.4700\n",
      "Epoch 2000/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9063 - accuracy: 0.6743 - val_loss: 1.3007 - val_accuracy: 0.4700\n",
      "Epoch 2001/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9061 - accuracy: 0.6729 - val_loss: 1.3000 - val_accuracy: 0.4700\n",
      "Epoch 2002/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9061 - accuracy: 0.6729 - val_loss: 1.2993 - val_accuracy: 0.4700\n",
      "Epoch 2003/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9059 - accuracy: 0.6771 - val_loss: 1.2990 - val_accuracy: 0.4667\n",
      "Epoch 2004/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9058 - accuracy: 0.6743 - val_loss: 1.3007 - val_accuracy: 0.4667\n",
      "Epoch 2005/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9055 - accuracy: 0.6757 - val_loss: 1.2991 - val_accuracy: 0.4667\n",
      "Epoch 2006/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 0.9054 - accuracy: 0.6757 - val_loss: 1.2994 - val_accuracy: 0.4700\n",
      "Epoch 2007/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.9054 - accuracy: 0.6757 - val_loss: 1.3002 - val_accuracy: 0.4700\n",
      "Epoch 2008/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.9053 - accuracy: 0.6743 - val_loss: 1.3000 - val_accuracy: 0.4700\n",
      "Epoch 2009/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9049 - accuracy: 0.6800 - val_loss: 1.3005 - val_accuracy: 0.4700\n",
      "Epoch 2010/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9052 - accuracy: 0.6729 - val_loss: 1.3006 - val_accuracy: 0.4700\n",
      "Epoch 2011/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9046 - accuracy: 0.6714 - val_loss: 1.2989 - val_accuracy: 0.4700\n",
      "Epoch 2012/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9049 - accuracy: 0.6743 - val_loss: 1.2993 - val_accuracy: 0.4700\n",
      "Epoch 2013/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9048 - accuracy: 0.6757 - val_loss: 1.2994 - val_accuracy: 0.4700\n",
      "Epoch 2014/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9045 - accuracy: 0.6771 - val_loss: 1.2999 - val_accuracy: 0.4700\n",
      "Epoch 2015/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9046 - accuracy: 0.6771 - val_loss: 1.3006 - val_accuracy: 0.4700\n",
      "Epoch 2016/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9043 - accuracy: 0.6743 - val_loss: 1.3003 - val_accuracy: 0.4700\n",
      "Epoch 2017/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9042 - accuracy: 0.6757 - val_loss: 1.3001 - val_accuracy: 0.4700\n",
      "Epoch 2018/3000\n",
      "700/700 [==============================] - 0s 90us/sample - loss: 0.9041 - accuracy: 0.6757 - val_loss: 1.3001 - val_accuracy: 0.4700\n",
      "Epoch 2019/3000\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 0.9042 - accuracy: 0.6757 - val_loss: 1.3002 - val_accuracy: 0.4700\n",
      "Epoch 2020/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 0.9040 - accuracy: 0.6757 - val_loss: 1.3005 - val_accuracy: 0.4700\n",
      "Epoch 2021/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.9036 - accuracy: 0.6743 - val_loss: 1.2994 - val_accuracy: 0.4700\n",
      "Epoch 2022/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9037 - accuracy: 0.6700 - val_loss: 1.2996 - val_accuracy: 0.4700\n",
      "Epoch 2023/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9037 - accuracy: 0.6743 - val_loss: 1.3007 - val_accuracy: 0.4700\n",
      "Epoch 2024/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.9034 - accuracy: 0.6743 - val_loss: 1.3013 - val_accuracy: 0.4700\n",
      "Epoch 2025/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9033 - accuracy: 0.6743 - val_loss: 1.3015 - val_accuracy: 0.4700\n",
      "Epoch 2026/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9033 - accuracy: 0.6800 - val_loss: 1.3010 - val_accuracy: 0.4700\n",
      "Epoch 2027/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9030 - accuracy: 0.6686 - val_loss: 1.3006 - val_accuracy: 0.4667\n",
      "Epoch 2028/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.9030 - accuracy: 0.6786 - val_loss: 1.3010 - val_accuracy: 0.4667\n",
      "Epoch 2029/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9028 - accuracy: 0.6771 - val_loss: 1.3014 - val_accuracy: 0.4667\n",
      "Epoch 2030/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9026 - accuracy: 0.6771 - val_loss: 1.3007 - val_accuracy: 0.4700\n",
      "Epoch 2031/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9028 - accuracy: 0.6771 - val_loss: 1.3011 - val_accuracy: 0.4700\n",
      "Epoch 2032/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9026 - accuracy: 0.6800 - val_loss: 1.3018 - val_accuracy: 0.4700\n",
      "Epoch 2033/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9023 - accuracy: 0.6786 - val_loss: 1.3025 - val_accuracy: 0.4700\n",
      "Epoch 2034/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9023 - accuracy: 0.6800 - val_loss: 1.3018 - val_accuracy: 0.4700\n",
      "Epoch 2035/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9021 - accuracy: 0.6757 - val_loss: 1.3025 - val_accuracy: 0.4667\n",
      "Epoch 2036/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9021 - accuracy: 0.6757 - val_loss: 1.3013 - val_accuracy: 0.4667\n",
      "Epoch 2037/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9021 - accuracy: 0.6800 - val_loss: 1.3011 - val_accuracy: 0.4667\n",
      "Epoch 2038/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9018 - accuracy: 0.6786 - val_loss: 1.3017 - val_accuracy: 0.4667\n",
      "Epoch 2039/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9017 - accuracy: 0.6771 - val_loss: 1.3025 - val_accuracy: 0.4667\n",
      "Epoch 2040/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9016 - accuracy: 0.6786 - val_loss: 1.3019 - val_accuracy: 0.4667\n",
      "Epoch 2041/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.9015 - accuracy: 0.6771 - val_loss: 1.3023 - val_accuracy: 0.4700\n",
      "Epoch 2042/3000\n",
      "700/700 [==============================] - 0s 104us/sample - loss: 0.9016 - accuracy: 0.6800 - val_loss: 1.3017 - val_accuracy: 0.4667\n",
      "Epoch 2043/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 0.9011 - accuracy: 0.6714 - val_loss: 1.3004 - val_accuracy: 0.4667\n",
      "Epoch 2044/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.9011 - accuracy: 0.6814 - val_loss: 1.3015 - val_accuracy: 0.4667\n",
      "Epoch 2045/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.9009 - accuracy: 0.6786 - val_loss: 1.3027 - val_accuracy: 0.4667\n",
      "Epoch 2046/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9009 - accuracy: 0.6786 - val_loss: 1.3018 - val_accuracy: 0.4667\n",
      "Epoch 2047/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9006 - accuracy: 0.6757 - val_loss: 1.3023 - val_accuracy: 0.4700\n",
      "Epoch 2048/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9006 - accuracy: 0.6786 - val_loss: 1.3009 - val_accuracy: 0.4667\n",
      "Epoch 2049/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9007 - accuracy: 0.6786 - val_loss: 1.3020 - val_accuracy: 0.4700\n",
      "Epoch 2050/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9004 - accuracy: 0.6771 - val_loss: 1.3022 - val_accuracy: 0.4700\n",
      "Epoch 2051/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.9002 - accuracy: 0.6829 - val_loss: 1.3020 - val_accuracy: 0.4700\n",
      "Epoch 2052/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.9002 - accuracy: 0.6814 - val_loss: 1.3022 - val_accuracy: 0.4667\n",
      "Epoch 2053/3000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 0.9002 - accuracy: 0.6771 - val_loss: 1.3018 - val_accuracy: 0.4667\n",
      "Epoch 2054/3000\n",
      "700/700 [==============================] - 0s 86us/sample - loss: 0.8999 - accuracy: 0.6757 - val_loss: 1.3020 - val_accuracy: 0.4700\n",
      "Epoch 2055/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8999 - accuracy: 0.6771 - val_loss: 1.3021 - val_accuracy: 0.4700\n",
      "Epoch 2056/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8998 - accuracy: 0.6829 - val_loss: 1.3029 - val_accuracy: 0.4667\n",
      "Epoch 2057/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8995 - accuracy: 0.6814 - val_loss: 1.3021 - val_accuracy: 0.4667\n",
      "Epoch 2058/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8996 - accuracy: 0.6757 - val_loss: 1.3029 - val_accuracy: 0.4667\n",
      "Epoch 2059/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8995 - accuracy: 0.6771 - val_loss: 1.3037 - val_accuracy: 0.4667\n",
      "Epoch 2060/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8995 - accuracy: 0.6757 - val_loss: 1.3032 - val_accuracy: 0.4667\n",
      "Epoch 2061/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8989 - accuracy: 0.6786 - val_loss: 1.3048 - val_accuracy: 0.4633\n",
      "Epoch 2062/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8991 - accuracy: 0.6786 - val_loss: 1.3036 - val_accuracy: 0.4667\n",
      "Epoch 2063/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8989 - accuracy: 0.6786 - val_loss: 1.3037 - val_accuracy: 0.4700\n",
      "Epoch 2064/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8987 - accuracy: 0.6786 - val_loss: 1.3047 - val_accuracy: 0.4667\n",
      "Epoch 2065/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8988 - accuracy: 0.6829 - val_loss: 1.3028 - val_accuracy: 0.4700\n",
      "Epoch 2066/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8985 - accuracy: 0.6843 - val_loss: 1.3031 - val_accuracy: 0.4700\n",
      "Epoch 2067/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8985 - accuracy: 0.6800 - val_loss: 1.3045 - val_accuracy: 0.4667\n",
      "Epoch 2068/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8986 - accuracy: 0.6786 - val_loss: 1.3039 - val_accuracy: 0.4667\n",
      "Epoch 2069/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8983 - accuracy: 0.6771 - val_loss: 1.3035 - val_accuracy: 0.4667\n",
      "Epoch 2070/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8982 - accuracy: 0.6786 - val_loss: 1.3047 - val_accuracy: 0.4633\n",
      "Epoch 2071/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8982 - accuracy: 0.6843 - val_loss: 1.3029 - val_accuracy: 0.4667\n",
      "Epoch 2072/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8980 - accuracy: 0.6771 - val_loss: 1.3036 - val_accuracy: 0.4667\n",
      "Epoch 2073/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8977 - accuracy: 0.6786 - val_loss: 1.3030 - val_accuracy: 0.4667\n",
      "Epoch 2074/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8977 - accuracy: 0.6786 - val_loss: 1.3032 - val_accuracy: 0.4700\n",
      "Epoch 2075/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 0.8976 - accuracy: 0.6814 - val_loss: 1.3043 - val_accuracy: 0.4667\n",
      "Epoch 2076/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8975 - accuracy: 0.6800 - val_loss: 1.3046 - val_accuracy: 0.4667\n",
      "Epoch 2077/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8975 - accuracy: 0.6771 - val_loss: 1.3046 - val_accuracy: 0.4667\n",
      "Epoch 2078/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8972 - accuracy: 0.6771 - val_loss: 1.3048 - val_accuracy: 0.4667\n",
      "Epoch 2079/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8972 - accuracy: 0.6800 - val_loss: 1.3045 - val_accuracy: 0.4667\n",
      "Epoch 2080/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8973 - accuracy: 0.6814 - val_loss: 1.3044 - val_accuracy: 0.4667\n",
      "Epoch 2081/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8969 - accuracy: 0.6786 - val_loss: 1.3050 - val_accuracy: 0.4667\n",
      "Epoch 2082/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 0.8968 - accuracy: 0.6786 - val_loss: 1.3035 - val_accuracy: 0.4700\n",
      "Epoch 2083/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8968 - accuracy: 0.6757 - val_loss: 1.3049 - val_accuracy: 0.4700\n",
      "Epoch 2084/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8966 - accuracy: 0.6829 - val_loss: 1.3048 - val_accuracy: 0.4667\n",
      "Epoch 2085/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8965 - accuracy: 0.6829 - val_loss: 1.3048 - val_accuracy: 0.4700\n",
      "Epoch 2086/3000\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 0.8964 - accuracy: 0.6800 - val_loss: 1.3059 - val_accuracy: 0.4633\n",
      "Epoch 2087/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8964 - accuracy: 0.6800 - val_loss: 1.3050 - val_accuracy: 0.4700\n",
      "Epoch 2088/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8959 - accuracy: 0.6800 - val_loss: 1.3051 - val_accuracy: 0.4700\n",
      "Epoch 2089/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8961 - accuracy: 0.6786 - val_loss: 1.3053 - val_accuracy: 0.4667\n",
      "Epoch 2090/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8960 - accuracy: 0.6800 - val_loss: 1.3046 - val_accuracy: 0.4667\n",
      "Epoch 2091/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8959 - accuracy: 0.6786 - val_loss: 1.3057 - val_accuracy: 0.4667\n",
      "Epoch 2092/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8958 - accuracy: 0.6843 - val_loss: 1.3054 - val_accuracy: 0.4700\n",
      "Epoch 2093/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8955 - accuracy: 0.6800 - val_loss: 1.3042 - val_accuracy: 0.4700\n",
      "Epoch 2094/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8955 - accuracy: 0.6800 - val_loss: 1.3053 - val_accuracy: 0.4700\n",
      "Epoch 2095/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8954 - accuracy: 0.6800 - val_loss: 1.3051 - val_accuracy: 0.4667\n",
      "Epoch 2096/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8952 - accuracy: 0.6786 - val_loss: 1.3053 - val_accuracy: 0.4667\n",
      "Epoch 2097/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8953 - accuracy: 0.6829 - val_loss: 1.3057 - val_accuracy: 0.4700\n",
      "Epoch 2098/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8950 - accuracy: 0.6800 - val_loss: 1.3051 - val_accuracy: 0.4700\n",
      "Epoch 2099/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8949 - accuracy: 0.6829 - val_loss: 1.3046 - val_accuracy: 0.4700\n",
      "Epoch 2100/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8949 - accuracy: 0.6800 - val_loss: 1.3055 - val_accuracy: 0.4667\n",
      "Epoch 2101/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8946 - accuracy: 0.6814 - val_loss: 1.3044 - val_accuracy: 0.4700\n",
      "Epoch 2102/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8946 - accuracy: 0.6814 - val_loss: 1.3059 - val_accuracy: 0.4700\n",
      "Epoch 2103/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8946 - accuracy: 0.6814 - val_loss: 1.3061 - val_accuracy: 0.4667\n",
      "Epoch 2104/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8944 - accuracy: 0.6814 - val_loss: 1.3056 - val_accuracy: 0.4667\n",
      "Epoch 2105/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8943 - accuracy: 0.6829 - val_loss: 1.3051 - val_accuracy: 0.4700\n",
      "Epoch 2106/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8942 - accuracy: 0.6814 - val_loss: 1.3061 - val_accuracy: 0.4667\n",
      "Epoch 2107/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8942 - accuracy: 0.6800 - val_loss: 1.3067 - val_accuracy: 0.4667\n",
      "Epoch 2108/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8941 - accuracy: 0.6786 - val_loss: 1.3070 - val_accuracy: 0.4667\n",
      "Epoch 2109/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8938 - accuracy: 0.6800 - val_loss: 1.3061 - val_accuracy: 0.4667\n",
      "Epoch 2110/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8938 - accuracy: 0.6857 - val_loss: 1.3061 - val_accuracy: 0.4700\n",
      "Epoch 2111/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8938 - accuracy: 0.6786 - val_loss: 1.3064 - val_accuracy: 0.4667\n",
      "Epoch 2112/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8935 - accuracy: 0.6814 - val_loss: 1.3064 - val_accuracy: 0.4667\n",
      "Epoch 2113/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8932 - accuracy: 0.6814 - val_loss: 1.3078 - val_accuracy: 0.4667\n",
      "Epoch 2114/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8934 - accuracy: 0.6814 - val_loss: 1.3071 - val_accuracy: 0.4667\n",
      "Epoch 2115/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8933 - accuracy: 0.6814 - val_loss: 1.3063 - val_accuracy: 0.4667\n",
      "Epoch 2116/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8931 - accuracy: 0.6800 - val_loss: 1.3068 - val_accuracy: 0.4667\n",
      "Epoch 2117/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8928 - accuracy: 0.6786 - val_loss: 1.3065 - val_accuracy: 0.4667\n",
      "Epoch 2118/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8930 - accuracy: 0.6814 - val_loss: 1.3066 - val_accuracy: 0.4667\n",
      "Epoch 2119/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8927 - accuracy: 0.6857 - val_loss: 1.3076 - val_accuracy: 0.4667\n",
      "Epoch 2120/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8927 - accuracy: 0.6814 - val_loss: 1.3074 - val_accuracy: 0.4667\n",
      "Epoch 2121/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8927 - accuracy: 0.6843 - val_loss: 1.3072 - val_accuracy: 0.4700\n",
      "Epoch 2122/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8925 - accuracy: 0.6843 - val_loss: 1.3071 - val_accuracy: 0.4667\n",
      "Epoch 2123/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8924 - accuracy: 0.6829 - val_loss: 1.3076 - val_accuracy: 0.4667\n",
      "Epoch 2124/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8921 - accuracy: 0.6829 - val_loss: 1.3075 - val_accuracy: 0.4667\n",
      "Epoch 2125/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8920 - accuracy: 0.6829 - val_loss: 1.3071 - val_accuracy: 0.4667\n",
      "Epoch 2126/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8919 - accuracy: 0.6843 - val_loss: 1.3076 - val_accuracy: 0.4700\n",
      "Epoch 2127/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8918 - accuracy: 0.6843 - val_loss: 1.3074 - val_accuracy: 0.4700\n",
      "Epoch 2128/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8917 - accuracy: 0.6800 - val_loss: 1.3089 - val_accuracy: 0.4667\n",
      "Epoch 2129/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8918 - accuracy: 0.6814 - val_loss: 1.3082 - val_accuracy: 0.4667\n",
      "Epoch 2130/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8916 - accuracy: 0.6829 - val_loss: 1.3094 - val_accuracy: 0.4667\n",
      "Epoch 2131/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8915 - accuracy: 0.6857 - val_loss: 1.3090 - val_accuracy: 0.4667\n",
      "Epoch 2132/3000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 0.8913 - accuracy: 0.6843 - val_loss: 1.3087 - val_accuracy: 0.4667\n",
      "Epoch 2133/3000\n",
      "700/700 [==============================] - 0s 91us/sample - loss: 0.8913 - accuracy: 0.6814 - val_loss: 1.3084 - val_accuracy: 0.4667\n",
      "Epoch 2134/3000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 0.8910 - accuracy: 0.6829 - val_loss: 1.3076 - val_accuracy: 0.4667\n",
      "Epoch 2135/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8910 - accuracy: 0.6814 - val_loss: 1.3073 - val_accuracy: 0.4700\n",
      "Epoch 2136/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8909 - accuracy: 0.6800 - val_loss: 1.3092 - val_accuracy: 0.4667\n",
      "Epoch 2137/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8906 - accuracy: 0.6829 - val_loss: 1.3076 - val_accuracy: 0.4667\n",
      "Epoch 2138/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8908 - accuracy: 0.6814 - val_loss: 1.3081 - val_accuracy: 0.4667\n",
      "Epoch 2139/3000\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 0.8908 - accuracy: 0.6829 - val_loss: 1.3093 - val_accuracy: 0.4667\n",
      "Epoch 2140/3000\n",
      "700/700 [==============================] - 0s 86us/sample - loss: 0.8904 - accuracy: 0.6814 - val_loss: 1.3078 - val_accuracy: 0.4700\n",
      "Epoch 2141/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8904 - accuracy: 0.6829 - val_loss: 1.3083 - val_accuracy: 0.4667\n",
      "Epoch 2142/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8903 - accuracy: 0.6843 - val_loss: 1.3087 - val_accuracy: 0.4667\n",
      "Epoch 2143/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8900 - accuracy: 0.6843 - val_loss: 1.3088 - val_accuracy: 0.4700\n",
      "Epoch 2144/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8900 - accuracy: 0.6829 - val_loss: 1.3092 - val_accuracy: 0.4667\n",
      "Epoch 2145/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8899 - accuracy: 0.6829 - val_loss: 1.3091 - val_accuracy: 0.4667\n",
      "Epoch 2146/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8899 - accuracy: 0.6829 - val_loss: 1.3097 - val_accuracy: 0.4667\n",
      "Epoch 2147/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8898 - accuracy: 0.6871 - val_loss: 1.3089 - val_accuracy: 0.4700\n",
      "Epoch 2148/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8896 - accuracy: 0.6843 - val_loss: 1.3090 - val_accuracy: 0.4700\n",
      "Epoch 2149/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8896 - accuracy: 0.6800 - val_loss: 1.3093 - val_accuracy: 0.4667\n",
      "Epoch 2150/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8894 - accuracy: 0.6843 - val_loss: 1.3089 - val_accuracy: 0.4733\n",
      "Epoch 2151/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8894 - accuracy: 0.6843 - val_loss: 1.3091 - val_accuracy: 0.4733\n",
      "Epoch 2152/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8893 - accuracy: 0.6857 - val_loss: 1.3102 - val_accuracy: 0.4667\n",
      "Epoch 2153/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8892 - accuracy: 0.6829 - val_loss: 1.3100 - val_accuracy: 0.4700\n",
      "Epoch 2154/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8889 - accuracy: 0.6814 - val_loss: 1.3101 - val_accuracy: 0.4700\n",
      "Epoch 2155/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8890 - accuracy: 0.6843 - val_loss: 1.3094 - val_accuracy: 0.4733\n",
      "Epoch 2156/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8888 - accuracy: 0.6814 - val_loss: 1.3095 - val_accuracy: 0.4733\n",
      "Epoch 2157/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8886 - accuracy: 0.6857 - val_loss: 1.3093 - val_accuracy: 0.4733\n",
      "Epoch 2158/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8885 - accuracy: 0.6829 - val_loss: 1.3095 - val_accuracy: 0.4700\n",
      "Epoch 2159/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 0.8884 - accuracy: 0.6829 - val_loss: 1.3107 - val_accuracy: 0.4700\n",
      "Epoch 2160/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 0.8883 - accuracy: 0.6857 - val_loss: 1.3107 - val_accuracy: 0.4700\n",
      "Epoch 2161/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8883 - accuracy: 0.6843 - val_loss: 1.3111 - val_accuracy: 0.4667\n",
      "Epoch 2162/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8884 - accuracy: 0.6857 - val_loss: 1.3109 - val_accuracy: 0.4667\n",
      "Epoch 2163/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8879 - accuracy: 0.6843 - val_loss: 1.3112 - val_accuracy: 0.4667\n",
      "Epoch 2164/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8879 - accuracy: 0.6871 - val_loss: 1.3108 - val_accuracy: 0.4700\n",
      "Epoch 2165/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8879 - accuracy: 0.6843 - val_loss: 1.3105 - val_accuracy: 0.4667\n",
      "Epoch 2166/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8878 - accuracy: 0.6829 - val_loss: 1.3113 - val_accuracy: 0.4700\n",
      "Epoch 2167/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8876 - accuracy: 0.6871 - val_loss: 1.3111 - val_accuracy: 0.4700\n",
      "Epoch 2168/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8874 - accuracy: 0.6829 - val_loss: 1.3115 - val_accuracy: 0.4700\n",
      "Epoch 2169/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8874 - accuracy: 0.6843 - val_loss: 1.3104 - val_accuracy: 0.4733\n",
      "Epoch 2170/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8873 - accuracy: 0.6857 - val_loss: 1.3110 - val_accuracy: 0.4733\n",
      "Epoch 2171/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8872 - accuracy: 0.6843 - val_loss: 1.3108 - val_accuracy: 0.4733\n",
      "Epoch 2172/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8871 - accuracy: 0.6857 - val_loss: 1.3103 - val_accuracy: 0.4733\n",
      "Epoch 2173/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8871 - accuracy: 0.6843 - val_loss: 1.3110 - val_accuracy: 0.4733\n",
      "Epoch 2174/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8868 - accuracy: 0.6829 - val_loss: 1.3118 - val_accuracy: 0.4700\n",
      "Epoch 2175/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8868 - accuracy: 0.6871 - val_loss: 1.3113 - val_accuracy: 0.4700\n",
      "Epoch 2176/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8865 - accuracy: 0.6871 - val_loss: 1.3119 - val_accuracy: 0.4700\n",
      "Epoch 2177/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8864 - accuracy: 0.6843 - val_loss: 1.3120 - val_accuracy: 0.4700\n",
      "Epoch 2178/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8864 - accuracy: 0.6829 - val_loss: 1.3118 - val_accuracy: 0.4667\n",
      "Epoch 2179/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8863 - accuracy: 0.6857 - val_loss: 1.3112 - val_accuracy: 0.4700\n",
      "Epoch 2180/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8860 - accuracy: 0.6829 - val_loss: 1.3110 - val_accuracy: 0.4733\n",
      "Epoch 2181/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8861 - accuracy: 0.6829 - val_loss: 1.3119 - val_accuracy: 0.4733\n",
      "Epoch 2182/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8859 - accuracy: 0.6843 - val_loss: 1.3131 - val_accuracy: 0.4700\n",
      "Epoch 2183/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8858 - accuracy: 0.6857 - val_loss: 1.3115 - val_accuracy: 0.4733\n",
      "Epoch 2184/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8857 - accuracy: 0.6829 - val_loss: 1.3123 - val_accuracy: 0.4700\n",
      "Epoch 2185/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8857 - accuracy: 0.6843 - val_loss: 1.3123 - val_accuracy: 0.4733\n",
      "Epoch 2186/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8856 - accuracy: 0.6843 - val_loss: 1.3124 - val_accuracy: 0.4700\n",
      "Epoch 2187/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8854 - accuracy: 0.6857 - val_loss: 1.3128 - val_accuracy: 0.4700\n",
      "Epoch 2188/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8855 - accuracy: 0.6814 - val_loss: 1.3120 - val_accuracy: 0.4733\n",
      "Epoch 2189/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8850 - accuracy: 0.6829 - val_loss: 1.3125 - val_accuracy: 0.4700\n",
      "Epoch 2190/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8852 - accuracy: 0.6814 - val_loss: 1.3132 - val_accuracy: 0.4700\n",
      "Epoch 2191/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8850 - accuracy: 0.6843 - val_loss: 1.3127 - val_accuracy: 0.4700\n",
      "Epoch 2192/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8848 - accuracy: 0.6886 - val_loss: 1.3130 - val_accuracy: 0.4700\n",
      "Epoch 2193/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8848 - accuracy: 0.6843 - val_loss: 1.3132 - val_accuracy: 0.4733\n",
      "Epoch 2194/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8845 - accuracy: 0.6857 - val_loss: 1.3128 - val_accuracy: 0.4733\n",
      "Epoch 2195/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8845 - accuracy: 0.6857 - val_loss: 1.3118 - val_accuracy: 0.4700\n",
      "Epoch 2196/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8844 - accuracy: 0.6871 - val_loss: 1.3125 - val_accuracy: 0.4733\n",
      "Epoch 2197/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8844 - accuracy: 0.6871 - val_loss: 1.3126 - val_accuracy: 0.4733\n",
      "Epoch 2198/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8843 - accuracy: 0.6829 - val_loss: 1.3139 - val_accuracy: 0.4733\n",
      "Epoch 2199/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8841 - accuracy: 0.6871 - val_loss: 1.3148 - val_accuracy: 0.4700\n",
      "Epoch 2200/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8840 - accuracy: 0.6857 - val_loss: 1.3124 - val_accuracy: 0.4700\n",
      "Epoch 2201/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8839 - accuracy: 0.6886 - val_loss: 1.3134 - val_accuracy: 0.4733\n",
      "Epoch 2202/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8839 - accuracy: 0.6843 - val_loss: 1.3137 - val_accuracy: 0.4667\n",
      "Epoch 2203/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8835 - accuracy: 0.6829 - val_loss: 1.3130 - val_accuracy: 0.4700\n",
      "Epoch 2204/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8836 - accuracy: 0.6857 - val_loss: 1.3135 - val_accuracy: 0.4733\n",
      "Epoch 2205/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8835 - accuracy: 0.6857 - val_loss: 1.3131 - val_accuracy: 0.4733\n",
      "Epoch 2206/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.8834 - accuracy: 0.6871 - val_loss: 1.3127 - val_accuracy: 0.4700\n",
      "Epoch 2207/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8832 - accuracy: 0.6857 - val_loss: 1.3143 - val_accuracy: 0.4733\n",
      "Epoch 2208/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8832 - accuracy: 0.6886 - val_loss: 1.3145 - val_accuracy: 0.4733\n",
      "Epoch 2209/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8830 - accuracy: 0.6843 - val_loss: 1.3150 - val_accuracy: 0.4700\n",
      "Epoch 2210/3000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 0.8832 - accuracy: 0.6871 - val_loss: 1.3145 - val_accuracy: 0.4700\n",
      "Epoch 2211/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8828 - accuracy: 0.6857 - val_loss: 1.3148 - val_accuracy: 0.4733\n",
      "Epoch 2212/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8828 - accuracy: 0.6857 - val_loss: 1.3141 - val_accuracy: 0.4733\n",
      "Epoch 2213/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8827 - accuracy: 0.6871 - val_loss: 1.3134 - val_accuracy: 0.4700\n",
      "Epoch 2214/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8825 - accuracy: 0.6843 - val_loss: 1.3148 - val_accuracy: 0.4700\n",
      "Epoch 2215/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8823 - accuracy: 0.6871 - val_loss: 1.3129 - val_accuracy: 0.4633\n",
      "Epoch 2216/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8823 - accuracy: 0.6857 - val_loss: 1.3141 - val_accuracy: 0.4700\n",
      "Epoch 2217/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8821 - accuracy: 0.6843 - val_loss: 1.3150 - val_accuracy: 0.4733\n",
      "Epoch 2218/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8821 - accuracy: 0.6900 - val_loss: 1.3149 - val_accuracy: 0.4667\n",
      "Epoch 2219/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8819 - accuracy: 0.6886 - val_loss: 1.3144 - val_accuracy: 0.4667\n",
      "Epoch 2220/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8818 - accuracy: 0.6857 - val_loss: 1.3146 - val_accuracy: 0.4667\n",
      "Epoch 2221/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.8819 - accuracy: 0.6800 - val_loss: 1.3152 - val_accuracy: 0.4667\n",
      "Epoch 2222/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.8817 - accuracy: 0.6886 - val_loss: 1.3152 - val_accuracy: 0.4700\n",
      "Epoch 2223/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8817 - accuracy: 0.6871 - val_loss: 1.3148 - val_accuracy: 0.4700\n",
      "Epoch 2224/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.8815 - accuracy: 0.6871 - val_loss: 1.3139 - val_accuracy: 0.4700\n",
      "Epoch 2225/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8813 - accuracy: 0.6857 - val_loss: 1.3162 - val_accuracy: 0.4733\n",
      "Epoch 2226/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8814 - accuracy: 0.6886 - val_loss: 1.3160 - val_accuracy: 0.4700\n",
      "Epoch 2227/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8811 - accuracy: 0.6857 - val_loss: 1.3151 - val_accuracy: 0.4667\n",
      "Epoch 2228/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8808 - accuracy: 0.6871 - val_loss: 1.3163 - val_accuracy: 0.4667\n",
      "Epoch 2229/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8809 - accuracy: 0.6857 - val_loss: 1.3146 - val_accuracy: 0.4700\n",
      "Epoch 2230/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8808 - accuracy: 0.6871 - val_loss: 1.3159 - val_accuracy: 0.4700\n",
      "Epoch 2231/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8807 - accuracy: 0.6843 - val_loss: 1.3153 - val_accuracy: 0.4667\n",
      "Epoch 2232/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8808 - accuracy: 0.6886 - val_loss: 1.3163 - val_accuracy: 0.4733\n",
      "Epoch 2233/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8803 - accuracy: 0.6857 - val_loss: 1.3151 - val_accuracy: 0.4700\n",
      "Epoch 2234/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8803 - accuracy: 0.6871 - val_loss: 1.3158 - val_accuracy: 0.4667\n",
      "Epoch 2235/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8803 - accuracy: 0.6871 - val_loss: 1.3165 - val_accuracy: 0.4667\n",
      "Epoch 2236/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8802 - accuracy: 0.6871 - val_loss: 1.3165 - val_accuracy: 0.4700\n",
      "Epoch 2237/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8801 - accuracy: 0.6900 - val_loss: 1.3164 - val_accuracy: 0.4700\n",
      "Epoch 2238/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8800 - accuracy: 0.6900 - val_loss: 1.3154 - val_accuracy: 0.4700\n",
      "Epoch 2239/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8800 - accuracy: 0.6900 - val_loss: 1.3160 - val_accuracy: 0.4700\n",
      "Epoch 2240/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8797 - accuracy: 0.6857 - val_loss: 1.3158 - val_accuracy: 0.4700\n",
      "Epoch 2241/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8798 - accuracy: 0.6886 - val_loss: 1.3165 - val_accuracy: 0.4667\n",
      "Epoch 2242/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8796 - accuracy: 0.6900 - val_loss: 1.3159 - val_accuracy: 0.4700\n",
      "Epoch 2243/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8794 - accuracy: 0.6857 - val_loss: 1.3155 - val_accuracy: 0.4700\n",
      "Epoch 2244/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8796 - accuracy: 0.6857 - val_loss: 1.3167 - val_accuracy: 0.4700\n",
      "Epoch 2245/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8794 - accuracy: 0.6857 - val_loss: 1.3166 - val_accuracy: 0.4700\n",
      "Epoch 2246/3000\n",
      "700/700 [==============================] - 0s 91us/sample - loss: 0.8791 - accuracy: 0.6900 - val_loss: 1.3166 - val_accuracy: 0.4667\n",
      "Epoch 2247/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8790 - accuracy: 0.6871 - val_loss: 1.3162 - val_accuracy: 0.4667\n",
      "Epoch 2248/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8790 - accuracy: 0.6886 - val_loss: 1.3178 - val_accuracy: 0.4733\n",
      "Epoch 2249/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8790 - accuracy: 0.6871 - val_loss: 1.3168 - val_accuracy: 0.4700\n",
      "Epoch 2250/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8786 - accuracy: 0.6857 - val_loss: 1.3173 - val_accuracy: 0.4700\n",
      "Epoch 2251/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8787 - accuracy: 0.6871 - val_loss: 1.3173 - val_accuracy: 0.4667\n",
      "Epoch 2252/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8786 - accuracy: 0.6900 - val_loss: 1.3171 - val_accuracy: 0.4700\n",
      "Epoch 2253/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8785 - accuracy: 0.6900 - val_loss: 1.3170 - val_accuracy: 0.4700\n",
      "Epoch 2254/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8783 - accuracy: 0.6886 - val_loss: 1.3167 - val_accuracy: 0.4700\n",
      "Epoch 2255/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8783 - accuracy: 0.6871 - val_loss: 1.3177 - val_accuracy: 0.4700\n",
      "Epoch 2256/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8779 - accuracy: 0.6871 - val_loss: 1.3164 - val_accuracy: 0.4633\n",
      "Epoch 2257/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8780 - accuracy: 0.6857 - val_loss: 1.3180 - val_accuracy: 0.4700\n",
      "Epoch 2258/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8781 - accuracy: 0.6871 - val_loss: 1.3172 - val_accuracy: 0.4633\n",
      "Epoch 2259/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8780 - accuracy: 0.6900 - val_loss: 1.3178 - val_accuracy: 0.4667\n",
      "Epoch 2260/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8778 - accuracy: 0.6886 - val_loss: 1.3176 - val_accuracy: 0.4667\n",
      "Epoch 2261/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8775 - accuracy: 0.6871 - val_loss: 1.3168 - val_accuracy: 0.4633\n",
      "Epoch 2262/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8776 - accuracy: 0.6886 - val_loss: 1.3178 - val_accuracy: 0.4667\n",
      "Epoch 2263/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 0.8774 - accuracy: 0.6886 - val_loss: 1.3182 - val_accuracy: 0.4700\n",
      "Epoch 2264/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8774 - accuracy: 0.6886 - val_loss: 1.3182 - val_accuracy: 0.4700\n",
      "Epoch 2265/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8771 - accuracy: 0.6900 - val_loss: 1.3173 - val_accuracy: 0.4700\n",
      "Epoch 2266/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8770 - accuracy: 0.6871 - val_loss: 1.3180 - val_accuracy: 0.4667\n",
      "Epoch 2267/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8771 - accuracy: 0.6914 - val_loss: 1.3183 - val_accuracy: 0.4700\n",
      "Epoch 2268/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8769 - accuracy: 0.6900 - val_loss: 1.3184 - val_accuracy: 0.4700\n",
      "Epoch 2269/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8768 - accuracy: 0.6929 - val_loss: 1.3193 - val_accuracy: 0.4733\n",
      "Epoch 2270/3000\n",
      "700/700 [==============================] - 0s 89us/sample - loss: 0.8768 - accuracy: 0.6929 - val_loss: 1.3182 - val_accuracy: 0.4700\n",
      "Epoch 2271/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 0.8767 - accuracy: 0.6886 - val_loss: 1.3179 - val_accuracy: 0.4733\n",
      "Epoch 2272/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8764 - accuracy: 0.6914 - val_loss: 1.3198 - val_accuracy: 0.4700\n",
      "Epoch 2273/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8765 - accuracy: 0.6886 - val_loss: 1.3191 - val_accuracy: 0.4700\n",
      "Epoch 2274/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8763 - accuracy: 0.6871 - val_loss: 1.3202 - val_accuracy: 0.4733\n",
      "Epoch 2275/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8763 - accuracy: 0.6914 - val_loss: 1.3191 - val_accuracy: 0.4767\n",
      "Epoch 2276/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8760 - accuracy: 0.6929 - val_loss: 1.3191 - val_accuracy: 0.4733\n",
      "Epoch 2277/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8760 - accuracy: 0.6900 - val_loss: 1.3191 - val_accuracy: 0.4733\n",
      "Epoch 2278/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8757 - accuracy: 0.6914 - val_loss: 1.3186 - val_accuracy: 0.4700\n",
      "Epoch 2279/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8757 - accuracy: 0.6914 - val_loss: 1.3186 - val_accuracy: 0.4733\n",
      "Epoch 2280/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8756 - accuracy: 0.6929 - val_loss: 1.3182 - val_accuracy: 0.4667\n",
      "Epoch 2281/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8756 - accuracy: 0.6900 - val_loss: 1.3188 - val_accuracy: 0.4733\n",
      "Epoch 2282/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8754 - accuracy: 0.6871 - val_loss: 1.3186 - val_accuracy: 0.4700\n",
      "Epoch 2283/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8754 - accuracy: 0.6900 - val_loss: 1.3193 - val_accuracy: 0.4700\n",
      "Epoch 2284/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8753 - accuracy: 0.6914 - val_loss: 1.3192 - val_accuracy: 0.4767\n",
      "Epoch 2285/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8752 - accuracy: 0.6900 - val_loss: 1.3202 - val_accuracy: 0.4733\n",
      "Epoch 2286/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8750 - accuracy: 0.6914 - val_loss: 1.3196 - val_accuracy: 0.4700\n",
      "Epoch 2287/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8747 - accuracy: 0.6929 - val_loss: 1.3182 - val_accuracy: 0.4733\n",
      "Epoch 2288/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8749 - accuracy: 0.6900 - val_loss: 1.3196 - val_accuracy: 0.4733\n",
      "Epoch 2289/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8747 - accuracy: 0.6857 - val_loss: 1.3196 - val_accuracy: 0.4733\n",
      "Epoch 2290/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8746 - accuracy: 0.6900 - val_loss: 1.3198 - val_accuracy: 0.4733\n",
      "Epoch 2291/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8744 - accuracy: 0.6957 - val_loss: 1.3201 - val_accuracy: 0.4733\n",
      "Epoch 2292/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8743 - accuracy: 0.6914 - val_loss: 1.3209 - val_accuracy: 0.4700\n",
      "Epoch 2293/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8742 - accuracy: 0.6929 - val_loss: 1.3194 - val_accuracy: 0.4733\n",
      "Epoch 2294/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8741 - accuracy: 0.6943 - val_loss: 1.3212 - val_accuracy: 0.4700\n",
      "Epoch 2295/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8740 - accuracy: 0.6914 - val_loss: 1.3202 - val_accuracy: 0.4733\n",
      "Epoch 2296/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8740 - accuracy: 0.6914 - val_loss: 1.3204 - val_accuracy: 0.4733\n",
      "Epoch 2297/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8740 - accuracy: 0.6929 - val_loss: 1.3206 - val_accuracy: 0.4733\n",
      "Epoch 2298/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8739 - accuracy: 0.6914 - val_loss: 1.3205 - val_accuracy: 0.4733\n",
      "Epoch 2299/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8735 - accuracy: 0.6943 - val_loss: 1.3197 - val_accuracy: 0.4733\n",
      "Epoch 2300/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8735 - accuracy: 0.6914 - val_loss: 1.3199 - val_accuracy: 0.4700\n",
      "Epoch 2301/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8735 - accuracy: 0.6929 - val_loss: 1.3195 - val_accuracy: 0.4767\n",
      "Epoch 2302/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8733 - accuracy: 0.6900 - val_loss: 1.3195 - val_accuracy: 0.4767\n",
      "Epoch 2303/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8731 - accuracy: 0.6914 - val_loss: 1.3206 - val_accuracy: 0.4733\n",
      "Epoch 2304/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8732 - accuracy: 0.6929 - val_loss: 1.3199 - val_accuracy: 0.4767\n",
      "Epoch 2305/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8731 - accuracy: 0.6914 - val_loss: 1.3207 - val_accuracy: 0.4733\n",
      "Epoch 2306/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8729 - accuracy: 0.6914 - val_loss: 1.3211 - val_accuracy: 0.4733\n",
      "Epoch 2307/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8728 - accuracy: 0.6900 - val_loss: 1.3212 - val_accuracy: 0.4733\n",
      "Epoch 2308/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8727 - accuracy: 0.6900 - val_loss: 1.3206 - val_accuracy: 0.4733\n",
      "Epoch 2309/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8726 - accuracy: 0.6943 - val_loss: 1.3212 - val_accuracy: 0.4733\n",
      "Epoch 2310/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8726 - accuracy: 0.6914 - val_loss: 1.3212 - val_accuracy: 0.4733\n",
      "Epoch 2311/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8723 - accuracy: 0.6957 - val_loss: 1.3214 - val_accuracy: 0.4733\n",
      "Epoch 2312/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8724 - accuracy: 0.6943 - val_loss: 1.3218 - val_accuracy: 0.4733\n",
      "Epoch 2313/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8723 - accuracy: 0.6943 - val_loss: 1.3216 - val_accuracy: 0.4733\n",
      "Epoch 2314/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8720 - accuracy: 0.6914 - val_loss: 1.3203 - val_accuracy: 0.4733\n",
      "Epoch 2315/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8720 - accuracy: 0.6943 - val_loss: 1.3206 - val_accuracy: 0.4733\n",
      "Epoch 2316/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8719 - accuracy: 0.6886 - val_loss: 1.3205 - val_accuracy: 0.4767\n",
      "Epoch 2317/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8717 - accuracy: 0.6943 - val_loss: 1.3214 - val_accuracy: 0.4700\n",
      "Epoch 2318/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8718 - accuracy: 0.6914 - val_loss: 1.3213 - val_accuracy: 0.4700\n",
      "Epoch 2319/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8715 - accuracy: 0.6971 - val_loss: 1.3222 - val_accuracy: 0.4733\n",
      "Epoch 2320/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8718 - accuracy: 0.6929 - val_loss: 1.3221 - val_accuracy: 0.4700\n",
      "Epoch 2321/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8713 - accuracy: 0.6943 - val_loss: 1.3225 - val_accuracy: 0.4733\n",
      "Epoch 2322/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8715 - accuracy: 0.6914 - val_loss: 1.3222 - val_accuracy: 0.4733\n",
      "Epoch 2323/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8713 - accuracy: 0.6957 - val_loss: 1.3225 - val_accuracy: 0.4733\n",
      "Epoch 2324/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8712 - accuracy: 0.6914 - val_loss: 1.3217 - val_accuracy: 0.4733\n",
      "Epoch 2325/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8711 - accuracy: 0.6929 - val_loss: 1.3225 - val_accuracy: 0.4733\n",
      "Epoch 2326/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8710 - accuracy: 0.6929 - val_loss: 1.3233 - val_accuracy: 0.4733\n",
      "Epoch 2327/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8708 - accuracy: 0.6929 - val_loss: 1.3233 - val_accuracy: 0.4733\n",
      "Epoch 2328/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8708 - accuracy: 0.6929 - val_loss: 1.3227 - val_accuracy: 0.4700\n",
      "Epoch 2329/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8705 - accuracy: 0.6957 - val_loss: 1.3232 - val_accuracy: 0.4700\n",
      "Epoch 2330/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8705 - accuracy: 0.6957 - val_loss: 1.3235 - val_accuracy: 0.4667\n",
      "Epoch 2331/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.8705 - accuracy: 0.6971 - val_loss: 1.3235 - val_accuracy: 0.4667\n",
      "Epoch 2332/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8704 - accuracy: 0.6914 - val_loss: 1.3231 - val_accuracy: 0.4700\n",
      "Epoch 2333/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8702 - accuracy: 0.6929 - val_loss: 1.3225 - val_accuracy: 0.4700\n",
      "Epoch 2334/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8700 - accuracy: 0.6929 - val_loss: 1.3228 - val_accuracy: 0.4700\n",
      "Epoch 2335/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8700 - accuracy: 0.6957 - val_loss: 1.3228 - val_accuracy: 0.4700\n",
      "Epoch 2336/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8699 - accuracy: 0.6971 - val_loss: 1.3225 - val_accuracy: 0.4733\n",
      "Epoch 2337/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8698 - accuracy: 0.6957 - val_loss: 1.3222 - val_accuracy: 0.4733\n",
      "Epoch 2338/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8699 - accuracy: 0.6943 - val_loss: 1.3228 - val_accuracy: 0.4733\n",
      "Epoch 2339/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8696 - accuracy: 0.6957 - val_loss: 1.3219 - val_accuracy: 0.4700\n",
      "Epoch 2340/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8696 - accuracy: 0.6929 - val_loss: 1.3233 - val_accuracy: 0.4700\n",
      "Epoch 2341/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8693 - accuracy: 0.6957 - val_loss: 1.3223 - val_accuracy: 0.4700\n",
      "Epoch 2342/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8692 - accuracy: 0.6943 - val_loss: 1.3240 - val_accuracy: 0.4700\n",
      "Epoch 2343/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8692 - accuracy: 0.6971 - val_loss: 1.3227 - val_accuracy: 0.4767\n",
      "Epoch 2344/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8691 - accuracy: 0.6986 - val_loss: 1.3230 - val_accuracy: 0.4767\n",
      "Epoch 2345/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8690 - accuracy: 0.6957 - val_loss: 1.3237 - val_accuracy: 0.4767\n",
      "Epoch 2346/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8690 - accuracy: 0.7000 - val_loss: 1.3242 - val_accuracy: 0.4733\n",
      "Epoch 2347/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8688 - accuracy: 0.6957 - val_loss: 1.3238 - val_accuracy: 0.4733\n",
      "Epoch 2348/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8688 - accuracy: 0.6957 - val_loss: 1.3240 - val_accuracy: 0.4733\n",
      "Epoch 2349/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8687 - accuracy: 0.6957 - val_loss: 1.3243 - val_accuracy: 0.4700\n",
      "Epoch 2350/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8684 - accuracy: 0.6971 - val_loss: 1.3233 - val_accuracy: 0.4733\n",
      "Epoch 2351/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8684 - accuracy: 0.6971 - val_loss: 1.3235 - val_accuracy: 0.4733\n",
      "Epoch 2352/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8683 - accuracy: 0.6929 - val_loss: 1.3232 - val_accuracy: 0.4733\n",
      "Epoch 2353/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8681 - accuracy: 0.6943 - val_loss: 1.3238 - val_accuracy: 0.4733\n",
      "Epoch 2354/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8680 - accuracy: 0.6957 - val_loss: 1.3248 - val_accuracy: 0.4700\n",
      "Epoch 2355/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8680 - accuracy: 0.6986 - val_loss: 1.3248 - val_accuracy: 0.4700\n",
      "Epoch 2356/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8676 - accuracy: 0.7000 - val_loss: 1.3249 - val_accuracy: 0.4667\n",
      "Epoch 2357/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8676 - accuracy: 0.6943 - val_loss: 1.3232 - val_accuracy: 0.4733\n",
      "Epoch 2358/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8677 - accuracy: 0.6914 - val_loss: 1.3236 - val_accuracy: 0.4700\n",
      "Epoch 2359/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8676 - accuracy: 0.6957 - val_loss: 1.3240 - val_accuracy: 0.4700\n",
      "Epoch 2360/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8675 - accuracy: 0.6957 - val_loss: 1.3244 - val_accuracy: 0.4700\n",
      "Epoch 2361/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8674 - accuracy: 0.6971 - val_loss: 1.3249 - val_accuracy: 0.4700\n",
      "Epoch 2362/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8674 - accuracy: 0.6986 - val_loss: 1.3248 - val_accuracy: 0.4700\n",
      "Epoch 2363/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8672 - accuracy: 0.6957 - val_loss: 1.3240 - val_accuracy: 0.4733\n",
      "Epoch 2364/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8672 - accuracy: 0.6971 - val_loss: 1.3245 - val_accuracy: 0.4733\n",
      "Epoch 2365/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8670 - accuracy: 0.6943 - val_loss: 1.3254 - val_accuracy: 0.4733\n",
      "Epoch 2366/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8669 - accuracy: 0.6957 - val_loss: 1.3254 - val_accuracy: 0.4733\n",
      "Epoch 2367/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8668 - accuracy: 0.6971 - val_loss: 1.3251 - val_accuracy: 0.4733\n",
      "Epoch 2368/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8666 - accuracy: 0.7000 - val_loss: 1.3255 - val_accuracy: 0.4733\n",
      "Epoch 2369/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8667 - accuracy: 0.6971 - val_loss: 1.3254 - val_accuracy: 0.4733\n",
      "Epoch 2370/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8665 - accuracy: 0.6971 - val_loss: 1.3259 - val_accuracy: 0.4700\n",
      "Epoch 2371/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8663 - accuracy: 0.6986 - val_loss: 1.3262 - val_accuracy: 0.4700\n",
      "Epoch 2372/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8662 - accuracy: 0.6971 - val_loss: 1.3247 - val_accuracy: 0.4733\n",
      "Epoch 2373/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8663 - accuracy: 0.7000 - val_loss: 1.3249 - val_accuracy: 0.4733\n",
      "Epoch 2374/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8661 - accuracy: 0.6957 - val_loss: 1.3248 - val_accuracy: 0.4733\n",
      "Epoch 2375/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8660 - accuracy: 0.6986 - val_loss: 1.3248 - val_accuracy: 0.4733\n",
      "Epoch 2376/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8660 - accuracy: 0.6971 - val_loss: 1.3252 - val_accuracy: 0.4733\n",
      "Epoch 2377/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8656 - accuracy: 0.6957 - val_loss: 1.3258 - val_accuracy: 0.4733\n",
      "Epoch 2378/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8656 - accuracy: 0.6971 - val_loss: 1.3251 - val_accuracy: 0.4733\n",
      "Epoch 2379/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8658 - accuracy: 0.6986 - val_loss: 1.3257 - val_accuracy: 0.4733\n",
      "Epoch 2380/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8654 - accuracy: 0.7029 - val_loss: 1.3267 - val_accuracy: 0.4767\n",
      "Epoch 2381/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8655 - accuracy: 0.6986 - val_loss: 1.3264 - val_accuracy: 0.4733\n",
      "Epoch 2382/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8653 - accuracy: 0.6943 - val_loss: 1.3255 - val_accuracy: 0.4733\n",
      "Epoch 2383/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8651 - accuracy: 0.6986 - val_loss: 1.3262 - val_accuracy: 0.4733\n",
      "Epoch 2384/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8650 - accuracy: 0.6957 - val_loss: 1.3262 - val_accuracy: 0.4733\n",
      "Epoch 2385/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8650 - accuracy: 0.6943 - val_loss: 1.3265 - val_accuracy: 0.4733\n",
      "Epoch 2386/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8649 - accuracy: 0.6986 - val_loss: 1.3265 - val_accuracy: 0.4767\n",
      "Epoch 2387/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8647 - accuracy: 0.6971 - val_loss: 1.3272 - val_accuracy: 0.4800\n",
      "Epoch 2388/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8648 - accuracy: 0.6957 - val_loss: 1.3264 - val_accuracy: 0.4767\n",
      "Epoch 2389/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8647 - accuracy: 0.6971 - val_loss: 1.3262 - val_accuracy: 0.4767\n",
      "Epoch 2390/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8646 - accuracy: 0.6986 - val_loss: 1.3272 - val_accuracy: 0.4767\n",
      "Epoch 2391/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8645 - accuracy: 0.7000 - val_loss: 1.3268 - val_accuracy: 0.4767\n",
      "Epoch 2392/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8643 - accuracy: 0.6986 - val_loss: 1.3279 - val_accuracy: 0.4767\n",
      "Epoch 2393/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8646 - accuracy: 0.6986 - val_loss: 1.3271 - val_accuracy: 0.4767\n",
      "Epoch 2394/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8642 - accuracy: 0.6971 - val_loss: 1.3280 - val_accuracy: 0.4800\n",
      "Epoch 2395/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8639 - accuracy: 0.6986 - val_loss: 1.3273 - val_accuracy: 0.4767\n",
      "Epoch 2396/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8640 - accuracy: 0.6986 - val_loss: 1.3276 - val_accuracy: 0.4733\n",
      "Epoch 2397/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8637 - accuracy: 0.7000 - val_loss: 1.3285 - val_accuracy: 0.4767\n",
      "Epoch 2398/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8637 - accuracy: 0.6971 - val_loss: 1.3279 - val_accuracy: 0.4767\n",
      "Epoch 2399/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8637 - accuracy: 0.7000 - val_loss: 1.3283 - val_accuracy: 0.4767\n",
      "Epoch 2400/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8636 - accuracy: 0.7000 - val_loss: 1.3278 - val_accuracy: 0.4767\n",
      "Epoch 2401/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8635 - accuracy: 0.6957 - val_loss: 1.3276 - val_accuracy: 0.4767\n",
      "Epoch 2402/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8634 - accuracy: 0.7000 - val_loss: 1.3278 - val_accuracy: 0.4767\n",
      "Epoch 2403/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8633 - accuracy: 0.6971 - val_loss: 1.3287 - val_accuracy: 0.4767\n",
      "Epoch 2404/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.8632 - accuracy: 0.6986 - val_loss: 1.3277 - val_accuracy: 0.4767\n",
      "Epoch 2405/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8631 - accuracy: 0.7000 - val_loss: 1.3280 - val_accuracy: 0.4767\n",
      "Epoch 2406/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8630 - accuracy: 0.6986 - val_loss: 1.3273 - val_accuracy: 0.4767\n",
      "Epoch 2407/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8629 - accuracy: 0.6986 - val_loss: 1.3273 - val_accuracy: 0.4767\n",
      "Epoch 2408/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8628 - accuracy: 0.6971 - val_loss: 1.3275 - val_accuracy: 0.4767\n",
      "Epoch 2409/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8626 - accuracy: 0.6986 - val_loss: 1.3280 - val_accuracy: 0.4800\n",
      "Epoch 2410/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8626 - accuracy: 0.6986 - val_loss: 1.3285 - val_accuracy: 0.4767\n",
      "Epoch 2411/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8624 - accuracy: 0.6986 - val_loss: 1.3280 - val_accuracy: 0.4767\n",
      "Epoch 2412/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8622 - accuracy: 0.6986 - val_loss: 1.3282 - val_accuracy: 0.4767\n",
      "Epoch 2413/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8621 - accuracy: 0.6929 - val_loss: 1.3271 - val_accuracy: 0.4800\n",
      "Epoch 2414/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8623 - accuracy: 0.7000 - val_loss: 1.3276 - val_accuracy: 0.4800\n",
      "Epoch 2415/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8621 - accuracy: 0.7029 - val_loss: 1.3271 - val_accuracy: 0.4800\n",
      "Epoch 2416/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8622 - accuracy: 0.6986 - val_loss: 1.3277 - val_accuracy: 0.4800\n",
      "Epoch 2417/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8617 - accuracy: 0.7000 - val_loss: 1.3274 - val_accuracy: 0.4800\n",
      "Epoch 2418/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8618 - accuracy: 0.6986 - val_loss: 1.3293 - val_accuracy: 0.4767\n",
      "Epoch 2419/3000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 0.8615 - accuracy: 0.6986 - val_loss: 1.3281 - val_accuracy: 0.4800\n",
      "Epoch 2420/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8617 - accuracy: 0.7014 - val_loss: 1.3279 - val_accuracy: 0.4800\n",
      "Epoch 2421/3000\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 0.8616 - accuracy: 0.7000 - val_loss: 1.3290 - val_accuracy: 0.4800\n",
      "Epoch 2422/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8613 - accuracy: 0.7000 - val_loss: 1.3281 - val_accuracy: 0.4800\n",
      "Epoch 2423/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8614 - accuracy: 0.6986 - val_loss: 1.3289 - val_accuracy: 0.4767\n",
      "Epoch 2424/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8613 - accuracy: 0.7029 - val_loss: 1.3295 - val_accuracy: 0.4767\n",
      "Epoch 2425/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8612 - accuracy: 0.6986 - val_loss: 1.3291 - val_accuracy: 0.4767\n",
      "Epoch 2426/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8610 - accuracy: 0.7000 - val_loss: 1.3298 - val_accuracy: 0.4767\n",
      "Epoch 2427/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8608 - accuracy: 0.7014 - val_loss: 1.3292 - val_accuracy: 0.4733\n",
      "Epoch 2428/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8608 - accuracy: 0.7014 - val_loss: 1.3291 - val_accuracy: 0.4733\n",
      "Epoch 2429/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.8607 - accuracy: 0.6986 - val_loss: 1.3295 - val_accuracy: 0.4767\n",
      "Epoch 2430/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8606 - accuracy: 0.6986 - val_loss: 1.3299 - val_accuracy: 0.4767\n",
      "Epoch 2431/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8604 - accuracy: 0.7014 - val_loss: 1.3304 - val_accuracy: 0.4767\n",
      "Epoch 2432/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8606 - accuracy: 0.7000 - val_loss: 1.3312 - val_accuracy: 0.4767\n",
      "Epoch 2433/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8603 - accuracy: 0.7000 - val_loss: 1.3301 - val_accuracy: 0.4767\n",
      "Epoch 2434/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8601 - accuracy: 0.7029 - val_loss: 1.3306 - val_accuracy: 0.4767\n",
      "Epoch 2435/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8601 - accuracy: 0.7014 - val_loss: 1.3297 - val_accuracy: 0.4767\n",
      "Epoch 2436/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8601 - accuracy: 0.6986 - val_loss: 1.3298 - val_accuracy: 0.4767\n",
      "Epoch 2437/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8599 - accuracy: 0.6971 - val_loss: 1.3296 - val_accuracy: 0.4767\n",
      "Epoch 2438/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8598 - accuracy: 0.7000 - val_loss: 1.3296 - val_accuracy: 0.4767\n",
      "Epoch 2439/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8596 - accuracy: 0.7014 - val_loss: 1.3292 - val_accuracy: 0.4767\n",
      "Epoch 2440/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8598 - accuracy: 0.7057 - val_loss: 1.3301 - val_accuracy: 0.4767\n",
      "Epoch 2441/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8596 - accuracy: 0.7000 - val_loss: 1.3306 - val_accuracy: 0.4767\n",
      "Epoch 2442/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8594 - accuracy: 0.7014 - val_loss: 1.3303 - val_accuracy: 0.4767\n",
      "Epoch 2443/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8594 - accuracy: 0.7014 - val_loss: 1.3299 - val_accuracy: 0.4767\n",
      "Epoch 2444/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8593 - accuracy: 0.6986 - val_loss: 1.3307 - val_accuracy: 0.4767\n",
      "Epoch 2445/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8593 - accuracy: 0.6986 - val_loss: 1.3317 - val_accuracy: 0.4767\n",
      "Epoch 2446/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8592 - accuracy: 0.7000 - val_loss: 1.3308 - val_accuracy: 0.4800\n",
      "Epoch 2447/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8589 - accuracy: 0.7029 - val_loss: 1.3313 - val_accuracy: 0.4800\n",
      "Epoch 2448/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8589 - accuracy: 0.7029 - val_loss: 1.3312 - val_accuracy: 0.4767\n",
      "Epoch 2449/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8588 - accuracy: 0.7000 - val_loss: 1.3318 - val_accuracy: 0.4767\n",
      "Epoch 2450/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8586 - accuracy: 0.6971 - val_loss: 1.3303 - val_accuracy: 0.4767\n",
      "Epoch 2451/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8585 - accuracy: 0.7043 - val_loss: 1.3321 - val_accuracy: 0.4767\n",
      "Epoch 2452/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8585 - accuracy: 0.6986 - val_loss: 1.3326 - val_accuracy: 0.4800\n",
      "Epoch 2453/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8586 - accuracy: 0.7029 - val_loss: 1.3313 - val_accuracy: 0.4800\n",
      "Epoch 2454/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8582 - accuracy: 0.7014 - val_loss: 1.3313 - val_accuracy: 0.4800\n",
      "Epoch 2455/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.8581 - accuracy: 0.7029 - val_loss: 1.3314 - val_accuracy: 0.4767\n",
      "Epoch 2456/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8582 - accuracy: 0.6986 - val_loss: 1.3313 - val_accuracy: 0.4767\n",
      "Epoch 2457/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8580 - accuracy: 0.6986 - val_loss: 1.3324 - val_accuracy: 0.4767\n",
      "Epoch 2458/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 0.8579 - accuracy: 0.7014 - val_loss: 1.3311 - val_accuracy: 0.4767\n",
      "Epoch 2459/3000\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 0.8578 - accuracy: 0.7014 - val_loss: 1.3324 - val_accuracy: 0.4767\n",
      "Epoch 2460/3000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 0.8578 - accuracy: 0.7057 - val_loss: 1.3322 - val_accuracy: 0.4800\n",
      "Epoch 2461/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8575 - accuracy: 0.7014 - val_loss: 1.3329 - val_accuracy: 0.4800\n",
      "Epoch 2462/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8576 - accuracy: 0.7000 - val_loss: 1.3322 - val_accuracy: 0.4800\n",
      "Epoch 2463/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8574 - accuracy: 0.7029 - val_loss: 1.3329 - val_accuracy: 0.4767\n",
      "Epoch 2464/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8573 - accuracy: 0.7014 - val_loss: 1.3320 - val_accuracy: 0.4767\n",
      "Epoch 2465/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8574 - accuracy: 0.7029 - val_loss: 1.3328 - val_accuracy: 0.4800\n",
      "Epoch 2466/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8569 - accuracy: 0.6986 - val_loss: 1.3317 - val_accuracy: 0.4767\n",
      "Epoch 2467/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8570 - accuracy: 0.7014 - val_loss: 1.3322 - val_accuracy: 0.4767\n",
      "Epoch 2468/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8570 - accuracy: 0.7014 - val_loss: 1.3333 - val_accuracy: 0.4733\n",
      "Epoch 2469/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8567 - accuracy: 0.7071 - val_loss: 1.3346 - val_accuracy: 0.4733\n",
      "Epoch 2470/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8569 - accuracy: 0.7029 - val_loss: 1.3334 - val_accuracy: 0.4800\n",
      "Epoch 2471/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8567 - accuracy: 0.7043 - val_loss: 1.3329 - val_accuracy: 0.4800\n",
      "Epoch 2472/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8565 - accuracy: 0.7014 - val_loss: 1.3328 - val_accuracy: 0.4800\n",
      "Epoch 2473/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8564 - accuracy: 0.7071 - val_loss: 1.3341 - val_accuracy: 0.4733\n",
      "Epoch 2474/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8564 - accuracy: 0.7014 - val_loss: 1.3331 - val_accuracy: 0.4767\n",
      "Epoch 2475/3000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 0.8563 - accuracy: 0.7029 - val_loss: 1.3333 - val_accuracy: 0.4767\n",
      "Epoch 2476/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.8560 - accuracy: 0.7029 - val_loss: 1.3321 - val_accuracy: 0.4800\n",
      "Epoch 2477/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8559 - accuracy: 0.7014 - val_loss: 1.3348 - val_accuracy: 0.4733\n",
      "Epoch 2478/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8560 - accuracy: 0.7043 - val_loss: 1.3332 - val_accuracy: 0.4800\n",
      "Epoch 2479/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8561 - accuracy: 0.7029 - val_loss: 1.3336 - val_accuracy: 0.4800\n",
      "Epoch 2480/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8557 - accuracy: 0.7000 - val_loss: 1.3341 - val_accuracy: 0.4767\n",
      "Epoch 2481/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8557 - accuracy: 0.7000 - val_loss: 1.3332 - val_accuracy: 0.4767\n",
      "Epoch 2482/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.8555 - accuracy: 0.7014 - val_loss: 1.3346 - val_accuracy: 0.4733\n",
      "Epoch 2483/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.8555 - accuracy: 0.7057 - val_loss: 1.3351 - val_accuracy: 0.4733\n",
      "Epoch 2484/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8554 - accuracy: 0.7000 - val_loss: 1.3341 - val_accuracy: 0.4733\n",
      "Epoch 2485/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8552 - accuracy: 0.7057 - val_loss: 1.3353 - val_accuracy: 0.4767\n",
      "Epoch 2486/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8554 - accuracy: 0.7043 - val_loss: 1.3345 - val_accuracy: 0.4767\n",
      "Epoch 2487/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8552 - accuracy: 0.7071 - val_loss: 1.3350 - val_accuracy: 0.4767\n",
      "Epoch 2488/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8550 - accuracy: 0.7071 - val_loss: 1.3335 - val_accuracy: 0.4800\n",
      "Epoch 2489/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8550 - accuracy: 0.7057 - val_loss: 1.3350 - val_accuracy: 0.4767\n",
      "Epoch 2490/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8550 - accuracy: 0.7029 - val_loss: 1.3344 - val_accuracy: 0.4800\n",
      "Epoch 2491/3000\n",
      "700/700 [==============================] - 0s 90us/sample - loss: 0.8546 - accuracy: 0.7057 - val_loss: 1.3352 - val_accuracy: 0.4767\n",
      "Epoch 2492/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 0.8548 - accuracy: 0.7043 - val_loss: 1.3352 - val_accuracy: 0.4767\n",
      "Epoch 2493/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8546 - accuracy: 0.7057 - val_loss: 1.3365 - val_accuracy: 0.4767\n",
      "Epoch 2494/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8546 - accuracy: 0.7043 - val_loss: 1.3355 - val_accuracy: 0.4767\n",
      "Epoch 2495/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8544 - accuracy: 0.7086 - val_loss: 1.3362 - val_accuracy: 0.4733\n",
      "Epoch 2496/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8545 - accuracy: 0.7029 - val_loss: 1.3359 - val_accuracy: 0.4733\n",
      "Epoch 2497/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8542 - accuracy: 0.7029 - val_loss: 1.3347 - val_accuracy: 0.4733\n",
      "Epoch 2498/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8541 - accuracy: 0.7014 - val_loss: 1.3361 - val_accuracy: 0.4733\n",
      "Epoch 2499/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8542 - accuracy: 0.7029 - val_loss: 1.3350 - val_accuracy: 0.4733\n",
      "Epoch 2500/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8539 - accuracy: 0.7086 - val_loss: 1.3359 - val_accuracy: 0.4733\n",
      "Epoch 2501/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8538 - accuracy: 0.7071 - val_loss: 1.3354 - val_accuracy: 0.4733\n",
      "Epoch 2502/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8538 - accuracy: 0.7057 - val_loss: 1.3355 - val_accuracy: 0.4733\n",
      "Epoch 2503/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8536 - accuracy: 0.7057 - val_loss: 1.3374 - val_accuracy: 0.4733\n",
      "Epoch 2504/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8537 - accuracy: 0.7057 - val_loss: 1.3364 - val_accuracy: 0.4733\n",
      "Epoch 2505/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8534 - accuracy: 0.7000 - val_loss: 1.3373 - val_accuracy: 0.4767\n",
      "Epoch 2506/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8534 - accuracy: 0.7057 - val_loss: 1.3365 - val_accuracy: 0.4767\n",
      "Epoch 2507/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8534 - accuracy: 0.7057 - val_loss: 1.3372 - val_accuracy: 0.4767\n",
      "Epoch 2508/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8533 - accuracy: 0.7043 - val_loss: 1.3367 - val_accuracy: 0.4733\n",
      "Epoch 2509/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8531 - accuracy: 0.7043 - val_loss: 1.3368 - val_accuracy: 0.4767\n",
      "Epoch 2510/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8530 - accuracy: 0.7057 - val_loss: 1.3355 - val_accuracy: 0.4767\n",
      "Epoch 2511/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8528 - accuracy: 0.7043 - val_loss: 1.3372 - val_accuracy: 0.4733\n",
      "Epoch 2512/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8527 - accuracy: 0.7029 - val_loss: 1.3363 - val_accuracy: 0.4733\n",
      "Epoch 2513/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8527 - accuracy: 0.7057 - val_loss: 1.3365 - val_accuracy: 0.4733\n",
      "Epoch 2514/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 0.8526 - accuracy: 0.7057 - val_loss: 1.3375 - val_accuracy: 0.4767\n",
      "Epoch 2515/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8525 - accuracy: 0.7086 - val_loss: 1.3389 - val_accuracy: 0.4767\n",
      "Epoch 2516/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8525 - accuracy: 0.7071 - val_loss: 1.3373 - val_accuracy: 0.4767\n",
      "Epoch 2517/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8524 - accuracy: 0.7000 - val_loss: 1.3364 - val_accuracy: 0.4733\n",
      "Epoch 2518/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8523 - accuracy: 0.7114 - val_loss: 1.3368 - val_accuracy: 0.4767\n",
      "Epoch 2519/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.8520 - accuracy: 0.7086 - val_loss: 1.3385 - val_accuracy: 0.4767\n",
      "Epoch 2520/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8522 - accuracy: 0.7071 - val_loss: 1.3383 - val_accuracy: 0.4767\n",
      "Epoch 2521/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8520 - accuracy: 0.7057 - val_loss: 1.3381 - val_accuracy: 0.4733\n",
      "Epoch 2522/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8518 - accuracy: 0.7057 - val_loss: 1.3380 - val_accuracy: 0.4733\n",
      "Epoch 2523/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8516 - accuracy: 0.7071 - val_loss: 1.3374 - val_accuracy: 0.4767\n",
      "Epoch 2524/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8515 - accuracy: 0.7057 - val_loss: 1.3375 - val_accuracy: 0.4767\n",
      "Epoch 2525/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8516 - accuracy: 0.7129 - val_loss: 1.3375 - val_accuracy: 0.4733\n",
      "Epoch 2526/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8514 - accuracy: 0.7100 - val_loss: 1.3368 - val_accuracy: 0.4733\n",
      "Epoch 2527/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8516 - accuracy: 0.7057 - val_loss: 1.3378 - val_accuracy: 0.4733\n",
      "Epoch 2528/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8513 - accuracy: 0.7086 - val_loss: 1.3377 - val_accuracy: 0.4733\n",
      "Epoch 2529/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8513 - accuracy: 0.7071 - val_loss: 1.3371 - val_accuracy: 0.4733\n",
      "Epoch 2530/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8512 - accuracy: 0.7086 - val_loss: 1.3380 - val_accuracy: 0.4733\n",
      "Epoch 2531/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8511 - accuracy: 0.7057 - val_loss: 1.3381 - val_accuracy: 0.4733\n",
      "Epoch 2532/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8510 - accuracy: 0.7071 - val_loss: 1.3380 - val_accuracy: 0.4733\n",
      "Epoch 2533/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8507 - accuracy: 0.7100 - val_loss: 1.3372 - val_accuracy: 0.4733\n",
      "Epoch 2534/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8507 - accuracy: 0.7086 - val_loss: 1.3378 - val_accuracy: 0.4733\n",
      "Epoch 2535/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8509 - accuracy: 0.7100 - val_loss: 1.3392 - val_accuracy: 0.4733\n",
      "Epoch 2536/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8505 - accuracy: 0.7029 - val_loss: 1.3383 - val_accuracy: 0.4733\n",
      "Epoch 2537/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8504 - accuracy: 0.7071 - val_loss: 1.3375 - val_accuracy: 0.4733\n",
      "Epoch 2538/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8506 - accuracy: 0.7057 - val_loss: 1.3386 - val_accuracy: 0.4767\n",
      "Epoch 2539/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8504 - accuracy: 0.7086 - val_loss: 1.3392 - val_accuracy: 0.4767\n",
      "Epoch 2540/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8503 - accuracy: 0.7071 - val_loss: 1.3384 - val_accuracy: 0.4733\n",
      "Epoch 2541/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8501 - accuracy: 0.7086 - val_loss: 1.3393 - val_accuracy: 0.4767\n",
      "Epoch 2542/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8502 - accuracy: 0.7071 - val_loss: 1.3390 - val_accuracy: 0.4767\n",
      "Epoch 2543/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8500 - accuracy: 0.7100 - val_loss: 1.3389 - val_accuracy: 0.4767\n",
      "Epoch 2544/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8499 - accuracy: 0.7129 - val_loss: 1.3395 - val_accuracy: 0.4767\n",
      "Epoch 2545/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8499 - accuracy: 0.7071 - val_loss: 1.3397 - val_accuracy: 0.4733\n",
      "Epoch 2546/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8497 - accuracy: 0.7086 - val_loss: 1.3392 - val_accuracy: 0.4733\n",
      "Epoch 2547/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 0.8497 - accuracy: 0.7086 - val_loss: 1.3387 - val_accuracy: 0.4733\n",
      "Epoch 2548/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8494 - accuracy: 0.7100 - val_loss: 1.3384 - val_accuracy: 0.4733\n",
      "Epoch 2549/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8494 - accuracy: 0.7086 - val_loss: 1.3403 - val_accuracy: 0.4733\n",
      "Epoch 2550/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8493 - accuracy: 0.7071 - val_loss: 1.3396 - val_accuracy: 0.4733\n",
      "Epoch 2551/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8493 - accuracy: 0.7114 - val_loss: 1.3409 - val_accuracy: 0.4767\n",
      "Epoch 2552/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8491 - accuracy: 0.7057 - val_loss: 1.3406 - val_accuracy: 0.4767\n",
      "Epoch 2553/3000\n",
      "700/700 [==============================] - 0s 111us/sample - loss: 0.8490 - accuracy: 0.7100 - val_loss: 1.3412 - val_accuracy: 0.4767\n",
      "Epoch 2554/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8491 - accuracy: 0.7086 - val_loss: 1.3404 - val_accuracy: 0.4767\n",
      "Epoch 2555/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8490 - accuracy: 0.7100 - val_loss: 1.3399 - val_accuracy: 0.4767\n",
      "Epoch 2556/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8487 - accuracy: 0.7086 - val_loss: 1.3407 - val_accuracy: 0.4767\n",
      "Epoch 2557/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8486 - accuracy: 0.7100 - val_loss: 1.3416 - val_accuracy: 0.4767\n",
      "Epoch 2558/3000\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 0.8486 - accuracy: 0.7114 - val_loss: 1.3403 - val_accuracy: 0.4767\n",
      "Epoch 2559/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.8484 - accuracy: 0.7086 - val_loss: 1.3414 - val_accuracy: 0.4767\n",
      "Epoch 2560/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8483 - accuracy: 0.7100 - val_loss: 1.3409 - val_accuracy: 0.4733\n",
      "Epoch 2561/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8483 - accuracy: 0.7071 - val_loss: 1.3401 - val_accuracy: 0.4767\n",
      "Epoch 2562/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.8482 - accuracy: 0.7071 - val_loss: 1.3409 - val_accuracy: 0.4733\n",
      "Epoch 2563/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8482 - accuracy: 0.7100 - val_loss: 1.3410 - val_accuracy: 0.4767\n",
      "Epoch 2564/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8479 - accuracy: 0.7086 - val_loss: 1.3398 - val_accuracy: 0.4767\n",
      "Epoch 2565/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8482 - accuracy: 0.7086 - val_loss: 1.3413 - val_accuracy: 0.4733\n",
      "Epoch 2566/3000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 0.8478 - accuracy: 0.7071 - val_loss: 1.3416 - val_accuracy: 0.4733\n",
      "Epoch 2567/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8479 - accuracy: 0.7129 - val_loss: 1.3414 - val_accuracy: 0.4733\n",
      "Epoch 2568/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8478 - accuracy: 0.7086 - val_loss: 1.3417 - val_accuracy: 0.4733\n",
      "Epoch 2569/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8475 - accuracy: 0.7100 - val_loss: 1.3426 - val_accuracy: 0.4733\n",
      "Epoch 2570/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8474 - accuracy: 0.7043 - val_loss: 1.3406 - val_accuracy: 0.4767\n",
      "Epoch 2571/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8474 - accuracy: 0.7100 - val_loss: 1.3425 - val_accuracy: 0.4733\n",
      "Epoch 2572/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8472 - accuracy: 0.7071 - val_loss: 1.3408 - val_accuracy: 0.4800\n",
      "Epoch 2573/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8471 - accuracy: 0.7086 - val_loss: 1.3410 - val_accuracy: 0.4800\n",
      "Epoch 2574/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8472 - accuracy: 0.7114 - val_loss: 1.3419 - val_accuracy: 0.4767\n",
      "Epoch 2575/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8470 - accuracy: 0.7086 - val_loss: 1.3420 - val_accuracy: 0.4800\n",
      "Epoch 2576/3000\n",
      "700/700 [==============================] - 0s 89us/sample - loss: 0.8470 - accuracy: 0.7129 - val_loss: 1.3418 - val_accuracy: 0.4767\n",
      "Epoch 2577/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8468 - accuracy: 0.7100 - val_loss: 1.3422 - val_accuracy: 0.4733\n",
      "Epoch 2578/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8469 - accuracy: 0.7100 - val_loss: 1.3427 - val_accuracy: 0.4733\n",
      "Epoch 2579/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8468 - accuracy: 0.7086 - val_loss: 1.3423 - val_accuracy: 0.4767\n",
      "Epoch 2580/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8465 - accuracy: 0.7100 - val_loss: 1.3426 - val_accuracy: 0.4767\n",
      "Epoch 2581/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8462 - accuracy: 0.7114 - val_loss: 1.3447 - val_accuracy: 0.4767\n",
      "Epoch 2582/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8465 - accuracy: 0.7114 - val_loss: 1.3434 - val_accuracy: 0.4733\n",
      "Epoch 2583/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8464 - accuracy: 0.7129 - val_loss: 1.3428 - val_accuracy: 0.4800\n",
      "Epoch 2584/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8462 - accuracy: 0.7114 - val_loss: 1.3428 - val_accuracy: 0.4767\n",
      "Epoch 2585/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.8460 - accuracy: 0.7071 - val_loss: 1.3436 - val_accuracy: 0.4733\n",
      "Epoch 2586/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8459 - accuracy: 0.7114 - val_loss: 1.3420 - val_accuracy: 0.4800\n",
      "Epoch 2587/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8460 - accuracy: 0.7086 - val_loss: 1.3427 - val_accuracy: 0.4767\n",
      "Epoch 2588/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8458 - accuracy: 0.7114 - val_loss: 1.3429 - val_accuracy: 0.4767\n",
      "Epoch 2589/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8457 - accuracy: 0.7143 - val_loss: 1.3433 - val_accuracy: 0.4800\n",
      "Epoch 2590/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8458 - accuracy: 0.7100 - val_loss: 1.3433 - val_accuracy: 0.4800\n",
      "Epoch 2591/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8456 - accuracy: 0.7100 - val_loss: 1.3442 - val_accuracy: 0.4767\n",
      "Epoch 2592/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8455 - accuracy: 0.7129 - val_loss: 1.3431 - val_accuracy: 0.4767\n",
      "Epoch 2593/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8455 - accuracy: 0.7071 - val_loss: 1.3423 - val_accuracy: 0.4767\n",
      "Epoch 2594/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8453 - accuracy: 0.7143 - val_loss: 1.3445 - val_accuracy: 0.4733\n",
      "Epoch 2595/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8452 - accuracy: 0.7114 - val_loss: 1.3439 - val_accuracy: 0.4800\n",
      "Epoch 2596/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8451 - accuracy: 0.7129 - val_loss: 1.3455 - val_accuracy: 0.4767\n",
      "Epoch 2597/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8451 - accuracy: 0.7114 - val_loss: 1.3456 - val_accuracy: 0.4767\n",
      "Epoch 2598/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8450 - accuracy: 0.7114 - val_loss: 1.3445 - val_accuracy: 0.4800\n",
      "Epoch 2599/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8449 - accuracy: 0.7114 - val_loss: 1.3446 - val_accuracy: 0.4767\n",
      "Epoch 2600/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8448 - accuracy: 0.7114 - val_loss: 1.3452 - val_accuracy: 0.4767\n",
      "Epoch 2601/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.8448 - accuracy: 0.7129 - val_loss: 1.3451 - val_accuracy: 0.4800\n",
      "Epoch 2602/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 0.8446 - accuracy: 0.7129 - val_loss: 1.3453 - val_accuracy: 0.4800\n",
      "Epoch 2603/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8445 - accuracy: 0.7114 - val_loss: 1.3441 - val_accuracy: 0.4767\n",
      "Epoch 2604/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8444 - accuracy: 0.7100 - val_loss: 1.3443 - val_accuracy: 0.4767\n",
      "Epoch 2605/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8443 - accuracy: 0.7100 - val_loss: 1.3434 - val_accuracy: 0.4767\n",
      "Epoch 2606/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8443 - accuracy: 0.7143 - val_loss: 1.3455 - val_accuracy: 0.4767\n",
      "Epoch 2607/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8443 - accuracy: 0.7086 - val_loss: 1.3458 - val_accuracy: 0.4800\n",
      "Epoch 2608/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 0.8442 - accuracy: 0.7086 - val_loss: 1.3449 - val_accuracy: 0.4767\n",
      "Epoch 2609/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8439 - accuracy: 0.7114 - val_loss: 1.3462 - val_accuracy: 0.4767\n",
      "Epoch 2610/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8440 - accuracy: 0.7114 - val_loss: 1.3454 - val_accuracy: 0.4767\n",
      "Epoch 2611/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8438 - accuracy: 0.7143 - val_loss: 1.3449 - val_accuracy: 0.4767\n",
      "Epoch 2612/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8437 - accuracy: 0.7100 - val_loss: 1.3457 - val_accuracy: 0.4767\n",
      "Epoch 2613/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8436 - accuracy: 0.7143 - val_loss: 1.3452 - val_accuracy: 0.4767\n",
      "Epoch 2614/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8435 - accuracy: 0.7129 - val_loss: 1.3450 - val_accuracy: 0.4767\n",
      "Epoch 2615/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8435 - accuracy: 0.7114 - val_loss: 1.3454 - val_accuracy: 0.4767\n",
      "Epoch 2616/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8435 - accuracy: 0.7114 - val_loss: 1.3449 - val_accuracy: 0.4767\n",
      "Epoch 2617/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8433 - accuracy: 0.7143 - val_loss: 1.3466 - val_accuracy: 0.4767\n",
      "Epoch 2618/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8431 - accuracy: 0.7100 - val_loss: 1.3452 - val_accuracy: 0.4767\n",
      "Epoch 2619/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8432 - accuracy: 0.7157 - val_loss: 1.3461 - val_accuracy: 0.4767\n",
      "Epoch 2620/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8430 - accuracy: 0.7100 - val_loss: 1.3465 - val_accuracy: 0.4767\n",
      "Epoch 2621/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8428 - accuracy: 0.7129 - val_loss: 1.3463 - val_accuracy: 0.4767\n",
      "Epoch 2622/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8428 - accuracy: 0.7143 - val_loss: 1.3465 - val_accuracy: 0.4767\n",
      "Epoch 2623/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8428 - accuracy: 0.7157 - val_loss: 1.3461 - val_accuracy: 0.4767\n",
      "Epoch 2624/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8428 - accuracy: 0.7071 - val_loss: 1.3466 - val_accuracy: 0.4767\n",
      "Epoch 2625/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8427 - accuracy: 0.7100 - val_loss: 1.3465 - val_accuracy: 0.4800\n",
      "Epoch 2626/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 0.8424 - accuracy: 0.7157 - val_loss: 1.3469 - val_accuracy: 0.4767\n",
      "Epoch 2627/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8424 - accuracy: 0.7143 - val_loss: 1.3478 - val_accuracy: 0.4767\n",
      "Epoch 2628/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8423 - accuracy: 0.7143 - val_loss: 1.3472 - val_accuracy: 0.4767\n",
      "Epoch 2629/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8423 - accuracy: 0.7100 - val_loss: 1.3466 - val_accuracy: 0.4767\n",
      "Epoch 2630/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8424 - accuracy: 0.7157 - val_loss: 1.3471 - val_accuracy: 0.4767\n",
      "Epoch 2631/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8417 - accuracy: 0.7129 - val_loss: 1.3494 - val_accuracy: 0.4767\n",
      "Epoch 2632/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8422 - accuracy: 0.7114 - val_loss: 1.3481 - val_accuracy: 0.4767\n",
      "Epoch 2633/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8419 - accuracy: 0.7114 - val_loss: 1.3473 - val_accuracy: 0.4767\n",
      "Epoch 2634/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8418 - accuracy: 0.7114 - val_loss: 1.3467 - val_accuracy: 0.4767\n",
      "Epoch 2635/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8417 - accuracy: 0.7143 - val_loss: 1.3474 - val_accuracy: 0.4767\n",
      "Epoch 2636/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8416 - accuracy: 0.7114 - val_loss: 1.3461 - val_accuracy: 0.4767\n",
      "Epoch 2637/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8416 - accuracy: 0.7143 - val_loss: 1.3482 - val_accuracy: 0.4767\n",
      "Epoch 2638/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8414 - accuracy: 0.7143 - val_loss: 1.3477 - val_accuracy: 0.4767\n",
      "Epoch 2639/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8412 - accuracy: 0.7129 - val_loss: 1.3487 - val_accuracy: 0.4800\n",
      "Epoch 2640/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8413 - accuracy: 0.7143 - val_loss: 1.3474 - val_accuracy: 0.4767\n",
      "Epoch 2641/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 0.8412 - accuracy: 0.7129 - val_loss: 1.3484 - val_accuracy: 0.4767\n",
      "Epoch 2642/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8410 - accuracy: 0.7157 - val_loss: 1.3485 - val_accuracy: 0.4767\n",
      "Epoch 2643/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8410 - accuracy: 0.7086 - val_loss: 1.3478 - val_accuracy: 0.4767\n",
      "Epoch 2644/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8410 - accuracy: 0.7143 - val_loss: 1.3495 - val_accuracy: 0.4767\n",
      "Epoch 2645/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8407 - accuracy: 0.7114 - val_loss: 1.3478 - val_accuracy: 0.4767\n",
      "Epoch 2646/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8408 - accuracy: 0.7171 - val_loss: 1.3493 - val_accuracy: 0.4767\n",
      "Epoch 2647/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8406 - accuracy: 0.7114 - val_loss: 1.3499 - val_accuracy: 0.4767\n",
      "Epoch 2648/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 0.8405 - accuracy: 0.7157 - val_loss: 1.3491 - val_accuracy: 0.4767\n",
      "Epoch 2649/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8406 - accuracy: 0.7129 - val_loss: 1.3498 - val_accuracy: 0.4767\n",
      "Epoch 2650/3000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 0.8403 - accuracy: 0.7143 - val_loss: 1.3496 - val_accuracy: 0.4767\n",
      "Epoch 2651/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8402 - accuracy: 0.7114 - val_loss: 1.3505 - val_accuracy: 0.4767\n",
      "Epoch 2652/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8401 - accuracy: 0.7114 - val_loss: 1.3476 - val_accuracy: 0.4800\n",
      "Epoch 2653/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8403 - accuracy: 0.7143 - val_loss: 1.3488 - val_accuracy: 0.4767\n",
      "Epoch 2654/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8401 - accuracy: 0.7086 - val_loss: 1.3491 - val_accuracy: 0.4767\n",
      "Epoch 2655/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8399 - accuracy: 0.7100 - val_loss: 1.3491 - val_accuracy: 0.4767\n",
      "Epoch 2656/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8399 - accuracy: 0.7129 - val_loss: 1.3485 - val_accuracy: 0.4767\n",
      "Epoch 2657/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8398 - accuracy: 0.7100 - val_loss: 1.3499 - val_accuracy: 0.4767\n",
      "Epoch 2658/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8396 - accuracy: 0.7129 - val_loss: 1.3507 - val_accuracy: 0.4733\n",
      "Epoch 2659/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8396 - accuracy: 0.7143 - val_loss: 1.3498 - val_accuracy: 0.4767\n",
      "Epoch 2660/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.8394 - accuracy: 0.7129 - val_loss: 1.3511 - val_accuracy: 0.4767\n",
      "Epoch 2661/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8395 - accuracy: 0.7114 - val_loss: 1.3502 - val_accuracy: 0.4767\n",
      "Epoch 2662/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8395 - accuracy: 0.7157 - val_loss: 1.3499 - val_accuracy: 0.4767\n",
      "Epoch 2663/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8392 - accuracy: 0.7129 - val_loss: 1.3493 - val_accuracy: 0.4767\n",
      "Epoch 2664/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8392 - accuracy: 0.7129 - val_loss: 1.3511 - val_accuracy: 0.4800\n",
      "Epoch 2665/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8391 - accuracy: 0.7114 - val_loss: 1.3501 - val_accuracy: 0.4767\n",
      "Epoch 2666/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8390 - accuracy: 0.7071 - val_loss: 1.3493 - val_accuracy: 0.4767\n",
      "Epoch 2667/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8391 - accuracy: 0.7186 - val_loss: 1.3501 - val_accuracy: 0.4767\n",
      "Epoch 2668/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8389 - accuracy: 0.7129 - val_loss: 1.3498 - val_accuracy: 0.4767\n",
      "Epoch 2669/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.8387 - accuracy: 0.7157 - val_loss: 1.3505 - val_accuracy: 0.4767\n",
      "Epoch 2670/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8386 - accuracy: 0.7100 - val_loss: 1.3517 - val_accuracy: 0.4767\n",
      "Epoch 2671/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8386 - accuracy: 0.7129 - val_loss: 1.3513 - val_accuracy: 0.4767\n",
      "Epoch 2672/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8383 - accuracy: 0.7114 - val_loss: 1.3505 - val_accuracy: 0.4767\n",
      "Epoch 2673/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8383 - accuracy: 0.7086 - val_loss: 1.3513 - val_accuracy: 0.4767\n",
      "Epoch 2674/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.8383 - accuracy: 0.7143 - val_loss: 1.3521 - val_accuracy: 0.4800\n",
      "Epoch 2675/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8382 - accuracy: 0.7114 - val_loss: 1.3530 - val_accuracy: 0.4767\n",
      "Epoch 2676/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8382 - accuracy: 0.7100 - val_loss: 1.3528 - val_accuracy: 0.4733\n",
      "Epoch 2677/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8381 - accuracy: 0.7129 - val_loss: 1.3522 - val_accuracy: 0.4767\n",
      "Epoch 2678/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8380 - accuracy: 0.7129 - val_loss: 1.3519 - val_accuracy: 0.4767\n",
      "Epoch 2679/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8378 - accuracy: 0.7143 - val_loss: 1.3524 - val_accuracy: 0.4800\n",
      "Epoch 2680/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8376 - accuracy: 0.7157 - val_loss: 1.3522 - val_accuracy: 0.4733\n",
      "Epoch 2681/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8376 - accuracy: 0.7129 - val_loss: 1.3511 - val_accuracy: 0.4767\n",
      "Epoch 2682/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8376 - accuracy: 0.7143 - val_loss: 1.3510 - val_accuracy: 0.4767\n",
      "Epoch 2683/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8376 - accuracy: 0.7129 - val_loss: 1.3527 - val_accuracy: 0.4733\n",
      "Epoch 2684/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8374 - accuracy: 0.7114 - val_loss: 1.3513 - val_accuracy: 0.4767\n",
      "Epoch 2685/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8374 - accuracy: 0.7129 - val_loss: 1.3520 - val_accuracy: 0.4767\n",
      "Epoch 2686/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8374 - accuracy: 0.7129 - val_loss: 1.3517 - val_accuracy: 0.4767\n",
      "Epoch 2687/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8373 - accuracy: 0.7157 - val_loss: 1.3523 - val_accuracy: 0.4733\n",
      "Epoch 2688/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8371 - accuracy: 0.7114 - val_loss: 1.3535 - val_accuracy: 0.4733\n",
      "Epoch 2689/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8371 - accuracy: 0.7143 - val_loss: 1.3534 - val_accuracy: 0.4733\n",
      "Epoch 2690/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8369 - accuracy: 0.7129 - val_loss: 1.3528 - val_accuracy: 0.4767\n",
      "Epoch 2691/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8370 - accuracy: 0.7143 - val_loss: 1.3528 - val_accuracy: 0.4733\n",
      "Epoch 2692/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.8368 - accuracy: 0.7129 - val_loss: 1.3526 - val_accuracy: 0.4733\n",
      "Epoch 2693/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8368 - accuracy: 0.7157 - val_loss: 1.3542 - val_accuracy: 0.4733\n",
      "Epoch 2694/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8365 - accuracy: 0.7100 - val_loss: 1.3535 - val_accuracy: 0.4733\n",
      "Epoch 2695/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8365 - accuracy: 0.7171 - val_loss: 1.3520 - val_accuracy: 0.4767\n",
      "Epoch 2696/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8363 - accuracy: 0.7114 - val_loss: 1.3527 - val_accuracy: 0.4767\n",
      "Epoch 2697/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8364 - accuracy: 0.7129 - val_loss: 1.3533 - val_accuracy: 0.4733\n",
      "Epoch 2698/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8362 - accuracy: 0.7129 - val_loss: 1.3541 - val_accuracy: 0.4733\n",
      "Epoch 2699/3000\n",
      "700/700 [==============================] - 0s 89us/sample - loss: 0.8360 - accuracy: 0.7114 - val_loss: 1.3533 - val_accuracy: 0.4733\n",
      "Epoch 2700/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8360 - accuracy: 0.7129 - val_loss: 1.3529 - val_accuracy: 0.4767\n",
      "Epoch 2701/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8360 - accuracy: 0.7157 - val_loss: 1.3534 - val_accuracy: 0.4733\n",
      "Epoch 2702/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8359 - accuracy: 0.7114 - val_loss: 1.3532 - val_accuracy: 0.4767\n",
      "Epoch 2703/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8359 - accuracy: 0.7157 - val_loss: 1.3537 - val_accuracy: 0.4767\n",
      "Epoch 2704/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8356 - accuracy: 0.7171 - val_loss: 1.3530 - val_accuracy: 0.4767\n",
      "Epoch 2705/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8358 - accuracy: 0.7129 - val_loss: 1.3543 - val_accuracy: 0.4733\n",
      "Epoch 2706/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8355 - accuracy: 0.7143 - val_loss: 1.3545 - val_accuracy: 0.4733\n",
      "Epoch 2707/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8354 - accuracy: 0.7143 - val_loss: 1.3553 - val_accuracy: 0.4733\n",
      "Epoch 2708/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8354 - accuracy: 0.7171 - val_loss: 1.3551 - val_accuracy: 0.4733\n",
      "Epoch 2709/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8353 - accuracy: 0.7114 - val_loss: 1.3554 - val_accuracy: 0.4733\n",
      "Epoch 2710/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 0.8352 - accuracy: 0.7143 - val_loss: 1.3547 - val_accuracy: 0.4733\n",
      "Epoch 2711/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8352 - accuracy: 0.7129 - val_loss: 1.3548 - val_accuracy: 0.4733\n",
      "Epoch 2712/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8350 - accuracy: 0.7143 - val_loss: 1.3542 - val_accuracy: 0.4733\n",
      "Epoch 2713/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8350 - accuracy: 0.7114 - val_loss: 1.3550 - val_accuracy: 0.4733\n",
      "Epoch 2714/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8348 - accuracy: 0.7143 - val_loss: 1.3547 - val_accuracy: 0.4733\n",
      "Epoch 2715/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8348 - accuracy: 0.7114 - val_loss: 1.3555 - val_accuracy: 0.4733\n",
      "Epoch 2716/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8348 - accuracy: 0.7143 - val_loss: 1.3553 - val_accuracy: 0.4733\n",
      "Epoch 2717/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8346 - accuracy: 0.7157 - val_loss: 1.3550 - val_accuracy: 0.4733\n",
      "Epoch 2718/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8345 - accuracy: 0.7143 - val_loss: 1.3559 - val_accuracy: 0.4733\n",
      "Epoch 2719/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8344 - accuracy: 0.7157 - val_loss: 1.3560 - val_accuracy: 0.4733\n",
      "Epoch 2720/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8344 - accuracy: 0.7200 - val_loss: 1.3559 - val_accuracy: 0.4733\n",
      "Epoch 2721/3000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 0.8340 - accuracy: 0.7129 - val_loss: 1.3572 - val_accuracy: 0.4700\n",
      "Epoch 2722/3000\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 0.8341 - accuracy: 0.7157 - val_loss: 1.3561 - val_accuracy: 0.4733\n",
      "Epoch 2723/3000\n",
      "700/700 [==============================] - 0s 90us/sample - loss: 0.8341 - accuracy: 0.7143 - val_loss: 1.3566 - val_accuracy: 0.4733\n",
      "Epoch 2724/3000\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 0.8341 - accuracy: 0.7129 - val_loss: 1.3559 - val_accuracy: 0.4733\n",
      "Epoch 2725/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8339 - accuracy: 0.7186 - val_loss: 1.3573 - val_accuracy: 0.4733\n",
      "Epoch 2726/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8338 - accuracy: 0.7157 - val_loss: 1.3568 - val_accuracy: 0.4733\n",
      "Epoch 2727/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8337 - accuracy: 0.7171 - val_loss: 1.3561 - val_accuracy: 0.4733\n",
      "Epoch 2728/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8334 - accuracy: 0.7171 - val_loss: 1.3553 - val_accuracy: 0.4733\n",
      "Epoch 2729/3000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 0.8335 - accuracy: 0.7129 - val_loss: 1.3575 - val_accuracy: 0.4733\n",
      "Epoch 2730/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8334 - accuracy: 0.7157 - val_loss: 1.3558 - val_accuracy: 0.4733\n",
      "Epoch 2731/3000\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 0.8335 - accuracy: 0.7157 - val_loss: 1.3567 - val_accuracy: 0.4733\n",
      "Epoch 2732/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8334 - accuracy: 0.7171 - val_loss: 1.3565 - val_accuracy: 0.4733\n",
      "Epoch 2733/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8332 - accuracy: 0.7157 - val_loss: 1.3567 - val_accuracy: 0.4800\n",
      "Epoch 2734/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8333 - accuracy: 0.7171 - val_loss: 1.3564 - val_accuracy: 0.4767\n",
      "Epoch 2735/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8333 - accuracy: 0.7157 - val_loss: 1.3571 - val_accuracy: 0.4733\n",
      "Epoch 2736/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8330 - accuracy: 0.7171 - val_loss: 1.3575 - val_accuracy: 0.4733\n",
      "Epoch 2737/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8329 - accuracy: 0.7186 - val_loss: 1.3588 - val_accuracy: 0.4700\n",
      "Epoch 2738/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8328 - accuracy: 0.7157 - val_loss: 1.3573 - val_accuracy: 0.4767\n",
      "Epoch 2739/3000\n",
      "700/700 [==============================] - 0s 112us/sample - loss: 0.8327 - accuracy: 0.7171 - val_loss: 1.3571 - val_accuracy: 0.4767\n",
      "Epoch 2740/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8326 - accuracy: 0.7171 - val_loss: 1.3564 - val_accuracy: 0.4767\n",
      "Epoch 2741/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8328 - accuracy: 0.7171 - val_loss: 1.3575 - val_accuracy: 0.4733\n",
      "Epoch 2742/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8325 - accuracy: 0.7157 - val_loss: 1.3572 - val_accuracy: 0.4733\n",
      "Epoch 2743/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8323 - accuracy: 0.7171 - val_loss: 1.3592 - val_accuracy: 0.4700\n",
      "Epoch 2744/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8325 - accuracy: 0.7157 - val_loss: 1.3587 - val_accuracy: 0.4733\n",
      "Epoch 2745/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8323 - accuracy: 0.7114 - val_loss: 1.3579 - val_accuracy: 0.4733\n",
      "Epoch 2746/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8321 - accuracy: 0.7157 - val_loss: 1.3582 - val_accuracy: 0.4733\n",
      "Epoch 2747/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8321 - accuracy: 0.7186 - val_loss: 1.3584 - val_accuracy: 0.4733\n",
      "Epoch 2748/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8320 - accuracy: 0.7129 - val_loss: 1.3590 - val_accuracy: 0.4733\n",
      "Epoch 2749/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8320 - accuracy: 0.7143 - val_loss: 1.3588 - val_accuracy: 0.4733\n",
      "Epoch 2750/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8318 - accuracy: 0.7143 - val_loss: 1.3587 - val_accuracy: 0.4733\n",
      "Epoch 2751/3000\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 0.8318 - accuracy: 0.7157 - val_loss: 1.3594 - val_accuracy: 0.4733\n",
      "Epoch 2752/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8315 - accuracy: 0.7157 - val_loss: 1.3579 - val_accuracy: 0.4733\n",
      "Epoch 2753/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8316 - accuracy: 0.7129 - val_loss: 1.3583 - val_accuracy: 0.4800\n",
      "Epoch 2754/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8316 - accuracy: 0.7143 - val_loss: 1.3604 - val_accuracy: 0.4700\n",
      "Epoch 2755/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8313 - accuracy: 0.7129 - val_loss: 1.3593 - val_accuracy: 0.4700\n",
      "Epoch 2756/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8314 - accuracy: 0.7143 - val_loss: 1.3593 - val_accuracy: 0.4700\n",
      "Epoch 2757/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8312 - accuracy: 0.7143 - val_loss: 1.3597 - val_accuracy: 0.4700\n",
      "Epoch 2758/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8311 - accuracy: 0.7200 - val_loss: 1.3592 - val_accuracy: 0.4733\n",
      "Epoch 2759/3000\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 0.8308 - accuracy: 0.7200 - val_loss: 1.3580 - val_accuracy: 0.4767\n",
      "Epoch 2760/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8311 - accuracy: 0.7129 - val_loss: 1.3585 - val_accuracy: 0.4767\n",
      "Epoch 2761/3000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 0.8309 - accuracy: 0.7143 - val_loss: 1.3601 - val_accuracy: 0.4700\n",
      "Epoch 2762/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8308 - accuracy: 0.7114 - val_loss: 1.3597 - val_accuracy: 0.4733\n",
      "Epoch 2763/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8307 - accuracy: 0.7129 - val_loss: 1.3598 - val_accuracy: 0.4767\n",
      "Epoch 2764/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8307 - accuracy: 0.7143 - val_loss: 1.3601 - val_accuracy: 0.4733\n",
      "Epoch 2765/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 0.8306 - accuracy: 0.7143 - val_loss: 1.3603 - val_accuracy: 0.4700\n",
      "Epoch 2766/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8304 - accuracy: 0.7171 - val_loss: 1.3600 - val_accuracy: 0.4733\n",
      "Epoch 2767/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 0.8302 - accuracy: 0.7157 - val_loss: 1.3613 - val_accuracy: 0.4700\n",
      "Epoch 2768/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8303 - accuracy: 0.7157 - val_loss: 1.3606 - val_accuracy: 0.4700\n",
      "Epoch 2769/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8303 - accuracy: 0.7200 - val_loss: 1.3608 - val_accuracy: 0.4700\n",
      "Epoch 2770/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8303 - accuracy: 0.7171 - val_loss: 1.3603 - val_accuracy: 0.4733\n",
      "Epoch 2771/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8302 - accuracy: 0.7157 - val_loss: 1.3611 - val_accuracy: 0.4700\n",
      "Epoch 2772/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8300 - accuracy: 0.7143 - val_loss: 1.3617 - val_accuracy: 0.4700\n",
      "Epoch 2773/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8298 - accuracy: 0.7157 - val_loss: 1.3622 - val_accuracy: 0.4700\n",
      "Epoch 2774/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 0.8299 - accuracy: 0.7143 - val_loss: 1.3612 - val_accuracy: 0.4733\n",
      "Epoch 2775/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8298 - accuracy: 0.7129 - val_loss: 1.3612 - val_accuracy: 0.4733\n",
      "Epoch 2776/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8298 - accuracy: 0.7171 - val_loss: 1.3620 - val_accuracy: 0.4700\n",
      "Epoch 2777/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8295 - accuracy: 0.7214 - val_loss: 1.3606 - val_accuracy: 0.4733\n",
      "Epoch 2778/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8294 - accuracy: 0.7157 - val_loss: 1.3622 - val_accuracy: 0.4700\n",
      "Epoch 2779/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8293 - accuracy: 0.7143 - val_loss: 1.3617 - val_accuracy: 0.4700\n",
      "Epoch 2780/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8293 - accuracy: 0.7143 - val_loss: 1.3618 - val_accuracy: 0.4700\n",
      "Epoch 2781/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8292 - accuracy: 0.7129 - val_loss: 1.3629 - val_accuracy: 0.4700\n",
      "Epoch 2782/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8292 - accuracy: 0.7171 - val_loss: 1.3622 - val_accuracy: 0.4700\n",
      "Epoch 2783/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8292 - accuracy: 0.7186 - val_loss: 1.3625 - val_accuracy: 0.4700\n",
      "Epoch 2784/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8288 - accuracy: 0.7186 - val_loss: 1.3612 - val_accuracy: 0.4767\n",
      "Epoch 2785/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8290 - accuracy: 0.7157 - val_loss: 1.3618 - val_accuracy: 0.4733\n",
      "Epoch 2786/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8287 - accuracy: 0.7186 - val_loss: 1.3621 - val_accuracy: 0.4700\n",
      "Epoch 2787/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8289 - accuracy: 0.7143 - val_loss: 1.3627 - val_accuracy: 0.4700\n",
      "Epoch 2788/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8286 - accuracy: 0.7157 - val_loss: 1.3627 - val_accuracy: 0.4700\n",
      "Epoch 2789/3000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 0.8285 - accuracy: 0.7143 - val_loss: 1.3628 - val_accuracy: 0.4700\n",
      "Epoch 2790/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8284 - accuracy: 0.7157 - val_loss: 1.3640 - val_accuracy: 0.4700\n",
      "Epoch 2791/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8286 - accuracy: 0.7143 - val_loss: 1.3627 - val_accuracy: 0.4733\n",
      "Epoch 2792/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8283 - accuracy: 0.7157 - val_loss: 1.3630 - val_accuracy: 0.4733\n",
      "Epoch 2793/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8283 - accuracy: 0.7171 - val_loss: 1.3628 - val_accuracy: 0.4733\n",
      "Epoch 2794/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8281 - accuracy: 0.7171 - val_loss: 1.3619 - val_accuracy: 0.4767\n",
      "Epoch 2795/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8282 - accuracy: 0.7157 - val_loss: 1.3632 - val_accuracy: 0.4700\n",
      "Epoch 2796/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8279 - accuracy: 0.7157 - val_loss: 1.3629 - val_accuracy: 0.4733\n",
      "Epoch 2797/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8278 - accuracy: 0.7229 - val_loss: 1.3630 - val_accuracy: 0.4733\n",
      "Epoch 2798/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8278 - accuracy: 0.7100 - val_loss: 1.3637 - val_accuracy: 0.4733\n",
      "Epoch 2799/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8277 - accuracy: 0.7129 - val_loss: 1.3643 - val_accuracy: 0.4700\n",
      "Epoch 2800/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.8276 - accuracy: 0.7157 - val_loss: 1.3640 - val_accuracy: 0.4733\n",
      "Epoch 2801/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8275 - accuracy: 0.7157 - val_loss: 1.3628 - val_accuracy: 0.4733\n",
      "Epoch 2802/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8275 - accuracy: 0.7171 - val_loss: 1.3636 - val_accuracy: 0.4733\n",
      "Epoch 2803/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8272 - accuracy: 0.7143 - val_loss: 1.3648 - val_accuracy: 0.4700\n",
      "Epoch 2804/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8273 - accuracy: 0.7214 - val_loss: 1.3644 - val_accuracy: 0.4700\n",
      "Epoch 2805/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8271 - accuracy: 0.7186 - val_loss: 1.3635 - val_accuracy: 0.4733\n",
      "Epoch 2806/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8269 - accuracy: 0.7157 - val_loss: 1.3658 - val_accuracy: 0.4667\n",
      "Epoch 2807/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8274 - accuracy: 0.7129 - val_loss: 1.3646 - val_accuracy: 0.4733\n",
      "Epoch 2808/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8270 - accuracy: 0.7143 - val_loss: 1.3646 - val_accuracy: 0.4733\n",
      "Epoch 2809/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8268 - accuracy: 0.7200 - val_loss: 1.3637 - val_accuracy: 0.4733\n",
      "Epoch 2810/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8268 - accuracy: 0.7129 - val_loss: 1.3651 - val_accuracy: 0.4700\n",
      "Epoch 2811/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8269 - accuracy: 0.7129 - val_loss: 1.3643 - val_accuracy: 0.4733\n",
      "Epoch 2812/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8267 - accuracy: 0.7171 - val_loss: 1.3648 - val_accuracy: 0.4733\n",
      "Epoch 2813/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8265 - accuracy: 0.7143 - val_loss: 1.3663 - val_accuracy: 0.4700\n",
      "Epoch 2814/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8266 - accuracy: 0.7114 - val_loss: 1.3651 - val_accuracy: 0.4733\n",
      "Epoch 2815/3000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 0.8264 - accuracy: 0.7200 - val_loss: 1.3664 - val_accuracy: 0.4667\n",
      "Epoch 2816/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8264 - accuracy: 0.7171 - val_loss: 1.3660 - val_accuracy: 0.4733\n",
      "Epoch 2817/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 0.8263 - accuracy: 0.7143 - val_loss: 1.3657 - val_accuracy: 0.4700\n",
      "Epoch 2818/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.8263 - accuracy: 0.7143 - val_loss: 1.3654 - val_accuracy: 0.4733\n",
      "Epoch 2819/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8260 - accuracy: 0.7200 - val_loss: 1.3656 - val_accuracy: 0.4733\n",
      "Epoch 2820/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8260 - accuracy: 0.7171 - val_loss: 1.3655 - val_accuracy: 0.4733\n",
      "Epoch 2821/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8259 - accuracy: 0.7157 - val_loss: 1.3664 - val_accuracy: 0.4667\n",
      "Epoch 2822/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8259 - accuracy: 0.7157 - val_loss: 1.3666 - val_accuracy: 0.4700\n",
      "Epoch 2823/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8259 - accuracy: 0.7171 - val_loss: 1.3652 - val_accuracy: 0.4733\n",
      "Epoch 2824/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8256 - accuracy: 0.7200 - val_loss: 1.3660 - val_accuracy: 0.4733\n",
      "Epoch 2825/3000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 0.8257 - accuracy: 0.7129 - val_loss: 1.3660 - val_accuracy: 0.4733\n",
      "Epoch 2826/3000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 0.8254 - accuracy: 0.7157 - val_loss: 1.3655 - val_accuracy: 0.4733\n",
      "Epoch 2827/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8255 - accuracy: 0.7143 - val_loss: 1.3659 - val_accuracy: 0.4733\n",
      "Epoch 2828/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8254 - accuracy: 0.7171 - val_loss: 1.3669 - val_accuracy: 0.4733\n",
      "Epoch 2829/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8252 - accuracy: 0.7157 - val_loss: 1.3665 - val_accuracy: 0.4733\n",
      "Epoch 2830/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8250 - accuracy: 0.7186 - val_loss: 1.3656 - val_accuracy: 0.4733\n",
      "Epoch 2831/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8250 - accuracy: 0.7157 - val_loss: 1.3669 - val_accuracy: 0.4733\n",
      "Epoch 2832/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8250 - accuracy: 0.7157 - val_loss: 1.3671 - val_accuracy: 0.4733\n",
      "Epoch 2833/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8250 - accuracy: 0.7171 - val_loss: 1.3670 - val_accuracy: 0.4733\n",
      "Epoch 2834/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8247 - accuracy: 0.7171 - val_loss: 1.3653 - val_accuracy: 0.4733\n",
      "Epoch 2835/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8246 - accuracy: 0.7143 - val_loss: 1.3671 - val_accuracy: 0.4733\n",
      "Epoch 2836/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8248 - accuracy: 0.7129 - val_loss: 1.3675 - val_accuracy: 0.4733\n",
      "Epoch 2837/3000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 0.8245 - accuracy: 0.7186 - val_loss: 1.3668 - val_accuracy: 0.4733\n",
      "Epoch 2838/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8245 - accuracy: 0.7171 - val_loss: 1.3668 - val_accuracy: 0.4733\n",
      "Epoch 2839/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8245 - accuracy: 0.7186 - val_loss: 1.3681 - val_accuracy: 0.4700\n",
      "Epoch 2840/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8243 - accuracy: 0.7157 - val_loss: 1.3677 - val_accuracy: 0.4733\n",
      "Epoch 2841/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8242 - accuracy: 0.7143 - val_loss: 1.3691 - val_accuracy: 0.4733\n",
      "Epoch 2842/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8242 - accuracy: 0.7186 - val_loss: 1.3675 - val_accuracy: 0.4733\n",
      "Epoch 2843/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8242 - accuracy: 0.7114 - val_loss: 1.3694 - val_accuracy: 0.4700\n",
      "Epoch 2844/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8240 - accuracy: 0.7143 - val_loss: 1.3692 - val_accuracy: 0.4733\n",
      "Epoch 2845/3000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 0.8239 - accuracy: 0.7186 - val_loss: 1.3682 - val_accuracy: 0.4733\n",
      "Epoch 2846/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8238 - accuracy: 0.7171 - val_loss: 1.3675 - val_accuracy: 0.4767\n",
      "Epoch 2847/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.8236 - accuracy: 0.7186 - val_loss: 1.3695 - val_accuracy: 0.4700\n",
      "Epoch 2848/3000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 0.8236 - accuracy: 0.7171 - val_loss: 1.3677 - val_accuracy: 0.4733\n",
      "Epoch 2849/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8236 - accuracy: 0.7157 - val_loss: 1.3682 - val_accuracy: 0.4733\n",
      "Epoch 2850/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8234 - accuracy: 0.7186 - val_loss: 1.3686 - val_accuracy: 0.4733\n",
      "Epoch 2851/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8235 - accuracy: 0.7157 - val_loss: 1.3693 - val_accuracy: 0.4700\n",
      "Epoch 2852/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8234 - accuracy: 0.7143 - val_loss: 1.3684 - val_accuracy: 0.4733\n",
      "Epoch 2853/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8232 - accuracy: 0.7157 - val_loss: 1.3705 - val_accuracy: 0.4667\n",
      "Epoch 2854/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8232 - accuracy: 0.7214 - val_loss: 1.3689 - val_accuracy: 0.4733\n",
      "Epoch 2855/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8231 - accuracy: 0.7214 - val_loss: 1.3690 - val_accuracy: 0.4733\n",
      "Epoch 2856/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8230 - accuracy: 0.7157 - val_loss: 1.3703 - val_accuracy: 0.4700\n",
      "Epoch 2857/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8228 - accuracy: 0.7186 - val_loss: 1.3684 - val_accuracy: 0.4733\n",
      "Epoch 2858/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8229 - accuracy: 0.7143 - val_loss: 1.3700 - val_accuracy: 0.4700\n",
      "Epoch 2859/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8229 - accuracy: 0.7143 - val_loss: 1.3696 - val_accuracy: 0.4700\n",
      "Epoch 2860/3000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.8229 - accuracy: 0.7171 - val_loss: 1.3700 - val_accuracy: 0.4700\n",
      "Epoch 2861/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8226 - accuracy: 0.7129 - val_loss: 1.3700 - val_accuracy: 0.4700\n",
      "Epoch 2862/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8228 - accuracy: 0.7171 - val_loss: 1.3698 - val_accuracy: 0.4700\n",
      "Epoch 2863/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8226 - accuracy: 0.7171 - val_loss: 1.3700 - val_accuracy: 0.4700\n",
      "Epoch 2864/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8225 - accuracy: 0.7200 - val_loss: 1.3691 - val_accuracy: 0.4733\n",
      "Epoch 2865/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8224 - accuracy: 0.7129 - val_loss: 1.3708 - val_accuracy: 0.4667\n",
      "Epoch 2866/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8222 - accuracy: 0.7186 - val_loss: 1.3717 - val_accuracy: 0.4667\n",
      "Epoch 2867/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8224 - accuracy: 0.7171 - val_loss: 1.3705 - val_accuracy: 0.4700\n",
      "Epoch 2868/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8221 - accuracy: 0.7157 - val_loss: 1.3701 - val_accuracy: 0.4733\n",
      "Epoch 2869/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8220 - accuracy: 0.7171 - val_loss: 1.3702 - val_accuracy: 0.4700\n",
      "Epoch 2870/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8218 - accuracy: 0.7171 - val_loss: 1.3703 - val_accuracy: 0.4700\n",
      "Epoch 2871/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8218 - accuracy: 0.7129 - val_loss: 1.3709 - val_accuracy: 0.4700\n",
      "Epoch 2872/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8218 - accuracy: 0.7171 - val_loss: 1.3708 - val_accuracy: 0.4733\n",
      "Epoch 2873/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8217 - accuracy: 0.7171 - val_loss: 1.3715 - val_accuracy: 0.4700\n",
      "Epoch 2874/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8215 - accuracy: 0.7171 - val_loss: 1.3706 - val_accuracy: 0.4733\n",
      "Epoch 2875/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8211 - accuracy: 0.7157 - val_loss: 1.3690 - val_accuracy: 0.4767\n",
      "Epoch 2876/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8216 - accuracy: 0.7171 - val_loss: 1.3700 - val_accuracy: 0.4767\n",
      "Epoch 2877/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8214 - accuracy: 0.7214 - val_loss: 1.3711 - val_accuracy: 0.4700\n",
      "Epoch 2878/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8212 - accuracy: 0.7186 - val_loss: 1.3715 - val_accuracy: 0.4700\n",
      "Epoch 2879/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8213 - accuracy: 0.7186 - val_loss: 1.3718 - val_accuracy: 0.4700\n",
      "Epoch 2880/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8211 - accuracy: 0.7157 - val_loss: 1.3717 - val_accuracy: 0.4700\n",
      "Epoch 2881/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8210 - accuracy: 0.7157 - val_loss: 1.3725 - val_accuracy: 0.4700\n",
      "Epoch 2882/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8210 - accuracy: 0.7143 - val_loss: 1.3719 - val_accuracy: 0.4700\n",
      "Epoch 2883/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8208 - accuracy: 0.7214 - val_loss: 1.3729 - val_accuracy: 0.4700\n",
      "Epoch 2884/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8209 - accuracy: 0.7186 - val_loss: 1.3726 - val_accuracy: 0.4700\n",
      "Epoch 2885/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8207 - accuracy: 0.7243 - val_loss: 1.3716 - val_accuracy: 0.4700\n",
      "Epoch 2886/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8207 - accuracy: 0.7129 - val_loss: 1.3722 - val_accuracy: 0.4700\n",
      "Epoch 2887/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8205 - accuracy: 0.7171 - val_loss: 1.3732 - val_accuracy: 0.4700\n",
      "Epoch 2888/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8204 - accuracy: 0.7186 - val_loss: 1.3716 - val_accuracy: 0.4733\n",
      "Epoch 2889/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8205 - accuracy: 0.7214 - val_loss: 1.3720 - val_accuracy: 0.4733\n",
      "Epoch 2890/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8203 - accuracy: 0.7143 - val_loss: 1.3728 - val_accuracy: 0.4700\n",
      "Epoch 2891/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8203 - accuracy: 0.7186 - val_loss: 1.3740 - val_accuracy: 0.4667\n",
      "Epoch 2892/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8200 - accuracy: 0.7129 - val_loss: 1.3720 - val_accuracy: 0.4733\n",
      "Epoch 2893/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8201 - accuracy: 0.7171 - val_loss: 1.3728 - val_accuracy: 0.4667\n",
      "Epoch 2894/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8199 - accuracy: 0.7243 - val_loss: 1.3717 - val_accuracy: 0.4767\n",
      "Epoch 2895/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8201 - accuracy: 0.7143 - val_loss: 1.3726 - val_accuracy: 0.4700\n",
      "Epoch 2896/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8201 - accuracy: 0.7171 - val_loss: 1.3733 - val_accuracy: 0.4667\n",
      "Epoch 2897/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8199 - accuracy: 0.7157 - val_loss: 1.3740 - val_accuracy: 0.4667\n",
      "Epoch 2898/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8197 - accuracy: 0.7200 - val_loss: 1.3731 - val_accuracy: 0.4667\n",
      "Epoch 2899/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8196 - accuracy: 0.7143 - val_loss: 1.3733 - val_accuracy: 0.4667\n",
      "Epoch 2900/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8194 - accuracy: 0.7229 - val_loss: 1.3728 - val_accuracy: 0.4667\n",
      "Epoch 2901/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8195 - accuracy: 0.7143 - val_loss: 1.3738 - val_accuracy: 0.4667\n",
      "Epoch 2902/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8192 - accuracy: 0.7186 - val_loss: 1.3739 - val_accuracy: 0.4667\n",
      "Epoch 2903/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8194 - accuracy: 0.7214 - val_loss: 1.3742 - val_accuracy: 0.4667\n",
      "Epoch 2904/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8191 - accuracy: 0.7171 - val_loss: 1.3737 - val_accuracy: 0.4733\n",
      "Epoch 2905/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8191 - accuracy: 0.7157 - val_loss: 1.3744 - val_accuracy: 0.4700\n",
      "Epoch 2906/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8191 - accuracy: 0.7171 - val_loss: 1.3741 - val_accuracy: 0.4733\n",
      "Epoch 2907/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8190 - accuracy: 0.7171 - val_loss: 1.3750 - val_accuracy: 0.4700\n",
      "Epoch 2908/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8190 - accuracy: 0.7186 - val_loss: 1.3740 - val_accuracy: 0.4700\n",
      "Epoch 2909/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8188 - accuracy: 0.7186 - val_loss: 1.3745 - val_accuracy: 0.4700\n",
      "Epoch 2910/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8188 - accuracy: 0.7186 - val_loss: 1.3756 - val_accuracy: 0.4700\n",
      "Epoch 2911/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8188 - accuracy: 0.7200 - val_loss: 1.3752 - val_accuracy: 0.4700\n",
      "Epoch 2912/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8183 - accuracy: 0.7186 - val_loss: 1.3775 - val_accuracy: 0.4700\n",
      "Epoch 2913/3000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 0.8184 - accuracy: 0.7214 - val_loss: 1.3750 - val_accuracy: 0.4700\n",
      "Epoch 2914/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8183 - accuracy: 0.7200 - val_loss: 1.3740 - val_accuracy: 0.4767\n",
      "Epoch 2915/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8185 - accuracy: 0.7171 - val_loss: 1.3749 - val_accuracy: 0.4700\n",
      "Epoch 2916/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8183 - accuracy: 0.7186 - val_loss: 1.3763 - val_accuracy: 0.4667\n",
      "Epoch 2917/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8182 - accuracy: 0.7171 - val_loss: 1.3763 - val_accuracy: 0.4667\n",
      "Epoch 2918/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8182 - accuracy: 0.7214 - val_loss: 1.3756 - val_accuracy: 0.4700\n",
      "Epoch 2919/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8180 - accuracy: 0.7200 - val_loss: 1.3758 - val_accuracy: 0.4667\n",
      "Epoch 2920/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8179 - accuracy: 0.7229 - val_loss: 1.3761 - val_accuracy: 0.4667\n",
      "Epoch 2921/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8177 - accuracy: 0.7214 - val_loss: 1.3752 - val_accuracy: 0.4667\n",
      "Epoch 2922/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8178 - accuracy: 0.7186 - val_loss: 1.3763 - val_accuracy: 0.4667\n",
      "Epoch 2923/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8175 - accuracy: 0.7214 - val_loss: 1.3754 - val_accuracy: 0.4700\n",
      "Epoch 2924/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8177 - accuracy: 0.7186 - val_loss: 1.3758 - val_accuracy: 0.4700\n",
      "Epoch 2925/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8174 - accuracy: 0.7214 - val_loss: 1.3756 - val_accuracy: 0.4700\n",
      "Epoch 2926/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8175 - accuracy: 0.7143 - val_loss: 1.3762 - val_accuracy: 0.4700\n",
      "Epoch 2927/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8174 - accuracy: 0.7186 - val_loss: 1.3772 - val_accuracy: 0.4733\n",
      "Epoch 2928/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8173 - accuracy: 0.7143 - val_loss: 1.3775 - val_accuracy: 0.4733\n",
      "Epoch 2929/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8172 - accuracy: 0.7214 - val_loss: 1.3754 - val_accuracy: 0.4767\n",
      "Epoch 2930/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8172 - accuracy: 0.7214 - val_loss: 1.3756 - val_accuracy: 0.4700\n",
      "Epoch 2931/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8172 - accuracy: 0.7171 - val_loss: 1.3773 - val_accuracy: 0.4700\n",
      "Epoch 2932/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8169 - accuracy: 0.7171 - val_loss: 1.3760 - val_accuracy: 0.4700\n",
      "Epoch 2933/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8168 - accuracy: 0.7186 - val_loss: 1.3779 - val_accuracy: 0.4733\n",
      "Epoch 2934/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8168 - accuracy: 0.7229 - val_loss: 1.3769 - val_accuracy: 0.4700\n",
      "Epoch 2935/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8168 - accuracy: 0.7229 - val_loss: 1.3777 - val_accuracy: 0.4667\n",
      "Epoch 2936/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8167 - accuracy: 0.7171 - val_loss: 1.3784 - val_accuracy: 0.4700\n",
      "Epoch 2937/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8167 - accuracy: 0.7200 - val_loss: 1.3777 - val_accuracy: 0.4700\n",
      "Epoch 2938/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8165 - accuracy: 0.7200 - val_loss: 1.3781 - val_accuracy: 0.4733\n",
      "Epoch 2939/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8165 - accuracy: 0.7214 - val_loss: 1.3786 - val_accuracy: 0.4700\n",
      "Epoch 2940/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8161 - accuracy: 0.7186 - val_loss: 1.3793 - val_accuracy: 0.4700\n",
      "Epoch 2941/3000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.8165 - accuracy: 0.7186 - val_loss: 1.3775 - val_accuracy: 0.4667\n",
      "Epoch 2942/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8162 - accuracy: 0.7214 - val_loss: 1.3773 - val_accuracy: 0.4667\n",
      "Epoch 2943/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8163 - accuracy: 0.7214 - val_loss: 1.3783 - val_accuracy: 0.4667\n",
      "Epoch 2944/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8159 - accuracy: 0.7214 - val_loss: 1.3781 - val_accuracy: 0.4667\n",
      "Epoch 2945/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 0.8160 - accuracy: 0.7200 - val_loss: 1.3768 - val_accuracy: 0.4767\n",
      "Epoch 2946/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8160 - accuracy: 0.7214 - val_loss: 1.3776 - val_accuracy: 0.4667\n",
      "Epoch 2947/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8158 - accuracy: 0.7200 - val_loss: 1.3787 - val_accuracy: 0.4700\n",
      "Epoch 2948/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8157 - accuracy: 0.7214 - val_loss: 1.3785 - val_accuracy: 0.4700\n",
      "Epoch 2949/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8156 - accuracy: 0.7200 - val_loss: 1.3801 - val_accuracy: 0.4700\n",
      "Epoch 2950/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8156 - accuracy: 0.7214 - val_loss: 1.3796 - val_accuracy: 0.4700\n",
      "Epoch 2951/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8155 - accuracy: 0.7200 - val_loss: 1.3792 - val_accuracy: 0.4733\n",
      "Epoch 2952/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8153 - accuracy: 0.7186 - val_loss: 1.3790 - val_accuracy: 0.4733\n",
      "Epoch 2953/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8153 - accuracy: 0.7214 - val_loss: 1.3789 - val_accuracy: 0.4700\n",
      "Epoch 2954/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8154 - accuracy: 0.7157 - val_loss: 1.3791 - val_accuracy: 0.4700\n",
      "Epoch 2955/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8152 - accuracy: 0.7214 - val_loss: 1.3802 - val_accuracy: 0.4700\n",
      "Epoch 2956/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8151 - accuracy: 0.7200 - val_loss: 1.3801 - val_accuracy: 0.4700\n",
      "Epoch 2957/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8150 - accuracy: 0.7200 - val_loss: 1.3806 - val_accuracy: 0.4733\n",
      "Epoch 2958/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 0.8150 - accuracy: 0.7229 - val_loss: 1.3792 - val_accuracy: 0.4767\n",
      "Epoch 2959/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8149 - accuracy: 0.7229 - val_loss: 1.3797 - val_accuracy: 0.4667\n",
      "Epoch 2960/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8149 - accuracy: 0.7243 - val_loss: 1.3793 - val_accuracy: 0.4700\n",
      "Epoch 2961/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8147 - accuracy: 0.7200 - val_loss: 1.3804 - val_accuracy: 0.4700\n",
      "Epoch 2962/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8147 - accuracy: 0.7200 - val_loss: 1.3802 - val_accuracy: 0.4700\n",
      "Epoch 2963/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8145 - accuracy: 0.7200 - val_loss: 1.3801 - val_accuracy: 0.4700\n",
      "Epoch 2964/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8146 - accuracy: 0.7171 - val_loss: 1.3800 - val_accuracy: 0.4700\n",
      "Epoch 2965/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8142 - accuracy: 0.7171 - val_loss: 1.3806 - val_accuracy: 0.4700\n",
      "Epoch 2966/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8144 - accuracy: 0.7243 - val_loss: 1.3803 - val_accuracy: 0.4800\n",
      "Epoch 2967/3000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 0.8142 - accuracy: 0.7229 - val_loss: 1.3801 - val_accuracy: 0.4767\n",
      "Epoch 2968/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8141 - accuracy: 0.7200 - val_loss: 1.3811 - val_accuracy: 0.4700\n",
      "Epoch 2969/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8141 - accuracy: 0.7243 - val_loss: 1.3806 - val_accuracy: 0.4733\n",
      "Epoch 2970/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8139 - accuracy: 0.7214 - val_loss: 1.3818 - val_accuracy: 0.4700\n",
      "Epoch 2971/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8141 - accuracy: 0.7186 - val_loss: 1.3816 - val_accuracy: 0.4700\n",
      "Epoch 2972/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8138 - accuracy: 0.7186 - val_loss: 1.3828 - val_accuracy: 0.4700\n",
      "Epoch 2973/3000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 0.8138 - accuracy: 0.7214 - val_loss: 1.3822 - val_accuracy: 0.4700\n",
      "Epoch 2974/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8136 - accuracy: 0.7214 - val_loss: 1.3803 - val_accuracy: 0.4800\n",
      "Epoch 2975/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8137 - accuracy: 0.7200 - val_loss: 1.3805 - val_accuracy: 0.4800\n",
      "Epoch 2976/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8135 - accuracy: 0.7200 - val_loss: 1.3798 - val_accuracy: 0.4800\n",
      "Epoch 2977/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8134 - accuracy: 0.7200 - val_loss: 1.3806 - val_accuracy: 0.4767\n",
      "Epoch 2978/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8133 - accuracy: 0.7157 - val_loss: 1.3809 - val_accuracy: 0.4767\n",
      "Epoch 2979/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8135 - accuracy: 0.7200 - val_loss: 1.3816 - val_accuracy: 0.4767\n",
      "Epoch 2980/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8133 - accuracy: 0.7243 - val_loss: 1.3824 - val_accuracy: 0.4700\n",
      "Epoch 2981/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8131 - accuracy: 0.7214 - val_loss: 1.3838 - val_accuracy: 0.4700\n",
      "Epoch 2982/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8131 - accuracy: 0.7214 - val_loss: 1.3821 - val_accuracy: 0.4700\n",
      "Epoch 2983/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8129 - accuracy: 0.7229 - val_loss: 1.3829 - val_accuracy: 0.4700\n",
      "Epoch 2984/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8128 - accuracy: 0.7229 - val_loss: 1.3818 - val_accuracy: 0.4700\n",
      "Epoch 2985/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8129 - accuracy: 0.7214 - val_loss: 1.3830 - val_accuracy: 0.4700\n",
      "Epoch 2986/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8128 - accuracy: 0.7186 - val_loss: 1.3836 - val_accuracy: 0.4700\n",
      "Epoch 2987/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8128 - accuracy: 0.7229 - val_loss: 1.3827 - val_accuracy: 0.4700\n",
      "Epoch 2988/3000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 0.8126 - accuracy: 0.7257 - val_loss: 1.3825 - val_accuracy: 0.4700\n",
      "Epoch 2989/3000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.8126 - accuracy: 0.7200 - val_loss: 1.3836 - val_accuracy: 0.4700\n",
      "Epoch 2990/3000\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 0.8124 - accuracy: 0.7257 - val_loss: 1.3834 - val_accuracy: 0.4700\n",
      "Epoch 2991/3000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 0.8124 - accuracy: 0.7214 - val_loss: 1.3839 - val_accuracy: 0.4700\n",
      "Epoch 2992/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8123 - accuracy: 0.7214 - val_loss: 1.3834 - val_accuracy: 0.4700\n",
      "Epoch 2993/3000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 0.8122 - accuracy: 0.7186 - val_loss: 1.3840 - val_accuracy: 0.4700\n",
      "Epoch 2994/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8121 - accuracy: 0.7229 - val_loss: 1.3831 - val_accuracy: 0.4767\n",
      "Epoch 2995/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8120 - accuracy: 0.7186 - val_loss: 1.3840 - val_accuracy: 0.4700\n",
      "Epoch 2996/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8121 - accuracy: 0.7200 - val_loss: 1.3842 - val_accuracy: 0.4700\n",
      "Epoch 2997/3000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 0.8120 - accuracy: 0.7214 - val_loss: 1.3848 - val_accuracy: 0.4700\n",
      "Epoch 2998/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8119 - accuracy: 0.7214 - val_loss: 1.3843 - val_accuracy: 0.4700\n",
      "Epoch 2999/3000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 0.8119 - accuracy: 0.7186 - val_loss: 1.3846 - val_accuracy: 0.4700\n",
      "Epoch 3000/3000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 0.8115 - accuracy: 0.7186 - val_loss: 1.3855 - val_accuracy: 0.4767\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(3)\n",
    "\n",
    "# 1. 데이터셋 준비하기\n",
    "\n",
    "# 훈련셋과 시험셋 로딩\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# 훈련셋과 검증셋 분리\n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "\n",
    "X_train = X_train.reshape(50000, 784).astype('float32') / 255.0\n",
    "X_val = X_val.reshape(10000, 784).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "# 훈련셋, 검증셋 고르기\n",
    "train_rand_idxs = np.random.choice(50000, 700)\n",
    "val_rand_idxs = np.random.choice(10000, 300)\n",
    "\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]\n",
    "\n",
    "# 라벨링 전환\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_val = np_utils.to_categorical(Y_val)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# 3. 모델 엮기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "hist = model.fit(X_train, Y_train, epochs=1000, batch_size=10, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1830c39c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 10us/sample - loss: 1.5006 - accuracy: 0.5155\n",
      "\n",
      "loss : 1.5005593351364135\n",
      "accuray : 0.5155\n"
     ]
    }
   ],
   "source": [
    "# 6. 모델 사용하기\n",
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "\n",
    "print('')\n",
    "print('loss : ' + str(loss_and_metrics[0]))\n",
    "print('accuray : ' + str(loss_and_metrics[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 조기종료 시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "700/700 [==============================] - 0s 252us/sample - loss: 2.3156 - accuracy: 0.0614 - val_loss: 2.3044 - val_accuracy: 0.1100\n",
      "Epoch 2/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 2.3091 - accuracy: 0.0771 - val_loss: 2.3019 - val_accuracy: 0.1100\n",
      "Epoch 3/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.3057 - accuracy: 0.1014 - val_loss: 2.3007 - val_accuracy: 0.1033\n",
      "Epoch 4/1000\n",
      "700/700 [==============================] - 0s 90us/sample - loss: 2.3036 - accuracy: 0.1043 - val_loss: 2.3002 - val_accuracy: 0.1033\n",
      "Epoch 5/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 2.3022 - accuracy: 0.1043 - val_loss: 2.2995 - val_accuracy: 0.1067\n",
      "Epoch 6/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.3007 - accuracy: 0.1029 - val_loss: 2.2987 - val_accuracy: 0.1100\n",
      "Epoch 7/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.2989 - accuracy: 0.1129 - val_loss: 2.2973 - val_accuracy: 0.1067\n",
      "Epoch 8/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 2.2967 - accuracy: 0.1014 - val_loss: 2.2952 - val_accuracy: 0.1033\n",
      "Epoch 9/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 2.2947 - accuracy: 0.1000 - val_loss: 2.2927 - val_accuracy: 0.1100\n",
      "Epoch 10/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 2.2926 - accuracy: 0.0943 - val_loss: 2.2898 - val_accuracy: 0.1133\n",
      "Epoch 11/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.2898 - accuracy: 0.0971 - val_loss: 2.2863 - val_accuracy: 0.1100\n",
      "Epoch 12/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 2.2868 - accuracy: 0.1029 - val_loss: 2.2823 - val_accuracy: 0.1067\n",
      "Epoch 13/1000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 2.2836 - accuracy: 0.1014 - val_loss: 2.2779 - val_accuracy: 0.1033\n",
      "Epoch 14/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 2.2802 - accuracy: 0.1000 - val_loss: 2.2730 - val_accuracy: 0.1033\n",
      "Epoch 15/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 2.2767 - accuracy: 0.0986 - val_loss: 2.2687 - val_accuracy: 0.1067\n",
      "Epoch 16/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 2.2736 - accuracy: 0.1014 - val_loss: 2.2648 - val_accuracy: 0.1067\n",
      "Epoch 17/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 2.2708 - accuracy: 0.0986 - val_loss: 2.2612 - val_accuracy: 0.1067\n",
      "Epoch 18/1000\n",
      "700/700 [==============================] - 0s 100us/sample - loss: 2.2681 - accuracy: 0.1014 - val_loss: 2.2578 - val_accuracy: 0.1067\n",
      "Epoch 19/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 2.2655 - accuracy: 0.1000 - val_loss: 2.2546 - val_accuracy: 0.1033\n",
      "Epoch 20/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 2.2629 - accuracy: 0.1014 - val_loss: 2.2515 - val_accuracy: 0.1033\n",
      "Epoch 21/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 2.2606 - accuracy: 0.1000 - val_loss: 2.2485 - val_accuracy: 0.1033\n",
      "Epoch 22/1000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 2.2582 - accuracy: 0.1014 - val_loss: 2.2458 - val_accuracy: 0.1033\n",
      "Epoch 23/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 2.2559 - accuracy: 0.1014 - val_loss: 2.2428 - val_accuracy: 0.1033\n",
      "Epoch 24/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 2.2536 - accuracy: 0.1014 - val_loss: 2.2399 - val_accuracy: 0.1033\n",
      "Epoch 25/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 2.2512 - accuracy: 0.1029 - val_loss: 2.2372 - val_accuracy: 0.1133\n",
      "Epoch 26/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.2489 - accuracy: 0.1029 - val_loss: 2.2343 - val_accuracy: 0.1133\n",
      "Epoch 27/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 2.2466 - accuracy: 0.1000 - val_loss: 2.2313 - val_accuracy: 0.1133\n",
      "Epoch 28/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 2.2442 - accuracy: 0.1157 - val_loss: 2.2281 - val_accuracy: 0.1167\n",
      "Epoch 29/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.2417 - accuracy: 0.1214 - val_loss: 2.2247 - val_accuracy: 0.1167\n",
      "Epoch 30/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.2388 - accuracy: 0.1186 - val_loss: 2.2189 - val_accuracy: 0.1200\n",
      "Epoch 31/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.2348 - accuracy: 0.1171 - val_loss: 2.2116 - val_accuracy: 0.1167\n",
      "Epoch 32/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 2.2287 - accuracy: 0.1186 - val_loss: 2.2005 - val_accuracy: 0.1267\n",
      "Epoch 33/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 2.2202 - accuracy: 0.1214 - val_loss: 2.1882 - val_accuracy: 0.1533\n",
      "Epoch 34/1000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 2.2110 - accuracy: 0.1314 - val_loss: 2.1767 - val_accuracy: 0.1633\n",
      "Epoch 35/1000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 2.2012 - accuracy: 0.1414 - val_loss: 2.1659 - val_accuracy: 0.1633\n",
      "Epoch 36/1000\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 2.1912 - accuracy: 0.1514 - val_loss: 2.1565 - val_accuracy: 0.1733\n",
      "Epoch 37/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 2.1817 - accuracy: 0.1571 - val_loss: 2.1471 - val_accuracy: 0.1833\n",
      "Epoch 38/1000\n",
      "700/700 [==============================] - 0s 105us/sample - loss: 2.1721 - accuracy: 0.1614 - val_loss: 2.1386 - val_accuracy: 0.1833\n",
      "Epoch 39/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 2.1625 - accuracy: 0.1657 - val_loss: 2.1305 - val_accuracy: 0.1867\n",
      "Epoch 40/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.1532 - accuracy: 0.1671 - val_loss: 2.1232 - val_accuracy: 0.1900\n",
      "Epoch 41/1000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 2.1445 - accuracy: 0.1700 - val_loss: 2.1158 - val_accuracy: 0.1833\n",
      "Epoch 42/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 2.1363 - accuracy: 0.1729 - val_loss: 2.1089 - val_accuracy: 0.1833\n",
      "Epoch 43/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 2.1285 - accuracy: 0.1743 - val_loss: 2.1022 - val_accuracy: 0.1900\n",
      "Epoch 44/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 2.1210 - accuracy: 0.1743 - val_loss: 2.0956 - val_accuracy: 0.1900\n",
      "Epoch 45/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 2.1138 - accuracy: 0.1786 - val_loss: 2.0895 - val_accuracy: 0.1933\n",
      "Epoch 46/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 2.1069 - accuracy: 0.1771 - val_loss: 2.0833 - val_accuracy: 0.1967\n",
      "Epoch 47/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 2.1004 - accuracy: 0.1800 - val_loss: 2.0775 - val_accuracy: 0.1967\n",
      "Epoch 48/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.0941 - accuracy: 0.1800 - val_loss: 2.0718 - val_accuracy: 0.2000\n",
      "Epoch 49/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.0881 - accuracy: 0.1786 - val_loss: 2.0663 - val_accuracy: 0.2000\n",
      "Epoch 50/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 2.0820 - accuracy: 0.1800 - val_loss: 2.0614 - val_accuracy: 0.1933\n",
      "Epoch 51/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 2.0762 - accuracy: 0.1757 - val_loss: 2.0562 - val_accuracy: 0.1967\n",
      "Epoch 52/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 2.0704 - accuracy: 0.1757 - val_loss: 2.0509 - val_accuracy: 0.1933\n",
      "Epoch 53/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 2.0652 - accuracy: 0.1786 - val_loss: 2.0462 - val_accuracy: 0.1933\n",
      "Epoch 54/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 2.0599 - accuracy: 0.1786 - val_loss: 2.0415 - val_accuracy: 0.1933\n",
      "Epoch 55/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.0548 - accuracy: 0.1800 - val_loss: 2.0370 - val_accuracy: 0.1967\n",
      "Epoch 56/1000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 2.0496 - accuracy: 0.1829 - val_loss: 2.0324 - val_accuracy: 0.2000\n",
      "Epoch 57/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.0446 - accuracy: 0.1857 - val_loss: 2.0280 - val_accuracy: 0.2033\n",
      "Epoch 58/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 2.0397 - accuracy: 0.1857 - val_loss: 2.0236 - val_accuracy: 0.2100\n",
      "Epoch 59/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.0350 - accuracy: 0.1900 - val_loss: 2.0195 - val_accuracy: 0.2167\n",
      "Epoch 60/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.0303 - accuracy: 0.2014 - val_loss: 2.0150 - val_accuracy: 0.2167\n",
      "Epoch 61/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.0256 - accuracy: 0.2029 - val_loss: 2.0111 - val_accuracy: 0.2233\n",
      "Epoch 62/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.0212 - accuracy: 0.2129 - val_loss: 2.0069 - val_accuracy: 0.2300\n",
      "Epoch 63/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.0166 - accuracy: 0.2200 - val_loss: 2.0026 - val_accuracy: 0.2333\n",
      "Epoch 64/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.0122 - accuracy: 0.2214 - val_loss: 1.9985 - val_accuracy: 0.2433\n",
      "Epoch 65/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 2.0078 - accuracy: 0.2329 - val_loss: 1.9945 - val_accuracy: 0.2467\n",
      "Epoch 66/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 2.0036 - accuracy: 0.2414 - val_loss: 1.9907 - val_accuracy: 0.2433\n",
      "Epoch 67/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.9992 - accuracy: 0.2500 - val_loss: 1.9868 - val_accuracy: 0.2433\n",
      "Epoch 68/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.9951 - accuracy: 0.2543 - val_loss: 1.9828 - val_accuracy: 0.2467\n",
      "Epoch 69/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.9910 - accuracy: 0.2529 - val_loss: 1.9791 - val_accuracy: 0.2567\n",
      "Epoch 70/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.9868 - accuracy: 0.2657 - val_loss: 1.9753 - val_accuracy: 0.2667\n",
      "Epoch 71/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.9828 - accuracy: 0.2743 - val_loss: 1.9714 - val_accuracy: 0.2733\n",
      "Epoch 72/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.9787 - accuracy: 0.2757 - val_loss: 1.9677 - val_accuracy: 0.2733\n",
      "Epoch 73/1000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.9747 - accuracy: 0.2814 - val_loss: 1.9641 - val_accuracy: 0.2700\n",
      "Epoch 74/1000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.9708 - accuracy: 0.2786 - val_loss: 1.9603 - val_accuracy: 0.2733\n",
      "Epoch 75/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.9668 - accuracy: 0.2814 - val_loss: 1.9565 - val_accuracy: 0.2733\n",
      "Epoch 76/1000\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 1.9629 - accuracy: 0.2886 - val_loss: 1.9529 - val_accuracy: 0.2733\n",
      "Epoch 77/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.9591 - accuracy: 0.2886 - val_loss: 1.9496 - val_accuracy: 0.2733\n",
      "Epoch 78/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.9553 - accuracy: 0.2771 - val_loss: 1.9460 - val_accuracy: 0.2700\n",
      "Epoch 79/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.9517 - accuracy: 0.2900 - val_loss: 1.9427 - val_accuracy: 0.2733\n",
      "Epoch 80/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.9479 - accuracy: 0.2857 - val_loss: 1.9392 - val_accuracy: 0.2833\n",
      "Epoch 81/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.9441 - accuracy: 0.2900 - val_loss: 1.9358 - val_accuracy: 0.2833\n",
      "Epoch 82/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.9405 - accuracy: 0.2900 - val_loss: 1.9324 - val_accuracy: 0.2833\n",
      "Epoch 83/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.9370 - accuracy: 0.2914 - val_loss: 1.9292 - val_accuracy: 0.2867\n",
      "Epoch 84/1000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.9333 - accuracy: 0.2900 - val_loss: 1.9257 - val_accuracy: 0.2867\n",
      "Epoch 85/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.9297 - accuracy: 0.2900 - val_loss: 1.9222 - val_accuracy: 0.2867\n",
      "Epoch 86/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.9261 - accuracy: 0.2943 - val_loss: 1.9187 - val_accuracy: 0.2867\n",
      "Epoch 87/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.9227 - accuracy: 0.2929 - val_loss: 1.9156 - val_accuracy: 0.2867\n",
      "Epoch 88/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.9192 - accuracy: 0.2929 - val_loss: 1.9125 - val_accuracy: 0.2867\n",
      "Epoch 89/1000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.9157 - accuracy: 0.3014 - val_loss: 1.9096 - val_accuracy: 0.3067\n",
      "Epoch 90/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.9124 - accuracy: 0.3014 - val_loss: 1.9064 - val_accuracy: 0.3033\n",
      "Epoch 91/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.9090 - accuracy: 0.2971 - val_loss: 1.9034 - val_accuracy: 0.3033\n",
      "Epoch 92/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.9058 - accuracy: 0.3029 - val_loss: 1.9002 - val_accuracy: 0.3167\n",
      "Epoch 93/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.9023 - accuracy: 0.3071 - val_loss: 1.8969 - val_accuracy: 0.3200\n",
      "Epoch 94/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.8992 - accuracy: 0.3071 - val_loss: 1.8942 - val_accuracy: 0.3333\n",
      "Epoch 95/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.8959 - accuracy: 0.3014 - val_loss: 1.8914 - val_accuracy: 0.3367\n",
      "Epoch 96/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.8927 - accuracy: 0.3100 - val_loss: 1.8884 - val_accuracy: 0.3433\n",
      "Epoch 97/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.8894 - accuracy: 0.3157 - val_loss: 1.8857 - val_accuracy: 0.3500\n",
      "Epoch 98/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.8863 - accuracy: 0.3157 - val_loss: 1.8826 - val_accuracy: 0.3500\n",
      "Epoch 99/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.8831 - accuracy: 0.3186 - val_loss: 1.8799 - val_accuracy: 0.3533\n",
      "Epoch 100/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.8799 - accuracy: 0.3129 - val_loss: 1.8769 - val_accuracy: 0.3533\n",
      "Epoch 101/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.8768 - accuracy: 0.3143 - val_loss: 1.8741 - val_accuracy: 0.3533\n",
      "Epoch 102/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.8738 - accuracy: 0.3071 - val_loss: 1.8711 - val_accuracy: 0.3600\n",
      "Epoch 103/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.8707 - accuracy: 0.3086 - val_loss: 1.8685 - val_accuracy: 0.3633\n",
      "Epoch 104/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.8678 - accuracy: 0.3029 - val_loss: 1.8659 - val_accuracy: 0.3633\n",
      "Epoch 105/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.8646 - accuracy: 0.3086 - val_loss: 1.8631 - val_accuracy: 0.3633\n",
      "Epoch 106/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.8618 - accuracy: 0.3057 - val_loss: 1.8604 - val_accuracy: 0.3600\n",
      "Epoch 107/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.8588 - accuracy: 0.2986 - val_loss: 1.8580 - val_accuracy: 0.3567\n",
      "Epoch 108/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.8558 - accuracy: 0.3057 - val_loss: 1.8553 - val_accuracy: 0.3600\n",
      "Epoch 109/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.8529 - accuracy: 0.3071 - val_loss: 1.8528 - val_accuracy: 0.3600\n",
      "Epoch 110/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.8500 - accuracy: 0.3043 - val_loss: 1.8503 - val_accuracy: 0.3600\n",
      "Epoch 111/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.8472 - accuracy: 0.3014 - val_loss: 1.8476 - val_accuracy: 0.3567\n",
      "Epoch 112/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.8444 - accuracy: 0.3014 - val_loss: 1.8453 - val_accuracy: 0.3533\n",
      "Epoch 113/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.8417 - accuracy: 0.2986 - val_loss: 1.8426 - val_accuracy: 0.3533\n",
      "Epoch 114/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.8388 - accuracy: 0.2957 - val_loss: 1.8401 - val_accuracy: 0.3533\n",
      "Epoch 115/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.8361 - accuracy: 0.2971 - val_loss: 1.8378 - val_accuracy: 0.3500\n",
      "Epoch 116/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.8332 - accuracy: 0.3029 - val_loss: 1.8352 - val_accuracy: 0.3500\n",
      "Epoch 117/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.8306 - accuracy: 0.3129 - val_loss: 1.8326 - val_accuracy: 0.3533\n",
      "Epoch 118/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.8279 - accuracy: 0.3329 - val_loss: 1.8302 - val_accuracy: 0.3567\n",
      "Epoch 119/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.8253 - accuracy: 0.3386 - val_loss: 1.8276 - val_accuracy: 0.3567\n",
      "Epoch 120/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.8227 - accuracy: 0.3300 - val_loss: 1.8255 - val_accuracy: 0.3533\n",
      "Epoch 121/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.8200 - accuracy: 0.3314 - val_loss: 1.8234 - val_accuracy: 0.3500\n",
      "Epoch 122/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.8174 - accuracy: 0.3371 - val_loss: 1.8212 - val_accuracy: 0.3533\n",
      "Epoch 123/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.8149 - accuracy: 0.3400 - val_loss: 1.8188 - val_accuracy: 0.3600\n",
      "Epoch 124/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.8123 - accuracy: 0.3343 - val_loss: 1.8167 - val_accuracy: 0.3533\n",
      "Epoch 125/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.8097 - accuracy: 0.3386 - val_loss: 1.8143 - val_accuracy: 0.3567\n",
      "Epoch 126/1000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.8072 - accuracy: 0.3371 - val_loss: 1.8123 - val_accuracy: 0.3433\n",
      "Epoch 127/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.8047 - accuracy: 0.3443 - val_loss: 1.8100 - val_accuracy: 0.3433\n",
      "Epoch 128/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.8022 - accuracy: 0.3400 - val_loss: 1.8079 - val_accuracy: 0.3433\n",
      "Epoch 129/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.7998 - accuracy: 0.3414 - val_loss: 1.8058 - val_accuracy: 0.3400\n",
      "Epoch 130/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.7973 - accuracy: 0.3429 - val_loss: 1.8035 - val_accuracy: 0.3433\n",
      "Epoch 131/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.7949 - accuracy: 0.3429 - val_loss: 1.8013 - val_accuracy: 0.3467\n",
      "Epoch 132/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.7926 - accuracy: 0.3457 - val_loss: 1.7994 - val_accuracy: 0.3467\n",
      "Epoch 133/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7901 - accuracy: 0.3457 - val_loss: 1.7973 - val_accuracy: 0.3467\n",
      "Epoch 134/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.7877 - accuracy: 0.3386 - val_loss: 1.7957 - val_accuracy: 0.3500\n",
      "Epoch 135/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7854 - accuracy: 0.3486 - val_loss: 1.7936 - val_accuracy: 0.3500\n",
      "Epoch 136/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7830 - accuracy: 0.3500 - val_loss: 1.7916 - val_accuracy: 0.3467\n",
      "Epoch 137/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.7806 - accuracy: 0.3471 - val_loss: 1.7896 - val_accuracy: 0.3467\n",
      "Epoch 138/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7784 - accuracy: 0.3543 - val_loss: 1.7875 - val_accuracy: 0.3467\n",
      "Epoch 139/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.7761 - accuracy: 0.3543 - val_loss: 1.7853 - val_accuracy: 0.3467\n",
      "Epoch 140/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.7738 - accuracy: 0.3500 - val_loss: 1.7835 - val_accuracy: 0.3467\n",
      "Epoch 141/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.7716 - accuracy: 0.3486 - val_loss: 1.7817 - val_accuracy: 0.3467\n",
      "Epoch 142/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.7694 - accuracy: 0.3557 - val_loss: 1.7799 - val_accuracy: 0.3467\n",
      "Epoch 143/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.7670 - accuracy: 0.3486 - val_loss: 1.7780 - val_accuracy: 0.3500\n",
      "Epoch 144/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.7648 - accuracy: 0.3514 - val_loss: 1.7761 - val_accuracy: 0.3500\n",
      "Epoch 145/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7626 - accuracy: 0.3529 - val_loss: 1.7743 - val_accuracy: 0.3467\n",
      "Epoch 146/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.7604 - accuracy: 0.3529 - val_loss: 1.7724 - val_accuracy: 0.3500\n",
      "Epoch 147/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.7581 - accuracy: 0.3514 - val_loss: 1.7706 - val_accuracy: 0.3500\n",
      "Epoch 148/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7561 - accuracy: 0.3571 - val_loss: 1.7688 - val_accuracy: 0.3433\n",
      "Epoch 149/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.7538 - accuracy: 0.3500 - val_loss: 1.7671 - val_accuracy: 0.3433\n",
      "Epoch 150/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7517 - accuracy: 0.3571 - val_loss: 1.7653 - val_accuracy: 0.3433\n",
      "Epoch 151/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.7497 - accuracy: 0.3571 - val_loss: 1.7636 - val_accuracy: 0.3433\n",
      "Epoch 152/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7475 - accuracy: 0.3557 - val_loss: 1.7619 - val_accuracy: 0.3433\n",
      "Epoch 153/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.7454 - accuracy: 0.3571 - val_loss: 1.7603 - val_accuracy: 0.3433\n",
      "Epoch 154/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.7432 - accuracy: 0.3571 - val_loss: 1.7587 - val_accuracy: 0.3400\n",
      "Epoch 155/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.7412 - accuracy: 0.3600 - val_loss: 1.7569 - val_accuracy: 0.3433\n",
      "Epoch 156/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7391 - accuracy: 0.3600 - val_loss: 1.7551 - val_accuracy: 0.3400\n",
      "Epoch 157/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7371 - accuracy: 0.3571 - val_loss: 1.7534 - val_accuracy: 0.3400\n",
      "Epoch 158/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.7350 - accuracy: 0.3586 - val_loss: 1.7518 - val_accuracy: 0.3400\n",
      "Epoch 159/1000\n",
      "700/700 [==============================] - 0s 91us/sample - loss: 1.7329 - accuracy: 0.3600 - val_loss: 1.7502 - val_accuracy: 0.3400\n",
      "Epoch 160/1000\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 1.7310 - accuracy: 0.3643 - val_loss: 1.7485 - val_accuracy: 0.3400\n",
      "Epoch 161/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.7289 - accuracy: 0.3629 - val_loss: 1.7469 - val_accuracy: 0.3400\n",
      "Epoch 162/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.7268 - accuracy: 0.3629 - val_loss: 1.7453 - val_accuracy: 0.3400\n",
      "Epoch 163/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.7247 - accuracy: 0.3614 - val_loss: 1.7435 - val_accuracy: 0.3467\n",
      "Epoch 164/1000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.7228 - accuracy: 0.3643 - val_loss: 1.7421 - val_accuracy: 0.3433\n",
      "Epoch 165/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.7208 - accuracy: 0.3643 - val_loss: 1.7406 - val_accuracy: 0.3400\n",
      "Epoch 166/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.7189 - accuracy: 0.3657 - val_loss: 1.7390 - val_accuracy: 0.3400\n",
      "Epoch 167/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.7170 - accuracy: 0.3629 - val_loss: 1.7374 - val_accuracy: 0.3433\n",
      "Epoch 168/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.7150 - accuracy: 0.3671 - val_loss: 1.7359 - val_accuracy: 0.3433\n",
      "Epoch 169/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7130 - accuracy: 0.3657 - val_loss: 1.7342 - val_accuracy: 0.3467\n",
      "Epoch 170/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.7111 - accuracy: 0.3714 - val_loss: 1.7327 - val_accuracy: 0.3467\n",
      "Epoch 171/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.7091 - accuracy: 0.3671 - val_loss: 1.7310 - val_accuracy: 0.3467\n",
      "Epoch 172/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7073 - accuracy: 0.3686 - val_loss: 1.7296 - val_accuracy: 0.3433\n",
      "Epoch 173/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7054 - accuracy: 0.3686 - val_loss: 1.7278 - val_accuracy: 0.3433\n",
      "Epoch 174/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.7036 - accuracy: 0.3729 - val_loss: 1.7265 - val_accuracy: 0.3433\n",
      "Epoch 175/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.7016 - accuracy: 0.3714 - val_loss: 1.7251 - val_accuracy: 0.3433\n",
      "Epoch 176/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.6997 - accuracy: 0.3771 - val_loss: 1.7236 - val_accuracy: 0.3433\n",
      "Epoch 177/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.6979 - accuracy: 0.3743 - val_loss: 1.7220 - val_accuracy: 0.3500\n",
      "Epoch 178/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.6961 - accuracy: 0.3729 - val_loss: 1.7206 - val_accuracy: 0.3500\n",
      "Epoch 179/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.6941 - accuracy: 0.3786 - val_loss: 1.7190 - val_accuracy: 0.3500\n",
      "Epoch 180/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.6923 - accuracy: 0.3743 - val_loss: 1.7176 - val_accuracy: 0.3467\n",
      "Epoch 181/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.6905 - accuracy: 0.3729 - val_loss: 1.7160 - val_accuracy: 0.3467\n",
      "Epoch 182/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.6886 - accuracy: 0.3800 - val_loss: 1.7145 - val_accuracy: 0.3533\n",
      "Epoch 183/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.6868 - accuracy: 0.3814 - val_loss: 1.7130 - val_accuracy: 0.3533\n",
      "Epoch 184/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6849 - accuracy: 0.3800 - val_loss: 1.7117 - val_accuracy: 0.3533\n",
      "Epoch 185/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.6832 - accuracy: 0.3786 - val_loss: 1.7103 - val_accuracy: 0.3533\n",
      "Epoch 186/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6813 - accuracy: 0.3814 - val_loss: 1.7090 - val_accuracy: 0.3500\n",
      "Epoch 187/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.6795 - accuracy: 0.3814 - val_loss: 1.7075 - val_accuracy: 0.3500\n",
      "Epoch 188/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6777 - accuracy: 0.3829 - val_loss: 1.7061 - val_accuracy: 0.3500\n",
      "Epoch 189/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6758 - accuracy: 0.3886 - val_loss: 1.7046 - val_accuracy: 0.3500\n",
      "Epoch 190/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6741 - accuracy: 0.3871 - val_loss: 1.7032 - val_accuracy: 0.3500\n",
      "Epoch 191/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.6722 - accuracy: 0.3857 - val_loss: 1.7019 - val_accuracy: 0.3567\n",
      "Epoch 192/1000\n",
      "700/700 [==============================] - 0s 96us/sample - loss: 1.6706 - accuracy: 0.3886 - val_loss: 1.7004 - val_accuracy: 0.3567\n",
      "Epoch 193/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.6689 - accuracy: 0.3900 - val_loss: 1.6989 - val_accuracy: 0.3567\n",
      "Epoch 194/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6670 - accuracy: 0.3900 - val_loss: 1.6975 - val_accuracy: 0.3533\n",
      "Epoch 195/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.6652 - accuracy: 0.3929 - val_loss: 1.6961 - val_accuracy: 0.3567\n",
      "Epoch 196/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.6635 - accuracy: 0.3914 - val_loss: 1.6947 - val_accuracy: 0.3567\n",
      "Epoch 197/1000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.6616 - accuracy: 0.3914 - val_loss: 1.6934 - val_accuracy: 0.3600\n",
      "Epoch 198/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.6599 - accuracy: 0.3957 - val_loss: 1.6920 - val_accuracy: 0.3600\n",
      "Epoch 199/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6582 - accuracy: 0.3957 - val_loss: 1.6905 - val_accuracy: 0.3533\n",
      "Epoch 200/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6565 - accuracy: 0.3914 - val_loss: 1.6893 - val_accuracy: 0.3567\n",
      "Epoch 201/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.6548 - accuracy: 0.3929 - val_loss: 1.6879 - val_accuracy: 0.3567\n",
      "Epoch 202/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.6529 - accuracy: 0.3914 - val_loss: 1.6866 - val_accuracy: 0.3567\n",
      "Epoch 203/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6513 - accuracy: 0.3929 - val_loss: 1.6854 - val_accuracy: 0.3633\n",
      "Epoch 204/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6495 - accuracy: 0.3943 - val_loss: 1.6841 - val_accuracy: 0.3600\n",
      "Epoch 205/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.6478 - accuracy: 0.3929 - val_loss: 1.6829 - val_accuracy: 0.3700\n",
      "Epoch 206/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.6462 - accuracy: 0.3971 - val_loss: 1.6815 - val_accuracy: 0.3667\n",
      "Epoch 207/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.6445 - accuracy: 0.3957 - val_loss: 1.6803 - val_accuracy: 0.3667\n",
      "Epoch 208/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.6429 - accuracy: 0.3971 - val_loss: 1.6789 - val_accuracy: 0.3667\n",
      "Epoch 209/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6412 - accuracy: 0.4000 - val_loss: 1.6777 - val_accuracy: 0.3667\n",
      "Epoch 210/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6395 - accuracy: 0.3971 - val_loss: 1.6763 - val_accuracy: 0.3667\n",
      "Epoch 211/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.6379 - accuracy: 0.3971 - val_loss: 1.6749 - val_accuracy: 0.3700\n",
      "Epoch 212/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.6361 - accuracy: 0.3957 - val_loss: 1.6738 - val_accuracy: 0.3700\n",
      "Epoch 213/1000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 1.6346 - accuracy: 0.3971 - val_loss: 1.6725 - val_accuracy: 0.3700\n",
      "Epoch 214/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.6330 - accuracy: 0.4014 - val_loss: 1.6713 - val_accuracy: 0.3700\n",
      "Epoch 215/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.6312 - accuracy: 0.4014 - val_loss: 1.6700 - val_accuracy: 0.3700\n",
      "Epoch 216/1000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 1.6296 - accuracy: 0.4029 - val_loss: 1.6688 - val_accuracy: 0.3667\n",
      "Epoch 217/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.6280 - accuracy: 0.4043 - val_loss: 1.6674 - val_accuracy: 0.3667\n",
      "Epoch 218/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.6263 - accuracy: 0.4057 - val_loss: 1.6663 - val_accuracy: 0.3667\n",
      "Epoch 219/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.6247 - accuracy: 0.4071 - val_loss: 1.6652 - val_accuracy: 0.3633\n",
      "Epoch 220/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6231 - accuracy: 0.4029 - val_loss: 1.6640 - val_accuracy: 0.3633\n",
      "Epoch 221/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6216 - accuracy: 0.4029 - val_loss: 1.6627 - val_accuracy: 0.3600\n",
      "Epoch 222/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.6198 - accuracy: 0.4071 - val_loss: 1.6615 - val_accuracy: 0.3633\n",
      "Epoch 223/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.6183 - accuracy: 0.4086 - val_loss: 1.6603 - val_accuracy: 0.3633\n",
      "Epoch 224/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6167 - accuracy: 0.4043 - val_loss: 1.6591 - val_accuracy: 0.3633\n",
      "Epoch 225/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6150 - accuracy: 0.4100 - val_loss: 1.6579 - val_accuracy: 0.3600\n",
      "Epoch 226/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6135 - accuracy: 0.4086 - val_loss: 1.6570 - val_accuracy: 0.3600\n",
      "Epoch 227/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.6117 - accuracy: 0.4043 - val_loss: 1.6558 - val_accuracy: 0.3600\n",
      "Epoch 228/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.6103 - accuracy: 0.4100 - val_loss: 1.6544 - val_accuracy: 0.3600\n",
      "Epoch 229/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6087 - accuracy: 0.4086 - val_loss: 1.6534 - val_accuracy: 0.3567\n",
      "Epoch 230/1000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.6071 - accuracy: 0.4143 - val_loss: 1.6522 - val_accuracy: 0.3567\n",
      "Epoch 231/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6055 - accuracy: 0.4129 - val_loss: 1.6511 - val_accuracy: 0.3567\n",
      "Epoch 232/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6039 - accuracy: 0.4114 - val_loss: 1.6498 - val_accuracy: 0.3567\n",
      "Epoch 233/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6025 - accuracy: 0.4200 - val_loss: 1.6486 - val_accuracy: 0.3567\n",
      "Epoch 234/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6008 - accuracy: 0.4171 - val_loss: 1.6476 - val_accuracy: 0.3533\n",
      "Epoch 235/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5994 - accuracy: 0.4200 - val_loss: 1.6465 - val_accuracy: 0.3533\n",
      "Epoch 236/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5978 - accuracy: 0.4186 - val_loss: 1.6454 - val_accuracy: 0.3533\n",
      "Epoch 237/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.5962 - accuracy: 0.4214 - val_loss: 1.6445 - val_accuracy: 0.3567\n",
      "Epoch 238/1000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.5948 - accuracy: 0.4214 - val_loss: 1.6432 - val_accuracy: 0.3567\n",
      "Epoch 239/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5932 - accuracy: 0.4271 - val_loss: 1.6421 - val_accuracy: 0.3567\n",
      "Epoch 240/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5916 - accuracy: 0.4300 - val_loss: 1.6411 - val_accuracy: 0.3567\n",
      "Epoch 241/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5902 - accuracy: 0.4286 - val_loss: 1.6402 - val_accuracy: 0.3600\n",
      "Epoch 242/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5887 - accuracy: 0.4343 - val_loss: 1.6389 - val_accuracy: 0.3567\n",
      "Epoch 243/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5871 - accuracy: 0.4286 - val_loss: 1.6377 - val_accuracy: 0.3600\n",
      "Epoch 244/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5857 - accuracy: 0.4343 - val_loss: 1.6366 - val_accuracy: 0.3600\n",
      "Epoch 245/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.5843 - accuracy: 0.4300 - val_loss: 1.6356 - val_accuracy: 0.3600\n",
      "Epoch 246/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5829 - accuracy: 0.4357 - val_loss: 1.6345 - val_accuracy: 0.3600\n",
      "Epoch 247/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.5813 - accuracy: 0.4357 - val_loss: 1.6336 - val_accuracy: 0.3633\n",
      "Epoch 248/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.5798 - accuracy: 0.4371 - val_loss: 1.6327 - val_accuracy: 0.3667\n",
      "Epoch 249/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.5786 - accuracy: 0.4357 - val_loss: 1.6315 - val_accuracy: 0.3633\n",
      "Epoch 250/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5770 - accuracy: 0.4386 - val_loss: 1.6303 - val_accuracy: 0.3633\n",
      "Epoch 251/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5755 - accuracy: 0.4371 - val_loss: 1.6293 - val_accuracy: 0.3633\n",
      "Epoch 252/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5741 - accuracy: 0.4414 - val_loss: 1.6283 - val_accuracy: 0.3667\n",
      "Epoch 253/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.5727 - accuracy: 0.4414 - val_loss: 1.6274 - val_accuracy: 0.3667\n",
      "Epoch 254/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.5713 - accuracy: 0.4357 - val_loss: 1.6263 - val_accuracy: 0.3667\n",
      "Epoch 255/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.5697 - accuracy: 0.4414 - val_loss: 1.6254 - val_accuracy: 0.3700\n",
      "Epoch 256/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.5683 - accuracy: 0.4443 - val_loss: 1.6243 - val_accuracy: 0.3700\n",
      "Epoch 257/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.5671 - accuracy: 0.4371 - val_loss: 1.6230 - val_accuracy: 0.3667\n",
      "Epoch 258/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.5655 - accuracy: 0.4400 - val_loss: 1.6219 - val_accuracy: 0.3633\n",
      "Epoch 259/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.5643 - accuracy: 0.4414 - val_loss: 1.6209 - val_accuracy: 0.3633\n",
      "Epoch 260/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.5629 - accuracy: 0.4386 - val_loss: 1.6201 - val_accuracy: 0.3633\n",
      "Epoch 261/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.5616 - accuracy: 0.4414 - val_loss: 1.6192 - val_accuracy: 0.3667\n",
      "Epoch 262/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.5601 - accuracy: 0.4414 - val_loss: 1.6183 - val_accuracy: 0.3667\n",
      "Epoch 263/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.5587 - accuracy: 0.4400 - val_loss: 1.6174 - val_accuracy: 0.3667\n",
      "Epoch 264/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5573 - accuracy: 0.4414 - val_loss: 1.6164 - val_accuracy: 0.3633\n",
      "Epoch 265/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.5559 - accuracy: 0.4414 - val_loss: 1.6153 - val_accuracy: 0.3667\n",
      "Epoch 266/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5546 - accuracy: 0.4457 - val_loss: 1.6146 - val_accuracy: 0.3633\n",
      "Epoch 267/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.5534 - accuracy: 0.4400 - val_loss: 1.6138 - val_accuracy: 0.3633\n",
      "Epoch 268/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.5520 - accuracy: 0.4400 - val_loss: 1.6126 - val_accuracy: 0.3633\n",
      "Epoch 269/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.5507 - accuracy: 0.4443 - val_loss: 1.6116 - val_accuracy: 0.3633\n",
      "Epoch 270/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.5492 - accuracy: 0.4357 - val_loss: 1.6104 - val_accuracy: 0.3600\n",
      "Epoch 271/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5480 - accuracy: 0.4414 - val_loss: 1.6097 - val_accuracy: 0.3633\n",
      "Epoch 272/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5467 - accuracy: 0.4386 - val_loss: 1.6087 - val_accuracy: 0.3633\n",
      "Epoch 273/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5454 - accuracy: 0.4429 - val_loss: 1.6079 - val_accuracy: 0.3600\n",
      "Epoch 274/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5440 - accuracy: 0.4429 - val_loss: 1.6069 - val_accuracy: 0.3667\n",
      "Epoch 275/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.5427 - accuracy: 0.4457 - val_loss: 1.6064 - val_accuracy: 0.3633\n",
      "Epoch 276/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.5415 - accuracy: 0.4386 - val_loss: 1.6052 - val_accuracy: 0.3667\n",
      "Epoch 277/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.5402 - accuracy: 0.4400 - val_loss: 1.6043 - val_accuracy: 0.3667\n",
      "Epoch 278/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5388 - accuracy: 0.4400 - val_loss: 1.6032 - val_accuracy: 0.3700\n",
      "Epoch 279/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5377 - accuracy: 0.4457 - val_loss: 1.6025 - val_accuracy: 0.3700\n",
      "Epoch 280/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5364 - accuracy: 0.4429 - val_loss: 1.6016 - val_accuracy: 0.3733\n",
      "Epoch 281/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5351 - accuracy: 0.4457 - val_loss: 1.6008 - val_accuracy: 0.3733\n",
      "Epoch 282/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5338 - accuracy: 0.4414 - val_loss: 1.6002 - val_accuracy: 0.3700\n",
      "Epoch 283/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5328 - accuracy: 0.4500 - val_loss: 1.5991 - val_accuracy: 0.3700\n",
      "Epoch 284/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5314 - accuracy: 0.4486 - val_loss: 1.5984 - val_accuracy: 0.3733\n",
      "Epoch 285/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5302 - accuracy: 0.4486 - val_loss: 1.5977 - val_accuracy: 0.3700\n",
      "Epoch 286/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5290 - accuracy: 0.4471 - val_loss: 1.5967 - val_accuracy: 0.3733\n",
      "Epoch 287/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.5277 - accuracy: 0.4471 - val_loss: 1.5959 - val_accuracy: 0.3700\n",
      "Epoch 288/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5265 - accuracy: 0.4486 - val_loss: 1.5952 - val_accuracy: 0.3700\n",
      "Epoch 289/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.5253 - accuracy: 0.4500 - val_loss: 1.5941 - val_accuracy: 0.3733\n",
      "Epoch 290/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5241 - accuracy: 0.4471 - val_loss: 1.5934 - val_accuracy: 0.3733\n",
      "Epoch 291/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5229 - accuracy: 0.4500 - val_loss: 1.5927 - val_accuracy: 0.3700\n",
      "Epoch 292/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.5217 - accuracy: 0.4514 - val_loss: 1.5920 - val_accuracy: 0.3700\n",
      "Epoch 293/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.5206 - accuracy: 0.4514 - val_loss: 1.5910 - val_accuracy: 0.3700\n",
      "Epoch 294/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5194 - accuracy: 0.4514 - val_loss: 1.5902 - val_accuracy: 0.3700\n",
      "Epoch 295/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5180 - accuracy: 0.4529 - val_loss: 1.5892 - val_accuracy: 0.3733\n",
      "Epoch 296/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5170 - accuracy: 0.4514 - val_loss: 1.5886 - val_accuracy: 0.3733\n",
      "Epoch 297/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.5158 - accuracy: 0.4514 - val_loss: 1.5878 - val_accuracy: 0.3767\n",
      "Epoch 298/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5145 - accuracy: 0.4500 - val_loss: 1.5871 - val_accuracy: 0.3733\n",
      "Epoch 299/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5136 - accuracy: 0.4543 - val_loss: 1.5861 - val_accuracy: 0.3733\n",
      "Epoch 300/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5124 - accuracy: 0.4557 - val_loss: 1.5854 - val_accuracy: 0.3767\n",
      "Epoch 301/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5111 - accuracy: 0.4529 - val_loss: 1.5845 - val_accuracy: 0.3733\n",
      "Epoch 302/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.5099 - accuracy: 0.4486 - val_loss: 1.5839 - val_accuracy: 0.3733\n",
      "Epoch 303/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.5089 - accuracy: 0.4571 - val_loss: 1.5830 - val_accuracy: 0.3733\n",
      "Epoch 304/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5079 - accuracy: 0.4529 - val_loss: 1.5824 - val_accuracy: 0.3733\n",
      "Epoch 305/1000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.5065 - accuracy: 0.4557 - val_loss: 1.5820 - val_accuracy: 0.3767\n",
      "Epoch 306/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.5054 - accuracy: 0.4529 - val_loss: 1.5809 - val_accuracy: 0.3800\n",
      "Epoch 307/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.5044 - accuracy: 0.4571 - val_loss: 1.5803 - val_accuracy: 0.3867\n",
      "Epoch 308/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.5033 - accuracy: 0.4571 - val_loss: 1.5794 - val_accuracy: 0.3833\n",
      "Epoch 309/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.5021 - accuracy: 0.4543 - val_loss: 1.5791 - val_accuracy: 0.3800\n",
      "Epoch 310/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5011 - accuracy: 0.4614 - val_loss: 1.5783 - val_accuracy: 0.3800\n",
      "Epoch 311/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4997 - accuracy: 0.4600 - val_loss: 1.5774 - val_accuracy: 0.3833\n",
      "Epoch 312/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.4989 - accuracy: 0.4600 - val_loss: 1.5771 - val_accuracy: 0.3800\n",
      "Epoch 313/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4977 - accuracy: 0.4571 - val_loss: 1.5763 - val_accuracy: 0.3767\n",
      "Epoch 314/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4966 - accuracy: 0.4629 - val_loss: 1.5755 - val_accuracy: 0.3733\n",
      "Epoch 315/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4954 - accuracy: 0.4586 - val_loss: 1.5748 - val_accuracy: 0.3767\n",
      "Epoch 316/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4944 - accuracy: 0.4571 - val_loss: 1.5744 - val_accuracy: 0.3767\n",
      "Epoch 317/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4933 - accuracy: 0.4600 - val_loss: 1.5739 - val_accuracy: 0.3733\n",
      "Epoch 318/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4922 - accuracy: 0.4600 - val_loss: 1.5733 - val_accuracy: 0.3800\n",
      "Epoch 319/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.4911 - accuracy: 0.4614 - val_loss: 1.5723 - val_accuracy: 0.3800\n",
      "Epoch 320/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.4902 - accuracy: 0.4629 - val_loss: 1.5717 - val_accuracy: 0.3733\n",
      "Epoch 321/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4890 - accuracy: 0.4600 - val_loss: 1.5712 - val_accuracy: 0.3733\n",
      "Epoch 322/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.4880 - accuracy: 0.4629 - val_loss: 1.5705 - val_accuracy: 0.3667\n",
      "Epoch 323/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.4870 - accuracy: 0.4643 - val_loss: 1.5699 - val_accuracy: 0.3667\n",
      "Epoch 324/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4859 - accuracy: 0.4629 - val_loss: 1.5693 - val_accuracy: 0.3667\n",
      "Epoch 325/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4849 - accuracy: 0.4643 - val_loss: 1.5687 - val_accuracy: 0.3633\n",
      "Epoch 326/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4839 - accuracy: 0.4657 - val_loss: 1.5682 - val_accuracy: 0.3633\n",
      "Epoch 327/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.4827 - accuracy: 0.4586 - val_loss: 1.5675 - val_accuracy: 0.3633\n",
      "Epoch 328/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4818 - accuracy: 0.4600 - val_loss: 1.5670 - val_accuracy: 0.3633\n",
      "Epoch 329/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.4807 - accuracy: 0.4671 - val_loss: 1.5665 - val_accuracy: 0.3667\n",
      "Epoch 330/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4797 - accuracy: 0.4657 - val_loss: 1.5658 - val_accuracy: 0.3667\n",
      "Epoch 331/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4786 - accuracy: 0.4657 - val_loss: 1.5652 - val_accuracy: 0.3633\n",
      "Epoch 332/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4778 - accuracy: 0.4629 - val_loss: 1.5645 - val_accuracy: 0.3633\n",
      "Epoch 333/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4766 - accuracy: 0.4671 - val_loss: 1.5641 - val_accuracy: 0.3633\n",
      "Epoch 334/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4756 - accuracy: 0.4643 - val_loss: 1.5635 - val_accuracy: 0.3633\n",
      "Epoch 335/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4746 - accuracy: 0.4643 - val_loss: 1.5628 - val_accuracy: 0.3633\n",
      "Epoch 336/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4736 - accuracy: 0.4700 - val_loss: 1.5623 - val_accuracy: 0.3633\n",
      "Epoch 337/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4726 - accuracy: 0.4686 - val_loss: 1.5617 - val_accuracy: 0.3633\n",
      "Epoch 338/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4718 - accuracy: 0.4686 - val_loss: 1.5613 - val_accuracy: 0.3633\n",
      "Epoch 339/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.4709 - accuracy: 0.4714 - val_loss: 1.5607 - val_accuracy: 0.3633\n",
      "Epoch 340/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.4697 - accuracy: 0.4686 - val_loss: 1.5603 - val_accuracy: 0.3567\n",
      "Epoch 341/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.4688 - accuracy: 0.4657 - val_loss: 1.5596 - val_accuracy: 0.3567\n",
      "Epoch 342/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4679 - accuracy: 0.4643 - val_loss: 1.5591 - val_accuracy: 0.3567\n",
      "Epoch 343/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.4668 - accuracy: 0.4714 - val_loss: 1.5584 - val_accuracy: 0.3567\n",
      "Epoch 344/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.4660 - accuracy: 0.4700 - val_loss: 1.5580 - val_accuracy: 0.3567\n",
      "Epoch 345/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4650 - accuracy: 0.4629 - val_loss: 1.5577 - val_accuracy: 0.3533\n",
      "Epoch 346/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4640 - accuracy: 0.4714 - val_loss: 1.5571 - val_accuracy: 0.3533\n",
      "Epoch 347/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4631 - accuracy: 0.4643 - val_loss: 1.5566 - val_accuracy: 0.3533\n",
      "Epoch 348/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4619 - accuracy: 0.4729 - val_loss: 1.5559 - val_accuracy: 0.3500\n",
      "Epoch 349/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4611 - accuracy: 0.4729 - val_loss: 1.5555 - val_accuracy: 0.3500\n",
      "Epoch 350/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.4602 - accuracy: 0.4686 - val_loss: 1.5550 - val_accuracy: 0.3567\n",
      "Epoch 351/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4592 - accuracy: 0.4714 - val_loss: 1.5545 - val_accuracy: 0.3500\n",
      "Epoch 352/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4583 - accuracy: 0.4814 - val_loss: 1.5538 - val_accuracy: 0.3533\n",
      "Epoch 353/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.4574 - accuracy: 0.4729 - val_loss: 1.5535 - val_accuracy: 0.3533\n",
      "Epoch 354/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4565 - accuracy: 0.4743 - val_loss: 1.5532 - val_accuracy: 0.3533\n",
      "Epoch 355/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4557 - accuracy: 0.4743 - val_loss: 1.5527 - val_accuracy: 0.3533\n",
      "Epoch 356/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.4547 - accuracy: 0.4786 - val_loss: 1.5523 - val_accuracy: 0.3500\n",
      "Epoch 357/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.4537 - accuracy: 0.4729 - val_loss: 1.5515 - val_accuracy: 0.3500\n",
      "Epoch 358/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4529 - accuracy: 0.4743 - val_loss: 1.5510 - val_accuracy: 0.3500\n",
      "Epoch 359/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4521 - accuracy: 0.4743 - val_loss: 1.5506 - val_accuracy: 0.3467\n",
      "Epoch 360/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.4509 - accuracy: 0.4771 - val_loss: 1.5507 - val_accuracy: 0.3400\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(3)\n",
    "\n",
    "# 1. 데이터셋 준비하기\n",
    "\n",
    "# 훈련셋과 시험셋 로딩\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# 훈련셋과 검증셋 분리\n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "\n",
    "X_train = X_train.reshape(50000, 784).astype('float32') / 255.0\n",
    "X_val = X_val.reshape(10000, 784).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "# 훈련셋, 검증셋 고르기\n",
    "train_rand_idxs = np.random.choice(50000, 700)\n",
    "val_rand_idxs = np.random.choice(10000, 300)\n",
    "\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]\n",
    "\n",
    "# 라벨링 전환\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_val = np_utils.to_categorical(Y_val)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# 3. 모델 엮기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping() # 조기종료 콜백함수 정의\n",
    "hist = model.fit(X_train, Y_train, epochs=1000, batch_size=10, validation_data=(X_val, Y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x183248ac50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 11us/sample - loss: 1.5844 - accuracy: 0.4147\n",
      "\n",
      "loss : 1.5843831192016602\n",
      "accuray : 0.4147\n"
     ]
    }
   ],
   "source": [
    "# 6. 모델 사용하기\n",
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "\n",
    "print('')\n",
    "print('loss : ' + str(loss_and_metrics[0]))\n",
    "print('accuray : ' + str(loss_and_metrics[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# 적절한 조기종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "700/700 [==============================] - 0s 255us/sample - loss: 2.3298 - accuracy: 0.0800 - val_loss: 2.3140 - val_accuracy: 0.0900\n",
      "Epoch 2/1000\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 2.3130 - accuracy: 0.0786 - val_loss: 2.3046 - val_accuracy: 0.0967\n",
      "Epoch 3/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 2.3061 - accuracy: 0.0871 - val_loss: 2.3019 - val_accuracy: 0.0933\n",
      "Epoch 4/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 2.3036 - accuracy: 0.1000 - val_loss: 2.3007 - val_accuracy: 0.0933\n",
      "Epoch 5/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 2.3022 - accuracy: 0.1000 - val_loss: 2.2998 - val_accuracy: 0.0933\n",
      "Epoch 6/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 2.3010 - accuracy: 0.1029 - val_loss: 2.2991 - val_accuracy: 0.0933\n",
      "Epoch 7/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.3000 - accuracy: 0.1043 - val_loss: 2.2985 - val_accuracy: 0.0967\n",
      "Epoch 8/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.2990 - accuracy: 0.1057 - val_loss: 2.2980 - val_accuracy: 0.0967\n",
      "Epoch 9/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 2.2980 - accuracy: 0.1057 - val_loss: 2.2975 - val_accuracy: 0.1000\n",
      "Epoch 10/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.2971 - accuracy: 0.1086 - val_loss: 2.2970 - val_accuracy: 0.1033\n",
      "Epoch 11/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.2963 - accuracy: 0.1086 - val_loss: 2.2965 - val_accuracy: 0.1067\n",
      "Epoch 12/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.2955 - accuracy: 0.1100 - val_loss: 2.2960 - val_accuracy: 0.1067\n",
      "Epoch 13/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 2.2946 - accuracy: 0.1100 - val_loss: 2.2955 - val_accuracy: 0.1100\n",
      "Epoch 14/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.2938 - accuracy: 0.1143 - val_loss: 2.2950 - val_accuracy: 0.1100\n",
      "Epoch 15/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.2929 - accuracy: 0.1143 - val_loss: 2.2943 - val_accuracy: 0.1067\n",
      "Epoch 16/1000\n",
      "700/700 [==============================] - 0s 302us/sample - loss: 2.2919 - accuracy: 0.1143 - val_loss: 2.2936 - val_accuracy: 0.1033\n",
      "Epoch 17/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 2.2909 - accuracy: 0.1171 - val_loss: 2.2929 - val_accuracy: 0.1033\n",
      "Epoch 18/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 2.2897 - accuracy: 0.1171 - val_loss: 2.2920 - val_accuracy: 0.1033\n",
      "Epoch 19/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 2.2884 - accuracy: 0.1186 - val_loss: 2.2911 - val_accuracy: 0.1033\n",
      "Epoch 20/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 2.2870 - accuracy: 0.1243 - val_loss: 2.2901 - val_accuracy: 0.1033\n",
      "Epoch 21/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 2.2853 - accuracy: 0.1214 - val_loss: 2.2891 - val_accuracy: 0.1033\n",
      "Epoch 22/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 2.2833 - accuracy: 0.1229 - val_loss: 2.2877 - val_accuracy: 0.1033\n",
      "Epoch 23/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 2.2811 - accuracy: 0.1243 - val_loss: 2.2860 - val_accuracy: 0.1033\n",
      "Epoch 24/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.2788 - accuracy: 0.1271 - val_loss: 2.2843 - val_accuracy: 0.1100\n",
      "Epoch 25/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 2.2764 - accuracy: 0.1314 - val_loss: 2.2824 - val_accuracy: 0.1133\n",
      "Epoch 26/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.2738 - accuracy: 0.1314 - val_loss: 2.2802 - val_accuracy: 0.1167\n",
      "Epoch 27/1000\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 2.2706 - accuracy: 0.1386 - val_loss: 2.2775 - val_accuracy: 0.1133\n",
      "Epoch 28/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 2.2674 - accuracy: 0.1400 - val_loss: 2.2747 - val_accuracy: 0.1133\n",
      "Epoch 29/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.2639 - accuracy: 0.1400 - val_loss: 2.2724 - val_accuracy: 0.1200\n",
      "Epoch 30/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.2605 - accuracy: 0.1386 - val_loss: 2.2695 - val_accuracy: 0.1233\n",
      "Epoch 31/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.2570 - accuracy: 0.1429 - val_loss: 2.2664 - val_accuracy: 0.1300\n",
      "Epoch 32/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.2533 - accuracy: 0.1457 - val_loss: 2.2633 - val_accuracy: 0.1300\n",
      "Epoch 33/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.2494 - accuracy: 0.1629 - val_loss: 2.2597 - val_accuracy: 0.1433\n",
      "Epoch 34/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.2453 - accuracy: 0.1729 - val_loss: 2.2562 - val_accuracy: 0.1667\n",
      "Epoch 35/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.2412 - accuracy: 0.1771 - val_loss: 2.2522 - val_accuracy: 0.1967\n",
      "Epoch 36/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.2370 - accuracy: 0.1986 - val_loss: 2.2483 - val_accuracy: 0.2000\n",
      "Epoch 37/1000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 2.2326 - accuracy: 0.2086 - val_loss: 2.2446 - val_accuracy: 0.2133\n",
      "Epoch 38/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.2284 - accuracy: 0.2143 - val_loss: 2.2408 - val_accuracy: 0.2100\n",
      "Epoch 39/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.2241 - accuracy: 0.2157 - val_loss: 2.2372 - val_accuracy: 0.2133\n",
      "Epoch 40/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.2198 - accuracy: 0.2243 - val_loss: 2.2338 - val_accuracy: 0.2133\n",
      "Epoch 41/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.2156 - accuracy: 0.2243 - val_loss: 2.2305 - val_accuracy: 0.2333\n",
      "Epoch 42/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 2.2112 - accuracy: 0.2257 - val_loss: 2.2271 - val_accuracy: 0.2433\n",
      "Epoch 43/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.2069 - accuracy: 0.2229 - val_loss: 2.2237 - val_accuracy: 0.2433\n",
      "Epoch 44/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 2.2026 - accuracy: 0.2214 - val_loss: 2.2200 - val_accuracy: 0.2433\n",
      "Epoch 45/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 2.1985 - accuracy: 0.2343 - val_loss: 2.2162 - val_accuracy: 0.2333\n",
      "Epoch 46/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.1942 - accuracy: 0.2329 - val_loss: 2.2128 - val_accuracy: 0.2267\n",
      "Epoch 47/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.1900 - accuracy: 0.2329 - val_loss: 2.2091 - val_accuracy: 0.2300\n",
      "Epoch 48/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 2.1859 - accuracy: 0.2343 - val_loss: 2.2055 - val_accuracy: 0.2267\n",
      "Epoch 49/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 2.1816 - accuracy: 0.2343 - val_loss: 2.2016 - val_accuracy: 0.2233\n",
      "Epoch 50/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 2.1774 - accuracy: 0.2343 - val_loss: 2.1978 - val_accuracy: 0.2200\n",
      "Epoch 51/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.1732 - accuracy: 0.2471 - val_loss: 2.1940 - val_accuracy: 0.2233\n",
      "Epoch 52/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.1689 - accuracy: 0.2457 - val_loss: 2.1902 - val_accuracy: 0.2300\n",
      "Epoch 53/1000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 2.1645 - accuracy: 0.2557 - val_loss: 2.1863 - val_accuracy: 0.2267\n",
      "Epoch 54/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 2.1601 - accuracy: 0.2557 - val_loss: 2.1822 - val_accuracy: 0.2233\n",
      "Epoch 55/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.1558 - accuracy: 0.2529 - val_loss: 2.1783 - val_accuracy: 0.2233\n",
      "Epoch 56/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 2.1515 - accuracy: 0.2571 - val_loss: 2.1746 - val_accuracy: 0.2200\n",
      "Epoch 57/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 2.1472 - accuracy: 0.2600 - val_loss: 2.1708 - val_accuracy: 0.2267\n",
      "Epoch 58/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 2.1430 - accuracy: 0.2586 - val_loss: 2.1672 - val_accuracy: 0.2267\n",
      "Epoch 59/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.1387 - accuracy: 0.2557 - val_loss: 2.1634 - val_accuracy: 0.2233\n",
      "Epoch 60/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.1345 - accuracy: 0.2629 - val_loss: 2.1596 - val_accuracy: 0.2267\n",
      "Epoch 61/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.1304 - accuracy: 0.2586 - val_loss: 2.1557 - val_accuracy: 0.2300\n",
      "Epoch 62/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.1263 - accuracy: 0.2543 - val_loss: 2.1518 - val_accuracy: 0.2300\n",
      "Epoch 63/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.1221 - accuracy: 0.2571 - val_loss: 2.1482 - val_accuracy: 0.2367\n",
      "Epoch 64/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.1180 - accuracy: 0.2557 - val_loss: 2.1447 - val_accuracy: 0.2333\n",
      "Epoch 65/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 2.1138 - accuracy: 0.2571 - val_loss: 2.1410 - val_accuracy: 0.2367\n",
      "Epoch 66/1000\n",
      "700/700 [==============================] - 0s 102us/sample - loss: 2.1095 - accuracy: 0.2571 - val_loss: 2.1371 - val_accuracy: 0.2333\n",
      "Epoch 67/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 2.1052 - accuracy: 0.2600 - val_loss: 2.1331 - val_accuracy: 0.2367\n",
      "Epoch 68/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 2.1009 - accuracy: 0.2571 - val_loss: 2.1290 - val_accuracy: 0.2367\n",
      "Epoch 69/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 2.0967 - accuracy: 0.2629 - val_loss: 2.1251 - val_accuracy: 0.2367\n",
      "Epoch 70/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 2.0924 - accuracy: 0.2586 - val_loss: 2.1215 - val_accuracy: 0.2433\n",
      "Epoch 71/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 2.0882 - accuracy: 0.2586 - val_loss: 2.1175 - val_accuracy: 0.2433\n",
      "Epoch 72/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 2.0839 - accuracy: 0.2600 - val_loss: 2.1138 - val_accuracy: 0.2433\n",
      "Epoch 73/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 2.0797 - accuracy: 0.2571 - val_loss: 2.1101 - val_accuracy: 0.2433\n",
      "Epoch 74/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 2.0755 - accuracy: 0.2614 - val_loss: 2.1060 - val_accuracy: 0.2433\n",
      "Epoch 75/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 2.0714 - accuracy: 0.2600 - val_loss: 2.1024 - val_accuracy: 0.2400\n",
      "Epoch 76/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 2.0672 - accuracy: 0.2600 - val_loss: 2.0987 - val_accuracy: 0.2433\n",
      "Epoch 77/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 2.0632 - accuracy: 0.2600 - val_loss: 2.0950 - val_accuracy: 0.2433\n",
      "Epoch 78/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.0590 - accuracy: 0.2614 - val_loss: 2.0912 - val_accuracy: 0.2433\n",
      "Epoch 79/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.0548 - accuracy: 0.2586 - val_loss: 2.0875 - val_accuracy: 0.2500\n",
      "Epoch 80/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.0509 - accuracy: 0.2614 - val_loss: 2.0839 - val_accuracy: 0.2500\n",
      "Epoch 81/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.0466 - accuracy: 0.2629 - val_loss: 2.0801 - val_accuracy: 0.2500\n",
      "Epoch 82/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 2.0424 - accuracy: 0.2629 - val_loss: 2.0763 - val_accuracy: 0.2500\n",
      "Epoch 83/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.0383 - accuracy: 0.2671 - val_loss: 2.0729 - val_accuracy: 0.2500\n",
      "Epoch 84/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 2.0340 - accuracy: 0.2671 - val_loss: 2.0692 - val_accuracy: 0.2500\n",
      "Epoch 85/1000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 2.0298 - accuracy: 0.2714 - val_loss: 2.0654 - val_accuracy: 0.2467\n",
      "Epoch 86/1000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 2.0257 - accuracy: 0.2686 - val_loss: 2.0617 - val_accuracy: 0.2467\n",
      "Epoch 87/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 2.0215 - accuracy: 0.2700 - val_loss: 2.0581 - val_accuracy: 0.2467\n",
      "Epoch 88/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 2.0174 - accuracy: 0.2686 - val_loss: 2.0545 - val_accuracy: 0.2433\n",
      "Epoch 89/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.0132 - accuracy: 0.2686 - val_loss: 2.0512 - val_accuracy: 0.2400\n",
      "Epoch 90/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 2.0092 - accuracy: 0.2629 - val_loss: 2.0472 - val_accuracy: 0.2400\n",
      "Epoch 91/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 2.0052 - accuracy: 0.2686 - val_loss: 2.0436 - val_accuracy: 0.2400\n",
      "Epoch 92/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 2.0012 - accuracy: 0.2643 - val_loss: 2.0399 - val_accuracy: 0.2433\n",
      "Epoch 93/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.9972 - accuracy: 0.2614 - val_loss: 2.0365 - val_accuracy: 0.2400\n",
      "Epoch 94/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.9932 - accuracy: 0.2686 - val_loss: 2.0334 - val_accuracy: 0.2367\n",
      "Epoch 95/1000\n",
      "700/700 [==============================] - 0s 85us/sample - loss: 1.9893 - accuracy: 0.2671 - val_loss: 2.0299 - val_accuracy: 0.2367\n",
      "Epoch 96/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.9853 - accuracy: 0.2671 - val_loss: 2.0266 - val_accuracy: 0.2367\n",
      "Epoch 97/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.9814 - accuracy: 0.2671 - val_loss: 2.0232 - val_accuracy: 0.2367\n",
      "Epoch 98/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.9775 - accuracy: 0.2686 - val_loss: 2.0196 - val_accuracy: 0.2333\n",
      "Epoch 99/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.9736 - accuracy: 0.2700 - val_loss: 2.0161 - val_accuracy: 0.2333\n",
      "Epoch 100/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.9697 - accuracy: 0.2700 - val_loss: 2.0129 - val_accuracy: 0.2367\n",
      "Epoch 101/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.9658 - accuracy: 0.2714 - val_loss: 2.0096 - val_accuracy: 0.2400\n",
      "Epoch 102/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.9618 - accuracy: 0.2743 - val_loss: 2.0066 - val_accuracy: 0.2333\n",
      "Epoch 103/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.9579 - accuracy: 0.2757 - val_loss: 2.0033 - val_accuracy: 0.2333\n",
      "Epoch 104/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.9541 - accuracy: 0.2771 - val_loss: 2.0003 - val_accuracy: 0.2400\n",
      "Epoch 105/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.9501 - accuracy: 0.2786 - val_loss: 1.9972 - val_accuracy: 0.2500\n",
      "Epoch 106/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.9462 - accuracy: 0.2786 - val_loss: 1.9940 - val_accuracy: 0.2467\n",
      "Epoch 107/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.9423 - accuracy: 0.2829 - val_loss: 1.9910 - val_accuracy: 0.2433\n",
      "Epoch 108/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.9385 - accuracy: 0.2857 - val_loss: 1.9875 - val_accuracy: 0.2433\n",
      "Epoch 109/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.9347 - accuracy: 0.2857 - val_loss: 1.9838 - val_accuracy: 0.2333\n",
      "Epoch 110/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.9311 - accuracy: 0.2886 - val_loss: 1.9812 - val_accuracy: 0.2367\n",
      "Epoch 111/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.9275 - accuracy: 0.2843 - val_loss: 1.9779 - val_accuracy: 0.2433\n",
      "Epoch 112/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.9239 - accuracy: 0.2843 - val_loss: 1.9749 - val_accuracy: 0.2467\n",
      "Epoch 113/1000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 1.9204 - accuracy: 0.2814 - val_loss: 1.9718 - val_accuracy: 0.2500\n",
      "Epoch 114/1000\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 1.9169 - accuracy: 0.2771 - val_loss: 1.9687 - val_accuracy: 0.2467\n",
      "Epoch 115/1000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 1.9134 - accuracy: 0.2814 - val_loss: 1.9659 - val_accuracy: 0.2433\n",
      "Epoch 116/1000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.9101 - accuracy: 0.2786 - val_loss: 1.9630 - val_accuracy: 0.2300\n",
      "Epoch 117/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.9067 - accuracy: 0.2771 - val_loss: 1.9601 - val_accuracy: 0.2300\n",
      "Epoch 118/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.9033 - accuracy: 0.2729 - val_loss: 1.9570 - val_accuracy: 0.2367\n",
      "Epoch 119/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.9000 - accuracy: 0.2729 - val_loss: 1.9546 - val_accuracy: 0.2433\n",
      "Epoch 120/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.8968 - accuracy: 0.2700 - val_loss: 1.9517 - val_accuracy: 0.2400\n",
      "Epoch 121/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.8935 - accuracy: 0.2743 - val_loss: 1.9490 - val_accuracy: 0.2333\n",
      "Epoch 122/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.8904 - accuracy: 0.2729 - val_loss: 1.9462 - val_accuracy: 0.2267\n",
      "Epoch 123/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.8873 - accuracy: 0.2729 - val_loss: 1.9434 - val_accuracy: 0.2200\n",
      "Epoch 124/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.8841 - accuracy: 0.2786 - val_loss: 1.9410 - val_accuracy: 0.2233\n",
      "Epoch 125/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.8811 - accuracy: 0.2771 - val_loss: 1.9383 - val_accuracy: 0.2233\n",
      "Epoch 126/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.8780 - accuracy: 0.2857 - val_loss: 1.9359 - val_accuracy: 0.2300\n",
      "Epoch 127/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.8750 - accuracy: 0.2843 - val_loss: 1.9330 - val_accuracy: 0.2300\n",
      "Epoch 128/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.8721 - accuracy: 0.2814 - val_loss: 1.9306 - val_accuracy: 0.2300\n",
      "Epoch 129/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.8691 - accuracy: 0.2814 - val_loss: 1.9279 - val_accuracy: 0.2300\n",
      "Epoch 130/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.8662 - accuracy: 0.2800 - val_loss: 1.9253 - val_accuracy: 0.2267\n",
      "Epoch 131/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.8633 - accuracy: 0.2786 - val_loss: 1.9225 - val_accuracy: 0.2267\n",
      "Epoch 132/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.8604 - accuracy: 0.2814 - val_loss: 1.9205 - val_accuracy: 0.2233\n",
      "Epoch 133/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.8577 - accuracy: 0.2786 - val_loss: 1.9182 - val_accuracy: 0.2300\n",
      "Epoch 134/1000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.8548 - accuracy: 0.2786 - val_loss: 1.9160 - val_accuracy: 0.2333\n",
      "Epoch 135/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.8521 - accuracy: 0.2814 - val_loss: 1.9136 - val_accuracy: 0.2333\n",
      "Epoch 136/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.8494 - accuracy: 0.2786 - val_loss: 1.9112 - val_accuracy: 0.2300\n",
      "Epoch 137/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.8468 - accuracy: 0.2800 - val_loss: 1.9087 - val_accuracy: 0.2233\n",
      "Epoch 138/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.8441 - accuracy: 0.2800 - val_loss: 1.9064 - val_accuracy: 0.2233\n",
      "Epoch 139/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.8416 - accuracy: 0.2814 - val_loss: 1.9041 - val_accuracy: 0.2200\n",
      "Epoch 140/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.8389 - accuracy: 0.2800 - val_loss: 1.9018 - val_accuracy: 0.2200\n",
      "Epoch 141/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.8364 - accuracy: 0.2829 - val_loss: 1.8996 - val_accuracy: 0.2200\n",
      "Epoch 142/1000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.8337 - accuracy: 0.2829 - val_loss: 1.8974 - val_accuracy: 0.2200\n",
      "Epoch 143/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.8312 - accuracy: 0.2829 - val_loss: 1.8950 - val_accuracy: 0.2233\n",
      "Epoch 144/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.8286 - accuracy: 0.2814 - val_loss: 1.8929 - val_accuracy: 0.2233\n",
      "Epoch 145/1000\n",
      "700/700 [==============================] - 0s 86us/sample - loss: 1.8262 - accuracy: 0.2814 - val_loss: 1.8908 - val_accuracy: 0.2233\n",
      "Epoch 146/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.8237 - accuracy: 0.2814 - val_loss: 1.8884 - val_accuracy: 0.2300\n",
      "Epoch 147/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.8213 - accuracy: 0.2857 - val_loss: 1.8864 - val_accuracy: 0.2333\n",
      "Epoch 148/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.8189 - accuracy: 0.2857 - val_loss: 1.8842 - val_accuracy: 0.2333\n",
      "Epoch 149/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.8164 - accuracy: 0.2857 - val_loss: 1.8820 - val_accuracy: 0.2300\n",
      "Epoch 150/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.8139 - accuracy: 0.2843 - val_loss: 1.8797 - val_accuracy: 0.2267\n",
      "Epoch 151/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.8115 - accuracy: 0.2857 - val_loss: 1.8775 - val_accuracy: 0.2267\n",
      "Epoch 152/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.8092 - accuracy: 0.2843 - val_loss: 1.8754 - val_accuracy: 0.2233\n",
      "Epoch 153/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.8068 - accuracy: 0.2771 - val_loss: 1.8737 - val_accuracy: 0.2200\n",
      "Epoch 154/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.8046 - accuracy: 0.2800 - val_loss: 1.8716 - val_accuracy: 0.2200\n",
      "Epoch 155/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.8022 - accuracy: 0.2757 - val_loss: 1.8693 - val_accuracy: 0.2267\n",
      "Epoch 156/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.7999 - accuracy: 0.2743 - val_loss: 1.8675 - val_accuracy: 0.2233\n",
      "Epoch 157/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.7977 - accuracy: 0.2771 - val_loss: 1.8656 - val_accuracy: 0.2233\n",
      "Epoch 158/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.7955 - accuracy: 0.2786 - val_loss: 1.8636 - val_accuracy: 0.2167\n",
      "Epoch 159/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.7933 - accuracy: 0.2771 - val_loss: 1.8615 - val_accuracy: 0.2200\n",
      "Epoch 160/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.7911 - accuracy: 0.2814 - val_loss: 1.8597 - val_accuracy: 0.2200\n",
      "Epoch 161/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.7889 - accuracy: 0.2771 - val_loss: 1.8579 - val_accuracy: 0.2233\n",
      "Epoch 162/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.7867 - accuracy: 0.2743 - val_loss: 1.8560 - val_accuracy: 0.2233\n",
      "Epoch 163/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.7845 - accuracy: 0.2743 - val_loss: 1.8539 - val_accuracy: 0.2300\n",
      "Epoch 164/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.7824 - accuracy: 0.2743 - val_loss: 1.8520 - val_accuracy: 0.2300\n",
      "Epoch 165/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.7802 - accuracy: 0.2743 - val_loss: 1.8505 - val_accuracy: 0.2300\n",
      "Epoch 166/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.7782 - accuracy: 0.2743 - val_loss: 1.8485 - val_accuracy: 0.2233\n",
      "Epoch 167/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.7761 - accuracy: 0.2800 - val_loss: 1.8467 - val_accuracy: 0.2233\n",
      "Epoch 168/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.7741 - accuracy: 0.2800 - val_loss: 1.8451 - val_accuracy: 0.2300\n",
      "Epoch 169/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.7721 - accuracy: 0.2800 - val_loss: 1.8435 - val_accuracy: 0.2367\n",
      "Epoch 170/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.7701 - accuracy: 0.2829 - val_loss: 1.8417 - val_accuracy: 0.2467\n",
      "Epoch 171/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.7681 - accuracy: 0.2886 - val_loss: 1.8400 - val_accuracy: 0.2633\n",
      "Epoch 172/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.7661 - accuracy: 0.2886 - val_loss: 1.8382 - val_accuracy: 0.2733\n",
      "Epoch 173/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.7641 - accuracy: 0.2943 - val_loss: 1.8366 - val_accuracy: 0.2833\n",
      "Epoch 174/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.7622 - accuracy: 0.2914 - val_loss: 1.8350 - val_accuracy: 0.2800\n",
      "Epoch 175/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7603 - accuracy: 0.2986 - val_loss: 1.8332 - val_accuracy: 0.2833\n",
      "Epoch 176/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.7584 - accuracy: 0.2957 - val_loss: 1.8315 - val_accuracy: 0.2933\n",
      "Epoch 177/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.7565 - accuracy: 0.2986 - val_loss: 1.8299 - val_accuracy: 0.2933\n",
      "Epoch 178/1000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 1.7546 - accuracy: 0.2957 - val_loss: 1.8281 - val_accuracy: 0.2933\n",
      "Epoch 179/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.7528 - accuracy: 0.2986 - val_loss: 1.8264 - val_accuracy: 0.2933\n",
      "Epoch 180/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.7510 - accuracy: 0.3000 - val_loss: 1.8248 - val_accuracy: 0.2933\n",
      "Epoch 181/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.7491 - accuracy: 0.2986 - val_loss: 1.8231 - val_accuracy: 0.2933\n",
      "Epoch 182/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.7473 - accuracy: 0.3000 - val_loss: 1.8217 - val_accuracy: 0.2933\n",
      "Epoch 183/1000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 1.7455 - accuracy: 0.3000 - val_loss: 1.8199 - val_accuracy: 0.2933\n",
      "Epoch 184/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.7436 - accuracy: 0.3029 - val_loss: 1.8184 - val_accuracy: 0.2933\n",
      "Epoch 185/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.7419 - accuracy: 0.3014 - val_loss: 1.8168 - val_accuracy: 0.2933\n",
      "Epoch 186/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.7401 - accuracy: 0.3057 - val_loss: 1.8153 - val_accuracy: 0.2933\n",
      "Epoch 187/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.7383 - accuracy: 0.3057 - val_loss: 1.8138 - val_accuracy: 0.2900\n",
      "Epoch 188/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.7366 - accuracy: 0.3043 - val_loss: 1.8126 - val_accuracy: 0.2967\n",
      "Epoch 189/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.7348 - accuracy: 0.3057 - val_loss: 1.8111 - val_accuracy: 0.2967\n",
      "Epoch 190/1000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 1.7331 - accuracy: 0.3086 - val_loss: 1.8095 - val_accuracy: 0.2933\n",
      "Epoch 191/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.7314 - accuracy: 0.3100 - val_loss: 1.8082 - val_accuracy: 0.2967\n",
      "Epoch 192/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7298 - accuracy: 0.3100 - val_loss: 1.8067 - val_accuracy: 0.2967\n",
      "Epoch 193/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.7281 - accuracy: 0.3086 - val_loss: 1.8051 - val_accuracy: 0.2967\n",
      "Epoch 194/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.7264 - accuracy: 0.3114 - val_loss: 1.8039 - val_accuracy: 0.2967\n",
      "Epoch 195/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.7247 - accuracy: 0.3114 - val_loss: 1.8024 - val_accuracy: 0.2967\n",
      "Epoch 196/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.7231 - accuracy: 0.3086 - val_loss: 1.8013 - val_accuracy: 0.2967\n",
      "Epoch 197/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.7214 - accuracy: 0.3100 - val_loss: 1.7997 - val_accuracy: 0.2967\n",
      "Epoch 198/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.7199 - accuracy: 0.3086 - val_loss: 1.7983 - val_accuracy: 0.2967\n",
      "Epoch 199/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7183 - accuracy: 0.3100 - val_loss: 1.7969 - val_accuracy: 0.3000\n",
      "Epoch 200/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.7167 - accuracy: 0.3100 - val_loss: 1.7955 - val_accuracy: 0.3000\n",
      "Epoch 201/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.7150 - accuracy: 0.3129 - val_loss: 1.7942 - val_accuracy: 0.3000\n",
      "Epoch 202/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.7134 - accuracy: 0.3129 - val_loss: 1.7928 - val_accuracy: 0.3000\n",
      "Epoch 203/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.7119 - accuracy: 0.3129 - val_loss: 1.7916 - val_accuracy: 0.3033\n",
      "Epoch 204/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.7104 - accuracy: 0.3143 - val_loss: 1.7901 - val_accuracy: 0.3000\n",
      "Epoch 205/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.7087 - accuracy: 0.3114 - val_loss: 1.7889 - val_accuracy: 0.3000\n",
      "Epoch 206/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.7073 - accuracy: 0.3114 - val_loss: 1.7877 - val_accuracy: 0.3033\n",
      "Epoch 207/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.7058 - accuracy: 0.3129 - val_loss: 1.7864 - val_accuracy: 0.3000\n",
      "Epoch 208/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.7042 - accuracy: 0.3157 - val_loss: 1.7851 - val_accuracy: 0.3000\n",
      "Epoch 209/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.7026 - accuracy: 0.3143 - val_loss: 1.7836 - val_accuracy: 0.3033\n",
      "Epoch 210/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.7012 - accuracy: 0.3171 - val_loss: 1.7823 - val_accuracy: 0.3033\n",
      "Epoch 211/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.6997 - accuracy: 0.3143 - val_loss: 1.7811 - val_accuracy: 0.3033\n",
      "Epoch 212/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6981 - accuracy: 0.3129 - val_loss: 1.7802 - val_accuracy: 0.3000\n",
      "Epoch 213/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.6968 - accuracy: 0.3186 - val_loss: 1.7788 - val_accuracy: 0.3033\n",
      "Epoch 214/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6953 - accuracy: 0.3171 - val_loss: 1.7776 - val_accuracy: 0.3033\n",
      "Epoch 215/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6937 - accuracy: 0.3186 - val_loss: 1.7762 - val_accuracy: 0.3033\n",
      "Epoch 216/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6923 - accuracy: 0.3186 - val_loss: 1.7751 - val_accuracy: 0.3033\n",
      "Epoch 217/1000\n",
      "700/700 [==============================] - 0s 99us/sample - loss: 1.6909 - accuracy: 0.3186 - val_loss: 1.7740 - val_accuracy: 0.3033\n",
      "Epoch 218/1000\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 1.6896 - accuracy: 0.3214 - val_loss: 1.7728 - val_accuracy: 0.3033\n",
      "Epoch 219/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6880 - accuracy: 0.3214 - val_loss: 1.7717 - val_accuracy: 0.3033\n",
      "Epoch 220/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.6865 - accuracy: 0.3214 - val_loss: 1.7705 - val_accuracy: 0.3033\n",
      "Epoch 221/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.6852 - accuracy: 0.3200 - val_loss: 1.7694 - val_accuracy: 0.3033\n",
      "Epoch 222/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.6837 - accuracy: 0.3214 - val_loss: 1.7683 - val_accuracy: 0.3033\n",
      "Epoch 223/1000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.6823 - accuracy: 0.3214 - val_loss: 1.7673 - val_accuracy: 0.3033\n",
      "Epoch 224/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.6808 - accuracy: 0.3243 - val_loss: 1.7660 - val_accuracy: 0.3033\n",
      "Epoch 225/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.6795 - accuracy: 0.3257 - val_loss: 1.7650 - val_accuracy: 0.3033\n",
      "Epoch 226/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6782 - accuracy: 0.3243 - val_loss: 1.7639 - val_accuracy: 0.3033\n",
      "Epoch 227/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6767 - accuracy: 0.3257 - val_loss: 1.7629 - val_accuracy: 0.3033\n",
      "Epoch 228/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6753 - accuracy: 0.3271 - val_loss: 1.7619 - val_accuracy: 0.3067\n",
      "Epoch 229/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6739 - accuracy: 0.3286 - val_loss: 1.7606 - val_accuracy: 0.3067\n",
      "Epoch 230/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.6726 - accuracy: 0.3286 - val_loss: 1.7594 - val_accuracy: 0.3100\n",
      "Epoch 231/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6712 - accuracy: 0.3300 - val_loss: 1.7582 - val_accuracy: 0.3100\n",
      "Epoch 232/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.6699 - accuracy: 0.3329 - val_loss: 1.7574 - val_accuracy: 0.3100\n",
      "Epoch 233/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.6686 - accuracy: 0.3314 - val_loss: 1.7564 - val_accuracy: 0.3067\n",
      "Epoch 234/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6672 - accuracy: 0.3329 - val_loss: 1.7554 - val_accuracy: 0.3067\n",
      "Epoch 235/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6659 - accuracy: 0.3357 - val_loss: 1.7545 - val_accuracy: 0.3067\n",
      "Epoch 236/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6646 - accuracy: 0.3343 - val_loss: 1.7531 - val_accuracy: 0.3067\n",
      "Epoch 237/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6633 - accuracy: 0.3343 - val_loss: 1.7522 - val_accuracy: 0.3067\n",
      "Epoch 238/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6620 - accuracy: 0.3400 - val_loss: 1.7513 - val_accuracy: 0.3067\n",
      "Epoch 239/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6606 - accuracy: 0.3386 - val_loss: 1.7504 - val_accuracy: 0.3067\n",
      "Epoch 240/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6593 - accuracy: 0.3357 - val_loss: 1.7491 - val_accuracy: 0.3067\n",
      "Epoch 241/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6580 - accuracy: 0.3414 - val_loss: 1.7481 - val_accuracy: 0.3067\n",
      "Epoch 242/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6567 - accuracy: 0.3457 - val_loss: 1.7471 - val_accuracy: 0.3067\n",
      "Epoch 243/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6554 - accuracy: 0.3443 - val_loss: 1.7461 - val_accuracy: 0.3067\n",
      "Epoch 244/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.6542 - accuracy: 0.3457 - val_loss: 1.7452 - val_accuracy: 0.3067\n",
      "Epoch 245/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6529 - accuracy: 0.3457 - val_loss: 1.7444 - val_accuracy: 0.3067\n",
      "Epoch 246/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.6517 - accuracy: 0.3471 - val_loss: 1.7436 - val_accuracy: 0.3100\n",
      "Epoch 247/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6504 - accuracy: 0.3500 - val_loss: 1.7425 - val_accuracy: 0.3067\n",
      "Epoch 248/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.6491 - accuracy: 0.3471 - val_loss: 1.7414 - val_accuracy: 0.3067\n",
      "Epoch 249/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.6479 - accuracy: 0.3486 - val_loss: 1.7404 - val_accuracy: 0.3067\n",
      "Epoch 250/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.6467 - accuracy: 0.3486 - val_loss: 1.7394 - val_accuracy: 0.3067\n",
      "Epoch 251/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.6453 - accuracy: 0.3500 - val_loss: 1.7387 - val_accuracy: 0.3067\n",
      "Epoch 252/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.6441 - accuracy: 0.3471 - val_loss: 1.7378 - val_accuracy: 0.3067\n",
      "Epoch 253/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6430 - accuracy: 0.3486 - val_loss: 1.7370 - val_accuracy: 0.3133\n",
      "Epoch 254/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6417 - accuracy: 0.3529 - val_loss: 1.7359 - val_accuracy: 0.3133\n",
      "Epoch 255/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6405 - accuracy: 0.3514 - val_loss: 1.7351 - val_accuracy: 0.3133\n",
      "Epoch 256/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.6392 - accuracy: 0.3571 - val_loss: 1.7342 - val_accuracy: 0.3133\n",
      "Epoch 257/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.6380 - accuracy: 0.3571 - val_loss: 1.7332 - val_accuracy: 0.3133\n",
      "Epoch 258/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6368 - accuracy: 0.3571 - val_loss: 1.7323 - val_accuracy: 0.3133\n",
      "Epoch 259/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.6357 - accuracy: 0.3586 - val_loss: 1.7313 - val_accuracy: 0.3133\n",
      "Epoch 260/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6344 - accuracy: 0.3586 - val_loss: 1.7304 - val_accuracy: 0.3133\n",
      "Epoch 261/1000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.6332 - accuracy: 0.3614 - val_loss: 1.7295 - val_accuracy: 0.3133\n",
      "Epoch 262/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.6321 - accuracy: 0.3614 - val_loss: 1.7287 - val_accuracy: 0.3133\n",
      "Epoch 263/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6309 - accuracy: 0.3657 - val_loss: 1.7280 - val_accuracy: 0.3167\n",
      "Epoch 264/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.6297 - accuracy: 0.3614 - val_loss: 1.7270 - val_accuracy: 0.3167\n",
      "Epoch 265/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.6285 - accuracy: 0.3657 - val_loss: 1.7263 - val_accuracy: 0.3167\n",
      "Epoch 266/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6273 - accuracy: 0.3643 - val_loss: 1.7257 - val_accuracy: 0.3167\n",
      "Epoch 267/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6262 - accuracy: 0.3629 - val_loss: 1.7244 - val_accuracy: 0.3233\n",
      "Epoch 268/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6250 - accuracy: 0.3671 - val_loss: 1.7237 - val_accuracy: 0.3233\n",
      "Epoch 269/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6238 - accuracy: 0.3657 - val_loss: 1.7228 - val_accuracy: 0.3233\n",
      "Epoch 270/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6227 - accuracy: 0.3757 - val_loss: 1.7222 - val_accuracy: 0.3233\n",
      "Epoch 271/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.6216 - accuracy: 0.3714 - val_loss: 1.7214 - val_accuracy: 0.3233\n",
      "Epoch 272/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.6205 - accuracy: 0.3700 - val_loss: 1.7205 - val_accuracy: 0.3233\n",
      "Epoch 273/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.6194 - accuracy: 0.3771 - val_loss: 1.7196 - val_accuracy: 0.3233\n",
      "Epoch 274/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.6181 - accuracy: 0.3714 - val_loss: 1.7185 - val_accuracy: 0.3233\n",
      "Epoch 275/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.6171 - accuracy: 0.3743 - val_loss: 1.7179 - val_accuracy: 0.3233\n",
      "Epoch 276/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.6159 - accuracy: 0.3771 - val_loss: 1.7170 - val_accuracy: 0.3267\n",
      "Epoch 277/1000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.6148 - accuracy: 0.3743 - val_loss: 1.7162 - val_accuracy: 0.3267\n",
      "Epoch 278/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6136 - accuracy: 0.3771 - val_loss: 1.7155 - val_accuracy: 0.3267\n",
      "Epoch 279/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6126 - accuracy: 0.3800 - val_loss: 1.7148 - val_accuracy: 0.3267\n",
      "Epoch 280/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.6115 - accuracy: 0.3786 - val_loss: 1.7140 - val_accuracy: 0.3267\n",
      "Epoch 281/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.6104 - accuracy: 0.3786 - val_loss: 1.7133 - val_accuracy: 0.3267\n",
      "Epoch 282/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.6092 - accuracy: 0.3829 - val_loss: 1.7124 - val_accuracy: 0.3267\n",
      "Epoch 283/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6081 - accuracy: 0.3814 - val_loss: 1.7118 - val_accuracy: 0.3267\n",
      "Epoch 284/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6071 - accuracy: 0.3814 - val_loss: 1.7108 - val_accuracy: 0.3300\n",
      "Epoch 285/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6060 - accuracy: 0.3814 - val_loss: 1.7098 - val_accuracy: 0.3333\n",
      "Epoch 286/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6049 - accuracy: 0.3814 - val_loss: 1.7092 - val_accuracy: 0.3333\n",
      "Epoch 287/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.6038 - accuracy: 0.3857 - val_loss: 1.7084 - val_accuracy: 0.3333\n",
      "Epoch 288/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.6027 - accuracy: 0.3814 - val_loss: 1.7077 - val_accuracy: 0.3333\n",
      "Epoch 289/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.6016 - accuracy: 0.3871 - val_loss: 1.7069 - val_accuracy: 0.3333\n",
      "Epoch 290/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.6006 - accuracy: 0.3843 - val_loss: 1.7063 - val_accuracy: 0.3333\n",
      "Epoch 291/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.5995 - accuracy: 0.3829 - val_loss: 1.7054 - val_accuracy: 0.3333\n",
      "Epoch 292/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.5985 - accuracy: 0.3886 - val_loss: 1.7048 - val_accuracy: 0.3367\n",
      "Epoch 293/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5973 - accuracy: 0.3871 - val_loss: 1.7042 - val_accuracy: 0.3367\n",
      "Epoch 294/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5963 - accuracy: 0.3829 - val_loss: 1.7033 - val_accuracy: 0.3367\n",
      "Epoch 295/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5952 - accuracy: 0.3857 - val_loss: 1.7027 - val_accuracy: 0.3367\n",
      "Epoch 296/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.5942 - accuracy: 0.3857 - val_loss: 1.7021 - val_accuracy: 0.3400\n",
      "Epoch 297/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5931 - accuracy: 0.3857 - val_loss: 1.7014 - val_accuracy: 0.3400\n",
      "Epoch 298/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5921 - accuracy: 0.3900 - val_loss: 1.7007 - val_accuracy: 0.3400\n",
      "Epoch 299/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5910 - accuracy: 0.3914 - val_loss: 1.7001 - val_accuracy: 0.3400\n",
      "Epoch 300/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5900 - accuracy: 0.3914 - val_loss: 1.6991 - val_accuracy: 0.3400\n",
      "Epoch 301/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5889 - accuracy: 0.3914 - val_loss: 1.6984 - val_accuracy: 0.3400\n",
      "Epoch 302/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5880 - accuracy: 0.3900 - val_loss: 1.6977 - val_accuracy: 0.3400\n",
      "Epoch 303/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.5869 - accuracy: 0.3929 - val_loss: 1.6973 - val_accuracy: 0.3400\n",
      "Epoch 304/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5859 - accuracy: 0.3943 - val_loss: 1.6965 - val_accuracy: 0.3400\n",
      "Epoch 305/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5848 - accuracy: 0.3957 - val_loss: 1.6958 - val_accuracy: 0.3400\n",
      "Epoch 306/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5839 - accuracy: 0.3943 - val_loss: 1.6950 - val_accuracy: 0.3400\n",
      "Epoch 307/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5829 - accuracy: 0.3971 - val_loss: 1.6943 - val_accuracy: 0.3400\n",
      "Epoch 308/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5818 - accuracy: 0.3943 - val_loss: 1.6936 - val_accuracy: 0.3400\n",
      "Epoch 309/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.5808 - accuracy: 0.3943 - val_loss: 1.6929 - val_accuracy: 0.3400\n",
      "Epoch 310/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5798 - accuracy: 0.3971 - val_loss: 1.6924 - val_accuracy: 0.3400\n",
      "Epoch 311/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.5788 - accuracy: 0.3971 - val_loss: 1.6918 - val_accuracy: 0.3400\n",
      "Epoch 312/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.5778 - accuracy: 0.3957 - val_loss: 1.6909 - val_accuracy: 0.3433\n",
      "Epoch 313/1000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 1.5768 - accuracy: 0.4014 - val_loss: 1.6903 - val_accuracy: 0.3433\n",
      "Epoch 314/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.5757 - accuracy: 0.3986 - val_loss: 1.6897 - val_accuracy: 0.3433\n",
      "Epoch 315/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.5747 - accuracy: 0.4014 - val_loss: 1.6888 - val_accuracy: 0.3433\n",
      "Epoch 316/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.5738 - accuracy: 0.4000 - val_loss: 1.6883 - val_accuracy: 0.3433\n",
      "Epoch 317/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.5728 - accuracy: 0.4000 - val_loss: 1.6876 - val_accuracy: 0.3467\n",
      "Epoch 318/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.5718 - accuracy: 0.4029 - val_loss: 1.6871 - val_accuracy: 0.3433\n",
      "Epoch 319/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.5708 - accuracy: 0.4029 - val_loss: 1.6864 - val_accuracy: 0.3500\n",
      "Epoch 320/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.5698 - accuracy: 0.4043 - val_loss: 1.6858 - val_accuracy: 0.3500\n",
      "Epoch 321/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.5688 - accuracy: 0.4057 - val_loss: 1.6854 - val_accuracy: 0.3467\n",
      "Epoch 322/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.5679 - accuracy: 0.4057 - val_loss: 1.6846 - val_accuracy: 0.3500\n",
      "Epoch 323/1000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 1.5669 - accuracy: 0.4043 - val_loss: 1.6840 - val_accuracy: 0.3500\n",
      "Epoch 324/1000\n",
      "700/700 [==============================] - 0s 130us/sample - loss: 1.5659 - accuracy: 0.4014 - val_loss: 1.6832 - val_accuracy: 0.3500\n",
      "Epoch 325/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.5649 - accuracy: 0.4057 - val_loss: 1.6827 - val_accuracy: 0.3500\n",
      "Epoch 326/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5640 - accuracy: 0.4057 - val_loss: 1.6819 - val_accuracy: 0.3500\n",
      "Epoch 327/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5631 - accuracy: 0.4071 - val_loss: 1.6814 - val_accuracy: 0.3500\n",
      "Epoch 328/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5620 - accuracy: 0.4129 - val_loss: 1.6808 - val_accuracy: 0.3500\n",
      "Epoch 329/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5610 - accuracy: 0.4129 - val_loss: 1.6804 - val_accuracy: 0.3500\n",
      "Epoch 330/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.5601 - accuracy: 0.4086 - val_loss: 1.6797 - val_accuracy: 0.3500\n",
      "Epoch 331/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5592 - accuracy: 0.4129 - val_loss: 1.6791 - val_accuracy: 0.3500\n",
      "Epoch 332/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5581 - accuracy: 0.4100 - val_loss: 1.6784 - val_accuracy: 0.3500\n",
      "Epoch 333/1000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.5572 - accuracy: 0.4100 - val_loss: 1.6778 - val_accuracy: 0.3500\n",
      "Epoch 334/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5563 - accuracy: 0.4143 - val_loss: 1.6772 - val_accuracy: 0.3500\n",
      "Epoch 335/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5553 - accuracy: 0.4171 - val_loss: 1.6766 - val_accuracy: 0.3500\n",
      "Epoch 336/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.5543 - accuracy: 0.4114 - val_loss: 1.6759 - val_accuracy: 0.3533\n",
      "Epoch 337/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.5534 - accuracy: 0.4143 - val_loss: 1.6754 - val_accuracy: 0.3500\n",
      "Epoch 338/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.5525 - accuracy: 0.4171 - val_loss: 1.6748 - val_accuracy: 0.3533\n",
      "Epoch 339/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.5515 - accuracy: 0.4171 - val_loss: 1.6741 - val_accuracy: 0.3567\n",
      "Epoch 340/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.5505 - accuracy: 0.4171 - val_loss: 1.6737 - val_accuracy: 0.3567\n",
      "Epoch 341/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5496 - accuracy: 0.4171 - val_loss: 1.6730 - val_accuracy: 0.3567\n",
      "Epoch 342/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5486 - accuracy: 0.4186 - val_loss: 1.6725 - val_accuracy: 0.3567\n",
      "Epoch 343/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5477 - accuracy: 0.4171 - val_loss: 1.6720 - val_accuracy: 0.3567\n",
      "Epoch 344/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5468 - accuracy: 0.4186 - val_loss: 1.6714 - val_accuracy: 0.3567\n",
      "Epoch 345/1000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.5460 - accuracy: 0.4186 - val_loss: 1.6707 - val_accuracy: 0.3567\n",
      "Epoch 346/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5449 - accuracy: 0.4229 - val_loss: 1.6700 - val_accuracy: 0.3567\n",
      "Epoch 347/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5440 - accuracy: 0.4200 - val_loss: 1.6695 - val_accuracy: 0.3567\n",
      "Epoch 348/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5431 - accuracy: 0.4186 - val_loss: 1.6688 - val_accuracy: 0.3567\n",
      "Epoch 349/1000\n",
      "700/700 [==============================] - 0s 65us/sample - loss: 1.5422 - accuracy: 0.4214 - val_loss: 1.6682 - val_accuracy: 0.3567\n",
      "Epoch 350/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5412 - accuracy: 0.4171 - val_loss: 1.6677 - val_accuracy: 0.3567\n",
      "Epoch 351/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5403 - accuracy: 0.4200 - val_loss: 1.6670 - val_accuracy: 0.3567\n",
      "Epoch 352/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5394 - accuracy: 0.4214 - val_loss: 1.6665 - val_accuracy: 0.3567\n",
      "Epoch 353/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5385 - accuracy: 0.4214 - val_loss: 1.6660 - val_accuracy: 0.3567\n",
      "Epoch 354/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5375 - accuracy: 0.4200 - val_loss: 1.6655 - val_accuracy: 0.3567\n",
      "Epoch 355/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5366 - accuracy: 0.4243 - val_loss: 1.6648 - val_accuracy: 0.3567\n",
      "Epoch 356/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5357 - accuracy: 0.4214 - val_loss: 1.6643 - val_accuracy: 0.3567\n",
      "Epoch 357/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5347 - accuracy: 0.4200 - val_loss: 1.6636 - val_accuracy: 0.3567\n",
      "Epoch 358/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5339 - accuracy: 0.4229 - val_loss: 1.6629 - val_accuracy: 0.3567\n",
      "Epoch 359/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5330 - accuracy: 0.4243 - val_loss: 1.6625 - val_accuracy: 0.3567\n",
      "Epoch 360/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5320 - accuracy: 0.4243 - val_loss: 1.6618 - val_accuracy: 0.3533\n",
      "Epoch 361/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.5311 - accuracy: 0.4200 - val_loss: 1.6612 - val_accuracy: 0.3533\n",
      "Epoch 362/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.5301 - accuracy: 0.4229 - val_loss: 1.6607 - val_accuracy: 0.3533\n",
      "Epoch 363/1000\n",
      "700/700 [==============================] - 0s 91us/sample - loss: 1.5292 - accuracy: 0.4214 - val_loss: 1.6600 - val_accuracy: 0.3533\n",
      "Epoch 364/1000\n",
      "700/700 [==============================] - 0s 106us/sample - loss: 1.5284 - accuracy: 0.4243 - val_loss: 1.6596 - val_accuracy: 0.3567\n",
      "Epoch 365/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.5274 - accuracy: 0.4257 - val_loss: 1.6591 - val_accuracy: 0.3600\n",
      "Epoch 366/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5266 - accuracy: 0.4271 - val_loss: 1.6585 - val_accuracy: 0.3600\n",
      "Epoch 367/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5256 - accuracy: 0.4271 - val_loss: 1.6581 - val_accuracy: 0.3600\n",
      "Epoch 368/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.5248 - accuracy: 0.4257 - val_loss: 1.6574 - val_accuracy: 0.3600\n",
      "Epoch 369/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.5238 - accuracy: 0.4329 - val_loss: 1.6571 - val_accuracy: 0.3600\n",
      "Epoch 370/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.5229 - accuracy: 0.4300 - val_loss: 1.6566 - val_accuracy: 0.3600\n",
      "Epoch 371/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.5220 - accuracy: 0.4271 - val_loss: 1.6561 - val_accuracy: 0.3600\n",
      "Epoch 372/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.5211 - accuracy: 0.4257 - val_loss: 1.6553 - val_accuracy: 0.3600\n",
      "Epoch 373/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.5203 - accuracy: 0.4271 - val_loss: 1.6548 - val_accuracy: 0.3600\n",
      "Epoch 374/1000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.5194 - accuracy: 0.4271 - val_loss: 1.6542 - val_accuracy: 0.3600\n",
      "Epoch 375/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.5184 - accuracy: 0.4314 - val_loss: 1.6538 - val_accuracy: 0.3600\n",
      "Epoch 376/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.5176 - accuracy: 0.4329 - val_loss: 1.6533 - val_accuracy: 0.3600\n",
      "Epoch 377/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5167 - accuracy: 0.4271 - val_loss: 1.6527 - val_accuracy: 0.3600\n",
      "Epoch 378/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.5159 - accuracy: 0.4314 - val_loss: 1.6523 - val_accuracy: 0.3600\n",
      "Epoch 379/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5149 - accuracy: 0.4314 - val_loss: 1.6517 - val_accuracy: 0.3600\n",
      "Epoch 380/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5141 - accuracy: 0.4314 - val_loss: 1.6513 - val_accuracy: 0.3633\n",
      "Epoch 381/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5132 - accuracy: 0.4329 - val_loss: 1.6506 - val_accuracy: 0.3633\n",
      "Epoch 382/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.5124 - accuracy: 0.4371 - val_loss: 1.6502 - val_accuracy: 0.3633\n",
      "Epoch 383/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.5115 - accuracy: 0.4357 - val_loss: 1.6496 - val_accuracy: 0.3667\n",
      "Epoch 384/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.5105 - accuracy: 0.4357 - val_loss: 1.6493 - val_accuracy: 0.3633\n",
      "Epoch 385/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.5098 - accuracy: 0.4357 - val_loss: 1.6487 - val_accuracy: 0.3667\n",
      "Epoch 386/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.5089 - accuracy: 0.4357 - val_loss: 1.6482 - val_accuracy: 0.3667\n",
      "Epoch 387/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.5080 - accuracy: 0.4357 - val_loss: 1.6475 - val_accuracy: 0.3667\n",
      "Epoch 388/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5071 - accuracy: 0.4386 - val_loss: 1.6470 - val_accuracy: 0.3667\n",
      "Epoch 389/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5063 - accuracy: 0.4357 - val_loss: 1.6466 - val_accuracy: 0.3633\n",
      "Epoch 390/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5055 - accuracy: 0.4386 - val_loss: 1.6460 - val_accuracy: 0.3633\n",
      "Epoch 391/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.5046 - accuracy: 0.4371 - val_loss: 1.6455 - val_accuracy: 0.3633\n",
      "Epoch 392/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.5037 - accuracy: 0.4357 - val_loss: 1.6450 - val_accuracy: 0.3633\n",
      "Epoch 393/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.5028 - accuracy: 0.4357 - val_loss: 1.6444 - val_accuracy: 0.3633\n",
      "Epoch 394/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.5020 - accuracy: 0.4386 - val_loss: 1.6437 - val_accuracy: 0.3667\n",
      "Epoch 395/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.5012 - accuracy: 0.4414 - val_loss: 1.6434 - val_accuracy: 0.3633\n",
      "Epoch 396/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.5004 - accuracy: 0.4386 - val_loss: 1.6429 - val_accuracy: 0.3633\n",
      "Epoch 397/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4995 - accuracy: 0.4386 - val_loss: 1.6422 - val_accuracy: 0.3633\n",
      "Epoch 398/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4987 - accuracy: 0.4386 - val_loss: 1.6418 - val_accuracy: 0.3633\n",
      "Epoch 399/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4978 - accuracy: 0.4400 - val_loss: 1.6413 - val_accuracy: 0.3633\n",
      "Epoch 400/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4971 - accuracy: 0.4414 - val_loss: 1.6409 - val_accuracy: 0.3633\n",
      "Epoch 401/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4961 - accuracy: 0.4414 - val_loss: 1.6403 - val_accuracy: 0.3667\n",
      "Epoch 402/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4953 - accuracy: 0.4414 - val_loss: 1.6399 - val_accuracy: 0.3667\n",
      "Epoch 403/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4944 - accuracy: 0.4429 - val_loss: 1.6394 - val_accuracy: 0.3667\n",
      "Epoch 404/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4937 - accuracy: 0.4443 - val_loss: 1.6388 - val_accuracy: 0.3733\n",
      "Epoch 405/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4928 - accuracy: 0.4414 - val_loss: 1.6384 - val_accuracy: 0.3700\n",
      "Epoch 406/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4919 - accuracy: 0.4443 - val_loss: 1.6381 - val_accuracy: 0.3700\n",
      "Epoch 407/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4912 - accuracy: 0.4457 - val_loss: 1.6374 - val_accuracy: 0.3733\n",
      "Epoch 408/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4903 - accuracy: 0.4429 - val_loss: 1.6368 - val_accuracy: 0.3733\n",
      "Epoch 409/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4895 - accuracy: 0.4457 - val_loss: 1.6364 - val_accuracy: 0.3733\n",
      "Epoch 410/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.4887 - accuracy: 0.4457 - val_loss: 1.6359 - val_accuracy: 0.3733\n",
      "Epoch 411/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4878 - accuracy: 0.4457 - val_loss: 1.6355 - val_accuracy: 0.3733\n",
      "Epoch 412/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.4870 - accuracy: 0.4471 - val_loss: 1.6350 - val_accuracy: 0.3733\n",
      "Epoch 413/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4861 - accuracy: 0.4471 - val_loss: 1.6347 - val_accuracy: 0.3733\n",
      "Epoch 414/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4853 - accuracy: 0.4457 - val_loss: 1.6345 - val_accuracy: 0.3700\n",
      "Epoch 415/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.4845 - accuracy: 0.4443 - val_loss: 1.6338 - val_accuracy: 0.3767\n",
      "Epoch 416/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4837 - accuracy: 0.4443 - val_loss: 1.6331 - val_accuracy: 0.3767\n",
      "Epoch 417/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.4829 - accuracy: 0.4443 - val_loss: 1.6326 - val_accuracy: 0.3767\n",
      "Epoch 418/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.4820 - accuracy: 0.4471 - val_loss: 1.6322 - val_accuracy: 0.3767\n",
      "Epoch 419/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4813 - accuracy: 0.4443 - val_loss: 1.6317 - val_accuracy: 0.3800\n",
      "Epoch 420/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4804 - accuracy: 0.4486 - val_loss: 1.6313 - val_accuracy: 0.3800\n",
      "Epoch 421/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4795 - accuracy: 0.4500 - val_loss: 1.6307 - val_accuracy: 0.3800\n",
      "Epoch 422/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.4788 - accuracy: 0.4471 - val_loss: 1.6302 - val_accuracy: 0.3833\n",
      "Epoch 423/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4779 - accuracy: 0.4471 - val_loss: 1.6298 - val_accuracy: 0.3833\n",
      "Epoch 424/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4771 - accuracy: 0.4514 - val_loss: 1.6291 - val_accuracy: 0.3833\n",
      "Epoch 425/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.4764 - accuracy: 0.4486 - val_loss: 1.6287 - val_accuracy: 0.3833\n",
      "Epoch 426/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4754 - accuracy: 0.4529 - val_loss: 1.6280 - val_accuracy: 0.3833\n",
      "Epoch 427/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4747 - accuracy: 0.4486 - val_loss: 1.6277 - val_accuracy: 0.3833\n",
      "Epoch 428/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4739 - accuracy: 0.4514 - val_loss: 1.6273 - val_accuracy: 0.3833\n",
      "Epoch 429/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.4730 - accuracy: 0.4514 - val_loss: 1.6270 - val_accuracy: 0.3833\n",
      "Epoch 430/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.4723 - accuracy: 0.4500 - val_loss: 1.6265 - val_accuracy: 0.3833\n",
      "Epoch 431/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4716 - accuracy: 0.4486 - val_loss: 1.6259 - val_accuracy: 0.3833\n",
      "Epoch 432/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4707 - accuracy: 0.4543 - val_loss: 1.6252 - val_accuracy: 0.3833\n",
      "Epoch 433/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4699 - accuracy: 0.4543 - val_loss: 1.6246 - val_accuracy: 0.3833\n",
      "Epoch 434/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.4692 - accuracy: 0.4500 - val_loss: 1.6243 - val_accuracy: 0.3833\n",
      "Epoch 435/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.4683 - accuracy: 0.4557 - val_loss: 1.6240 - val_accuracy: 0.3833\n",
      "Epoch 436/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4675 - accuracy: 0.4529 - val_loss: 1.6234 - val_accuracy: 0.3833\n",
      "Epoch 437/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.4667 - accuracy: 0.4514 - val_loss: 1.6229 - val_accuracy: 0.3833\n",
      "Epoch 438/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.4659 - accuracy: 0.4543 - val_loss: 1.6224 - val_accuracy: 0.3833\n",
      "Epoch 439/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.4652 - accuracy: 0.4586 - val_loss: 1.6223 - val_accuracy: 0.3833\n",
      "Epoch 440/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4644 - accuracy: 0.4586 - val_loss: 1.6218 - val_accuracy: 0.3833\n",
      "Epoch 441/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4636 - accuracy: 0.4571 - val_loss: 1.6214 - val_accuracy: 0.3833\n",
      "Epoch 442/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.4626 - accuracy: 0.4600 - val_loss: 1.6213 - val_accuracy: 0.3833\n",
      "Epoch 443/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4620 - accuracy: 0.4586 - val_loss: 1.6206 - val_accuracy: 0.3833\n",
      "Epoch 444/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4613 - accuracy: 0.4586 - val_loss: 1.6203 - val_accuracy: 0.3833\n",
      "Epoch 445/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.4604 - accuracy: 0.4629 - val_loss: 1.6198 - val_accuracy: 0.3833\n",
      "Epoch 446/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.4596 - accuracy: 0.4629 - val_loss: 1.6191 - val_accuracy: 0.3800\n",
      "Epoch 447/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4589 - accuracy: 0.4643 - val_loss: 1.6188 - val_accuracy: 0.3800\n",
      "Epoch 448/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.4582 - accuracy: 0.4600 - val_loss: 1.6185 - val_accuracy: 0.3800\n",
      "Epoch 449/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.4574 - accuracy: 0.4614 - val_loss: 1.6180 - val_accuracy: 0.3800\n",
      "Epoch 450/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4565 - accuracy: 0.4600 - val_loss: 1.6179 - val_accuracy: 0.3800\n",
      "Epoch 451/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.4558 - accuracy: 0.4657 - val_loss: 1.6171 - val_accuracy: 0.3833\n",
      "Epoch 452/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4550 - accuracy: 0.4643 - val_loss: 1.6166 - val_accuracy: 0.3833\n",
      "Epoch 453/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4543 - accuracy: 0.4643 - val_loss: 1.6163 - val_accuracy: 0.3833\n",
      "Epoch 454/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.4535 - accuracy: 0.4643 - val_loss: 1.6159 - val_accuracy: 0.3833\n",
      "Epoch 455/1000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.4528 - accuracy: 0.4614 - val_loss: 1.6155 - val_accuracy: 0.3833\n",
      "Epoch 456/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.4521 - accuracy: 0.4657 - val_loss: 1.6150 - val_accuracy: 0.3833\n",
      "Epoch 457/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.4513 - accuracy: 0.4671 - val_loss: 1.6147 - val_accuracy: 0.3833\n",
      "Epoch 458/1000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.4506 - accuracy: 0.4671 - val_loss: 1.6141 - val_accuracy: 0.3867\n",
      "Epoch 459/1000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.4497 - accuracy: 0.4686 - val_loss: 1.6137 - val_accuracy: 0.3867\n",
      "Epoch 460/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.4491 - accuracy: 0.4671 - val_loss: 1.6134 - val_accuracy: 0.3867\n",
      "Epoch 461/1000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.4483 - accuracy: 0.4686 - val_loss: 1.6128 - val_accuracy: 0.3867\n",
      "Epoch 462/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.4476 - accuracy: 0.4671 - val_loss: 1.6125 - val_accuracy: 0.3833\n",
      "Epoch 463/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.4468 - accuracy: 0.4686 - val_loss: 1.6120 - val_accuracy: 0.3833\n",
      "Epoch 464/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.4461 - accuracy: 0.4686 - val_loss: 1.6118 - val_accuracy: 0.3867\n",
      "Epoch 465/1000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.4453 - accuracy: 0.4729 - val_loss: 1.6114 - val_accuracy: 0.3867\n",
      "Epoch 466/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.4445 - accuracy: 0.4686 - val_loss: 1.6110 - val_accuracy: 0.3867\n",
      "Epoch 467/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.4438 - accuracy: 0.4700 - val_loss: 1.6104 - val_accuracy: 0.3867\n",
      "Epoch 468/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.4431 - accuracy: 0.4700 - val_loss: 1.6105 - val_accuracy: 0.3867\n",
      "Epoch 469/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.4423 - accuracy: 0.4700 - val_loss: 1.6104 - val_accuracy: 0.3867\n",
      "Epoch 470/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.4417 - accuracy: 0.4729 - val_loss: 1.6098 - val_accuracy: 0.3867\n",
      "Epoch 471/1000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.4409 - accuracy: 0.4729 - val_loss: 1.6090 - val_accuracy: 0.3867\n",
      "Epoch 472/1000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.4401 - accuracy: 0.4686 - val_loss: 1.6088 - val_accuracy: 0.3900\n",
      "Epoch 473/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.4394 - accuracy: 0.4700 - val_loss: 1.6085 - val_accuracy: 0.3900\n",
      "Epoch 474/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.4387 - accuracy: 0.4743 - val_loss: 1.6082 - val_accuracy: 0.3967\n",
      "Epoch 475/1000\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 1.4380 - accuracy: 0.4729 - val_loss: 1.6078 - val_accuracy: 0.3967\n",
      "Epoch 476/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4373 - accuracy: 0.4729 - val_loss: 1.6071 - val_accuracy: 0.3933\n",
      "Epoch 477/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4365 - accuracy: 0.4729 - val_loss: 1.6070 - val_accuracy: 0.3967\n",
      "Epoch 478/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.4357 - accuracy: 0.4729 - val_loss: 1.6067 - val_accuracy: 0.3933\n",
      "Epoch 479/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.4350 - accuracy: 0.4729 - val_loss: 1.6062 - val_accuracy: 0.3967\n",
      "Epoch 480/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.4344 - accuracy: 0.4771 - val_loss: 1.6059 - val_accuracy: 0.3967\n",
      "Epoch 481/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.4336 - accuracy: 0.4786 - val_loss: 1.6056 - val_accuracy: 0.3967\n",
      "Epoch 482/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4329 - accuracy: 0.4786 - val_loss: 1.6049 - val_accuracy: 0.4000\n",
      "Epoch 483/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4322 - accuracy: 0.4786 - val_loss: 1.6046 - val_accuracy: 0.4000\n",
      "Epoch 484/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.4315 - accuracy: 0.4800 - val_loss: 1.6045 - val_accuracy: 0.3967\n",
      "Epoch 485/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.4307 - accuracy: 0.4800 - val_loss: 1.6042 - val_accuracy: 0.3967\n",
      "Epoch 486/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.4301 - accuracy: 0.4814 - val_loss: 1.6036 - val_accuracy: 0.3967\n",
      "Epoch 487/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4293 - accuracy: 0.4829 - val_loss: 1.6034 - val_accuracy: 0.3967\n",
      "Epoch 488/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4287 - accuracy: 0.4800 - val_loss: 1.6029 - val_accuracy: 0.4000\n",
      "Epoch 489/1000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.4280 - accuracy: 0.4814 - val_loss: 1.6025 - val_accuracy: 0.4000\n",
      "Epoch 490/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.4271 - accuracy: 0.4829 - val_loss: 1.6022 - val_accuracy: 0.4000\n",
      "Epoch 491/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4265 - accuracy: 0.4829 - val_loss: 1.6019 - val_accuracy: 0.4000\n",
      "Epoch 492/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4258 - accuracy: 0.4829 - val_loss: 1.6015 - val_accuracy: 0.4000\n",
      "Epoch 493/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4251 - accuracy: 0.4814 - val_loss: 1.6009 - val_accuracy: 0.4033\n",
      "Epoch 494/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.4243 - accuracy: 0.4829 - val_loss: 1.6004 - val_accuracy: 0.4033\n",
      "Epoch 495/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.4237 - accuracy: 0.4857 - val_loss: 1.6004 - val_accuracy: 0.4033\n",
      "Epoch 496/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.4229 - accuracy: 0.4843 - val_loss: 1.6003 - val_accuracy: 0.4033\n",
      "Epoch 497/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.4222 - accuracy: 0.4871 - val_loss: 1.5999 - val_accuracy: 0.4033\n",
      "Epoch 498/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.4216 - accuracy: 0.4857 - val_loss: 1.5995 - val_accuracy: 0.4033\n",
      "Epoch 499/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.4209 - accuracy: 0.4871 - val_loss: 1.5991 - val_accuracy: 0.4033\n",
      "Epoch 500/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.4201 - accuracy: 0.4871 - val_loss: 1.5989 - val_accuracy: 0.4033\n",
      "Epoch 501/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4194 - accuracy: 0.4886 - val_loss: 1.5984 - val_accuracy: 0.4033\n",
      "Epoch 502/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4187 - accuracy: 0.4871 - val_loss: 1.5982 - val_accuracy: 0.4033\n",
      "Epoch 503/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.4181 - accuracy: 0.4871 - val_loss: 1.5978 - val_accuracy: 0.4033\n",
      "Epoch 504/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4175 - accuracy: 0.4900 - val_loss: 1.5975 - val_accuracy: 0.4033\n",
      "Epoch 505/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.4168 - accuracy: 0.4900 - val_loss: 1.5970 - val_accuracy: 0.4033\n",
      "Epoch 506/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4160 - accuracy: 0.4929 - val_loss: 1.5970 - val_accuracy: 0.4033\n",
      "Epoch 507/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.4154 - accuracy: 0.4929 - val_loss: 1.5963 - val_accuracy: 0.4033\n",
      "Epoch 508/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.4147 - accuracy: 0.4900 - val_loss: 1.5961 - val_accuracy: 0.4033\n",
      "Epoch 509/1000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.4140 - accuracy: 0.4929 - val_loss: 1.5958 - val_accuracy: 0.4033\n",
      "Epoch 510/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4134 - accuracy: 0.4943 - val_loss: 1.5957 - val_accuracy: 0.4033\n",
      "Epoch 511/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.4126 - accuracy: 0.4943 - val_loss: 1.5950 - val_accuracy: 0.4033\n",
      "Epoch 512/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.4120 - accuracy: 0.4943 - val_loss: 1.5947 - val_accuracy: 0.4067\n",
      "Epoch 513/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.4113 - accuracy: 0.4971 - val_loss: 1.5943 - val_accuracy: 0.4067\n",
      "Epoch 514/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.4106 - accuracy: 0.4943 - val_loss: 1.5940 - val_accuracy: 0.4067\n",
      "Epoch 515/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.4100 - accuracy: 0.4986 - val_loss: 1.5937 - val_accuracy: 0.4067\n",
      "Epoch 516/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.4093 - accuracy: 0.4943 - val_loss: 1.5932 - val_accuracy: 0.4067\n",
      "Epoch 517/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.4086 - accuracy: 0.4986 - val_loss: 1.5931 - val_accuracy: 0.4067\n",
      "Epoch 518/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.4079 - accuracy: 0.5014 - val_loss: 1.5924 - val_accuracy: 0.4067\n",
      "Epoch 519/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.4073 - accuracy: 0.5000 - val_loss: 1.5922 - val_accuracy: 0.4067\n",
      "Epoch 520/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.4067 - accuracy: 0.5029 - val_loss: 1.5920 - val_accuracy: 0.4067\n",
      "Epoch 521/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.4060 - accuracy: 0.4986 - val_loss: 1.5916 - val_accuracy: 0.4067\n",
      "Epoch 522/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.4053 - accuracy: 0.5014 - val_loss: 1.5912 - val_accuracy: 0.4067\n",
      "Epoch 523/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.4047 - accuracy: 0.4986 - val_loss: 1.5912 - val_accuracy: 0.4067\n",
      "Epoch 524/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.4042 - accuracy: 0.5029 - val_loss: 1.5910 - val_accuracy: 0.4033\n",
      "Epoch 525/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.4033 - accuracy: 0.5014 - val_loss: 1.5908 - val_accuracy: 0.4033\n",
      "Epoch 526/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.4027 - accuracy: 0.5014 - val_loss: 1.5904 - val_accuracy: 0.4033\n",
      "Epoch 527/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.4021 - accuracy: 0.5014 - val_loss: 1.5898 - val_accuracy: 0.4067\n",
      "Epoch 528/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4014 - accuracy: 0.5071 - val_loss: 1.5894 - val_accuracy: 0.4067\n",
      "Epoch 529/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.4007 - accuracy: 0.5029 - val_loss: 1.5891 - val_accuracy: 0.4067\n",
      "Epoch 530/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.4001 - accuracy: 0.5043 - val_loss: 1.5886 - val_accuracy: 0.4067\n",
      "Epoch 531/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.3995 - accuracy: 0.5000 - val_loss: 1.5887 - val_accuracy: 0.4033\n",
      "Epoch 532/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3989 - accuracy: 0.5043 - val_loss: 1.5881 - val_accuracy: 0.4067\n",
      "Epoch 533/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3982 - accuracy: 0.5029 - val_loss: 1.5878 - val_accuracy: 0.4067\n",
      "Epoch 534/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.3975 - accuracy: 0.5029 - val_loss: 1.5874 - val_accuracy: 0.4033\n",
      "Epoch 535/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3968 - accuracy: 0.5029 - val_loss: 1.5872 - val_accuracy: 0.4033\n",
      "Epoch 536/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.3962 - accuracy: 0.5014 - val_loss: 1.5873 - val_accuracy: 0.4000\n",
      "Epoch 537/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.3956 - accuracy: 0.5057 - val_loss: 1.5870 - val_accuracy: 0.4000\n",
      "Epoch 538/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.3950 - accuracy: 0.5014 - val_loss: 1.5865 - val_accuracy: 0.4000\n",
      "Epoch 539/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3944 - accuracy: 0.5029 - val_loss: 1.5861 - val_accuracy: 0.4000\n",
      "Epoch 540/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.3937 - accuracy: 0.5071 - val_loss: 1.5859 - val_accuracy: 0.4000\n",
      "Epoch 541/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.3930 - accuracy: 0.5043 - val_loss: 1.5852 - val_accuracy: 0.4033\n",
      "Epoch 542/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3925 - accuracy: 0.5043 - val_loss: 1.5849 - val_accuracy: 0.4033\n",
      "Epoch 543/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.3918 - accuracy: 0.5000 - val_loss: 1.5849 - val_accuracy: 0.4000\n",
      "Epoch 544/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3912 - accuracy: 0.5014 - val_loss: 1.5842 - val_accuracy: 0.4033\n",
      "Epoch 545/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.3905 - accuracy: 0.5043 - val_loss: 1.5843 - val_accuracy: 0.4033\n",
      "Epoch 546/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3900 - accuracy: 0.5014 - val_loss: 1.5840 - val_accuracy: 0.4033\n",
      "Epoch 547/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3893 - accuracy: 0.5014 - val_loss: 1.5836 - val_accuracy: 0.4033\n",
      "Epoch 548/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.3887 - accuracy: 0.5029 - val_loss: 1.5835 - val_accuracy: 0.4033\n",
      "Epoch 549/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3880 - accuracy: 0.5029 - val_loss: 1.5830 - val_accuracy: 0.4033\n",
      "Epoch 550/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.3875 - accuracy: 0.5029 - val_loss: 1.5826 - val_accuracy: 0.4033\n",
      "Epoch 551/1000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 1.3868 - accuracy: 0.5014 - val_loss: 1.5825 - val_accuracy: 0.4033\n",
      "Epoch 552/1000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.3863 - accuracy: 0.5057 - val_loss: 1.5821 - val_accuracy: 0.4033\n",
      "Epoch 553/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.3856 - accuracy: 0.5043 - val_loss: 1.5820 - val_accuracy: 0.4033\n",
      "Epoch 554/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3850 - accuracy: 0.5043 - val_loss: 1.5815 - val_accuracy: 0.4067\n",
      "Epoch 555/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3844 - accuracy: 0.5057 - val_loss: 1.5813 - val_accuracy: 0.4067\n",
      "Epoch 556/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3838 - accuracy: 0.5043 - val_loss: 1.5809 - val_accuracy: 0.4033\n",
      "Epoch 557/1000\n",
      "700/700 [==============================] - 0s 107us/sample - loss: 1.3832 - accuracy: 0.5029 - val_loss: 1.5810 - val_accuracy: 0.4033\n",
      "Epoch 558/1000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.3825 - accuracy: 0.5043 - val_loss: 1.5804 - val_accuracy: 0.4033\n",
      "Epoch 559/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.3819 - accuracy: 0.5043 - val_loss: 1.5799 - val_accuracy: 0.4033\n",
      "Epoch 560/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.3814 - accuracy: 0.5043 - val_loss: 1.5799 - val_accuracy: 0.4033\n",
      "Epoch 561/1000\n",
      "700/700 [==============================] - 0s 88us/sample - loss: 1.3807 - accuracy: 0.5043 - val_loss: 1.5794 - val_accuracy: 0.4067\n",
      "Epoch 562/1000\n",
      "700/700 [==============================] - 0s 97us/sample - loss: 1.3801 - accuracy: 0.5057 - val_loss: 1.5793 - val_accuracy: 0.4033\n",
      "Epoch 563/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.3795 - accuracy: 0.5043 - val_loss: 1.5788 - val_accuracy: 0.4033\n",
      "Epoch 564/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3790 - accuracy: 0.5057 - val_loss: 1.5785 - val_accuracy: 0.4033\n",
      "Epoch 565/1000\n",
      "700/700 [==============================] - 0s 85us/sample - loss: 1.3784 - accuracy: 0.5043 - val_loss: 1.5784 - val_accuracy: 0.4067\n",
      "Epoch 566/1000\n",
      "700/700 [==============================] - 0s 91us/sample - loss: 1.3777 - accuracy: 0.5057 - val_loss: 1.5779 - val_accuracy: 0.4033\n",
      "Epoch 567/1000\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 1.3772 - accuracy: 0.5057 - val_loss: 1.5779 - val_accuracy: 0.4067\n",
      "Epoch 568/1000\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 1.3765 - accuracy: 0.5057 - val_loss: 1.5775 - val_accuracy: 0.4067\n",
      "Epoch 569/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.3759 - accuracy: 0.5057 - val_loss: 1.5769 - val_accuracy: 0.4033\n",
      "Epoch 570/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.3754 - accuracy: 0.5043 - val_loss: 1.5769 - val_accuracy: 0.4033\n",
      "Epoch 571/1000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 1.3749 - accuracy: 0.5029 - val_loss: 1.5769 - val_accuracy: 0.4067\n",
      "Epoch 572/1000\n",
      "700/700 [==============================] - 0s 87us/sample - loss: 1.3742 - accuracy: 0.5029 - val_loss: 1.5765 - val_accuracy: 0.4067\n",
      "Epoch 573/1000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.3735 - accuracy: 0.5043 - val_loss: 1.5762 - val_accuracy: 0.4067\n",
      "Epoch 574/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3730 - accuracy: 0.5057 - val_loss: 1.5759 - val_accuracy: 0.4033\n",
      "Epoch 575/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3725 - accuracy: 0.5043 - val_loss: 1.5754 - val_accuracy: 0.4000\n",
      "Epoch 576/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.3718 - accuracy: 0.5043 - val_loss: 1.5755 - val_accuracy: 0.4067\n",
      "Epoch 577/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.3712 - accuracy: 0.5043 - val_loss: 1.5752 - val_accuracy: 0.4067\n",
      "Epoch 578/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3706 - accuracy: 0.5057 - val_loss: 1.5751 - val_accuracy: 0.4033\n",
      "Epoch 579/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.3701 - accuracy: 0.5043 - val_loss: 1.5745 - val_accuracy: 0.4033\n",
      "Epoch 580/1000\n",
      "700/700 [==============================] - 0s 89us/sample - loss: 1.3695 - accuracy: 0.5057 - val_loss: 1.5741 - val_accuracy: 0.4000\n",
      "Epoch 581/1000\n",
      "700/700 [==============================] - 0s 87us/sample - loss: 1.3689 - accuracy: 0.5086 - val_loss: 1.5736 - val_accuracy: 0.4033\n",
      "Epoch 582/1000\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 1.3683 - accuracy: 0.5057 - val_loss: 1.5735 - val_accuracy: 0.4033\n",
      "Epoch 583/1000\n",
      "700/700 [==============================] - 0s 87us/sample - loss: 1.3677 - accuracy: 0.5029 - val_loss: 1.5736 - val_accuracy: 0.4000\n",
      "Epoch 584/1000\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 1.3672 - accuracy: 0.5043 - val_loss: 1.5736 - val_accuracy: 0.4033\n",
      "Epoch 585/1000\n",
      "700/700 [==============================] - 0s 87us/sample - loss: 1.3666 - accuracy: 0.5071 - val_loss: 1.5732 - val_accuracy: 0.4067\n",
      "Epoch 586/1000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 1.3660 - accuracy: 0.5086 - val_loss: 1.5732 - val_accuracy: 0.4067\n",
      "Epoch 587/1000\n",
      "700/700 [==============================] - 0s 85us/sample - loss: 1.3654 - accuracy: 0.5057 - val_loss: 1.5728 - val_accuracy: 0.4067\n",
      "Epoch 588/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.3649 - accuracy: 0.5100 - val_loss: 1.5724 - val_accuracy: 0.4067\n",
      "Epoch 589/1000\n",
      "700/700 [==============================] - 0s 91us/sample - loss: 1.3644 - accuracy: 0.5100 - val_loss: 1.5722 - val_accuracy: 0.4033\n",
      "Epoch 590/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.3638 - accuracy: 0.5086 - val_loss: 1.5718 - val_accuracy: 0.4000\n",
      "Epoch 591/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.3632 - accuracy: 0.5071 - val_loss: 1.5716 - val_accuracy: 0.4000\n",
      "Epoch 592/1000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 1.3626 - accuracy: 0.5086 - val_loss: 1.5714 - val_accuracy: 0.4000\n",
      "Epoch 593/1000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.3621 - accuracy: 0.5086 - val_loss: 1.5714 - val_accuracy: 0.4033\n",
      "Epoch 594/1000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 1.3615 - accuracy: 0.5100 - val_loss: 1.5706 - val_accuracy: 0.4000\n",
      "Epoch 595/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.3610 - accuracy: 0.5086 - val_loss: 1.5706 - val_accuracy: 0.4000\n",
      "Epoch 596/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.3603 - accuracy: 0.5086 - val_loss: 1.5709 - val_accuracy: 0.4033\n",
      "Epoch 597/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.3599 - accuracy: 0.5129 - val_loss: 1.5704 - val_accuracy: 0.4033\n",
      "Epoch 598/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.3594 - accuracy: 0.5071 - val_loss: 1.5702 - val_accuracy: 0.4033\n",
      "Epoch 599/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.3586 - accuracy: 0.5157 - val_loss: 1.5697 - val_accuracy: 0.4000\n",
      "Epoch 600/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.3582 - accuracy: 0.5100 - val_loss: 1.5698 - val_accuracy: 0.4033\n",
      "Epoch 601/1000\n",
      "700/700 [==============================] - 0s 92us/sample - loss: 1.3576 - accuracy: 0.5086 - val_loss: 1.5696 - val_accuracy: 0.4033\n",
      "Epoch 602/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.3570 - accuracy: 0.5086 - val_loss: 1.5698 - val_accuracy: 0.4033\n",
      "Epoch 603/1000\n",
      "700/700 [==============================] - 0s 85us/sample - loss: 1.3565 - accuracy: 0.5100 - val_loss: 1.5692 - val_accuracy: 0.4067\n",
      "Epoch 604/1000\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 1.3560 - accuracy: 0.5143 - val_loss: 1.5688 - val_accuracy: 0.4033\n",
      "Epoch 605/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.3554 - accuracy: 0.5114 - val_loss: 1.5684 - val_accuracy: 0.4033\n",
      "Epoch 606/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.3548 - accuracy: 0.5129 - val_loss: 1.5680 - val_accuracy: 0.4033\n",
      "Epoch 607/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.3543 - accuracy: 0.5114 - val_loss: 1.5683 - val_accuracy: 0.4067\n",
      "Epoch 608/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.3537 - accuracy: 0.5100 - val_loss: 1.5676 - val_accuracy: 0.4033\n",
      "Epoch 609/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.3532 - accuracy: 0.5100 - val_loss: 1.5676 - val_accuracy: 0.4033\n",
      "Epoch 610/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3527 - accuracy: 0.5114 - val_loss: 1.5673 - val_accuracy: 0.4033\n",
      "Epoch 611/1000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 1.3521 - accuracy: 0.5100 - val_loss: 1.5674 - val_accuracy: 0.4067\n",
      "Epoch 612/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.3516 - accuracy: 0.5143 - val_loss: 1.5669 - val_accuracy: 0.4000\n",
      "Epoch 613/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.3510 - accuracy: 0.5143 - val_loss: 1.5665 - val_accuracy: 0.4000\n",
      "Epoch 614/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3505 - accuracy: 0.5129 - val_loss: 1.5661 - val_accuracy: 0.4000\n",
      "Epoch 615/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3500 - accuracy: 0.5100 - val_loss: 1.5657 - val_accuracy: 0.4033\n",
      "Epoch 616/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.3494 - accuracy: 0.5143 - val_loss: 1.5659 - val_accuracy: 0.4033\n",
      "Epoch 617/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.3488 - accuracy: 0.5114 - val_loss: 1.5656 - val_accuracy: 0.4033\n",
      "Epoch 618/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3483 - accuracy: 0.5100 - val_loss: 1.5655 - val_accuracy: 0.4067\n",
      "Epoch 619/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.3478 - accuracy: 0.5100 - val_loss: 1.5652 - val_accuracy: 0.4033\n",
      "Epoch 620/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.3472 - accuracy: 0.5143 - val_loss: 1.5650 - val_accuracy: 0.4033\n",
      "Epoch 621/1000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 1.3468 - accuracy: 0.5129 - val_loss: 1.5651 - val_accuracy: 0.4033\n",
      "Epoch 622/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.3461 - accuracy: 0.5129 - val_loss: 1.5641 - val_accuracy: 0.4033\n",
      "Epoch 623/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.3457 - accuracy: 0.5129 - val_loss: 1.5640 - val_accuracy: 0.4033\n",
      "Epoch 624/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3451 - accuracy: 0.5143 - val_loss: 1.5639 - val_accuracy: 0.4033\n",
      "Epoch 625/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.3447 - accuracy: 0.5129 - val_loss: 1.5638 - val_accuracy: 0.4033\n",
      "Epoch 626/1000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 1.3441 - accuracy: 0.5143 - val_loss: 1.5638 - val_accuracy: 0.4033\n",
      "Epoch 627/1000\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 1.3435 - accuracy: 0.5100 - val_loss: 1.5638 - val_accuracy: 0.4033\n",
      "Epoch 628/1000\n",
      "700/700 [==============================] - 0s 105us/sample - loss: 1.3431 - accuracy: 0.5129 - val_loss: 1.5637 - val_accuracy: 0.4067\n",
      "Epoch 629/1000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.3426 - accuracy: 0.5114 - val_loss: 1.5632 - val_accuracy: 0.4033\n",
      "Epoch 630/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.3420 - accuracy: 0.5129 - val_loss: 1.5628 - val_accuracy: 0.4033\n",
      "Epoch 631/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.3415 - accuracy: 0.5129 - val_loss: 1.5627 - val_accuracy: 0.4033\n",
      "Epoch 632/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.3410 - accuracy: 0.5100 - val_loss: 1.5625 - val_accuracy: 0.4033\n",
      "Epoch 633/1000\n",
      "700/700 [==============================] - 0s 91us/sample - loss: 1.3405 - accuracy: 0.5114 - val_loss: 1.5625 - val_accuracy: 0.4033\n",
      "Epoch 634/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.3400 - accuracy: 0.5100 - val_loss: 1.5623 - val_accuracy: 0.4033\n",
      "Epoch 635/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3394 - accuracy: 0.5129 - val_loss: 1.5617 - val_accuracy: 0.4033\n",
      "Epoch 636/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.3390 - accuracy: 0.5114 - val_loss: 1.5616 - val_accuracy: 0.4033\n",
      "Epoch 637/1000\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 1.3384 - accuracy: 0.5114 - val_loss: 1.5620 - val_accuracy: 0.4033\n",
      "Epoch 638/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.3379 - accuracy: 0.5114 - val_loss: 1.5614 - val_accuracy: 0.4033\n",
      "Epoch 639/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3373 - accuracy: 0.5114 - val_loss: 1.5612 - val_accuracy: 0.4033\n",
      "Epoch 640/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3369 - accuracy: 0.5114 - val_loss: 1.5607 - val_accuracy: 0.4033\n",
      "Epoch 641/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3364 - accuracy: 0.5114 - val_loss: 1.5608 - val_accuracy: 0.4033\n",
      "Epoch 642/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.3358 - accuracy: 0.5114 - val_loss: 1.5608 - val_accuracy: 0.4033\n",
      "Epoch 643/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3353 - accuracy: 0.5100 - val_loss: 1.5608 - val_accuracy: 0.4033\n",
      "Epoch 644/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.3349 - accuracy: 0.5114 - val_loss: 1.5603 - val_accuracy: 0.4033\n",
      "Epoch 645/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3342 - accuracy: 0.5114 - val_loss: 1.5605 - val_accuracy: 0.4033\n",
      "Epoch 646/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.3338 - accuracy: 0.5129 - val_loss: 1.5600 - val_accuracy: 0.4033\n",
      "Epoch 647/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.3333 - accuracy: 0.5129 - val_loss: 1.5599 - val_accuracy: 0.4033\n",
      "Epoch 648/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.3328 - accuracy: 0.5129 - val_loss: 1.5594 - val_accuracy: 0.4033\n",
      "Epoch 649/1000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.3322 - accuracy: 0.5114 - val_loss: 1.5594 - val_accuracy: 0.4033\n",
      "Epoch 650/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.3318 - accuracy: 0.5100 - val_loss: 1.5592 - val_accuracy: 0.4033\n",
      "Epoch 651/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.3312 - accuracy: 0.5100 - val_loss: 1.5584 - val_accuracy: 0.4033\n",
      "Epoch 652/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.3309 - accuracy: 0.5114 - val_loss: 1.5585 - val_accuracy: 0.4033\n",
      "Epoch 653/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.3302 - accuracy: 0.5086 - val_loss: 1.5587 - val_accuracy: 0.4000\n",
      "Epoch 654/1000\n",
      "700/700 [==============================] - 0s 85us/sample - loss: 1.3298 - accuracy: 0.5100 - val_loss: 1.5582 - val_accuracy: 0.4000\n",
      "Epoch 655/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.3294 - accuracy: 0.5100 - val_loss: 1.5579 - val_accuracy: 0.4000\n",
      "Epoch 656/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.3288 - accuracy: 0.5100 - val_loss: 1.5579 - val_accuracy: 0.4033\n",
      "Epoch 657/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.3283 - accuracy: 0.5129 - val_loss: 1.5575 - val_accuracy: 0.4033\n",
      "Epoch 658/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.3279 - accuracy: 0.5114 - val_loss: 1.5573 - val_accuracy: 0.4033\n",
      "Epoch 659/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3272 - accuracy: 0.5129 - val_loss: 1.5568 - val_accuracy: 0.4033\n",
      "Epoch 660/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3269 - accuracy: 0.5100 - val_loss: 1.5575 - val_accuracy: 0.4033\n",
      "Epoch 661/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.3263 - accuracy: 0.5143 - val_loss: 1.5568 - val_accuracy: 0.4033\n",
      "Epoch 662/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3259 - accuracy: 0.5100 - val_loss: 1.5569 - val_accuracy: 0.4033\n",
      "Epoch 663/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3254 - accuracy: 0.5114 - val_loss: 1.5567 - val_accuracy: 0.4033\n",
      "Epoch 664/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.3250 - accuracy: 0.5129 - val_loss: 1.5565 - val_accuracy: 0.4033\n",
      "Epoch 665/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.3244 - accuracy: 0.5114 - val_loss: 1.5558 - val_accuracy: 0.4033\n",
      "Epoch 666/1000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.3239 - accuracy: 0.5086 - val_loss: 1.5559 - val_accuracy: 0.4000\n",
      "Epoch 667/1000\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 1.3234 - accuracy: 0.5114 - val_loss: 1.5558 - val_accuracy: 0.4033\n",
      "Epoch 668/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.3228 - accuracy: 0.5143 - val_loss: 1.5560 - val_accuracy: 0.4033\n",
      "Epoch 669/1000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.3225 - accuracy: 0.5114 - val_loss: 1.5557 - val_accuracy: 0.4033\n",
      "Epoch 670/1000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 1.3220 - accuracy: 0.5143 - val_loss: 1.5551 - val_accuracy: 0.4033\n",
      "Epoch 671/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.3215 - accuracy: 0.5129 - val_loss: 1.5551 - val_accuracy: 0.4033\n",
      "Epoch 672/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3209 - accuracy: 0.5100 - val_loss: 1.5553 - val_accuracy: 0.4000\n",
      "Epoch 673/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3205 - accuracy: 0.5100 - val_loss: 1.5547 - val_accuracy: 0.4000\n",
      "Epoch 674/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3200 - accuracy: 0.5114 - val_loss: 1.5547 - val_accuracy: 0.4000\n",
      "Epoch 675/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3195 - accuracy: 0.5086 - val_loss: 1.5548 - val_accuracy: 0.4000\n",
      "Epoch 676/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.3191 - accuracy: 0.5143 - val_loss: 1.5543 - val_accuracy: 0.4000\n",
      "Epoch 677/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.3186 - accuracy: 0.5129 - val_loss: 1.5536 - val_accuracy: 0.4000\n",
      "Epoch 678/1000\n",
      "700/700 [==============================] - 0s 104us/sample - loss: 1.3181 - accuracy: 0.5129 - val_loss: 1.5538 - val_accuracy: 0.4000\n",
      "Epoch 679/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.3177 - accuracy: 0.5100 - val_loss: 1.5539 - val_accuracy: 0.4000\n",
      "Epoch 680/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.3172 - accuracy: 0.5100 - val_loss: 1.5537 - val_accuracy: 0.4000\n",
      "Epoch 681/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.3167 - accuracy: 0.5157 - val_loss: 1.5531 - val_accuracy: 0.4000\n",
      "Epoch 682/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.3162 - accuracy: 0.5143 - val_loss: 1.5531 - val_accuracy: 0.4000\n",
      "Epoch 683/1000\n",
      "700/700 [==============================] - 0s 85us/sample - loss: 1.3157 - accuracy: 0.5129 - val_loss: 1.5530 - val_accuracy: 0.4000\n",
      "Epoch 684/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.3153 - accuracy: 0.5143 - val_loss: 1.5529 - val_accuracy: 0.4000\n",
      "Epoch 685/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3148 - accuracy: 0.5129 - val_loss: 1.5524 - val_accuracy: 0.4000\n",
      "Epoch 686/1000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.3143 - accuracy: 0.5129 - val_loss: 1.5522 - val_accuracy: 0.4000\n",
      "Epoch 687/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.3139 - accuracy: 0.5157 - val_loss: 1.5524 - val_accuracy: 0.4000\n",
      "Epoch 688/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3134 - accuracy: 0.5143 - val_loss: 1.5520 - val_accuracy: 0.4000\n",
      "Epoch 689/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.3130 - accuracy: 0.5143 - val_loss: 1.5516 - val_accuracy: 0.4000\n",
      "Epoch 690/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.3125 - accuracy: 0.5143 - val_loss: 1.5518 - val_accuracy: 0.4000\n",
      "Epoch 691/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.3120 - accuracy: 0.5129 - val_loss: 1.5515 - val_accuracy: 0.4000\n",
      "Epoch 692/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.3116 - accuracy: 0.5143 - val_loss: 1.5513 - val_accuracy: 0.4033\n",
      "Epoch 693/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.3111 - accuracy: 0.5157 - val_loss: 1.5506 - val_accuracy: 0.4033\n",
      "Epoch 694/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3106 - accuracy: 0.5129 - val_loss: 1.5506 - val_accuracy: 0.4033\n",
      "Epoch 695/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.3102 - accuracy: 0.5129 - val_loss: 1.5508 - val_accuracy: 0.4033\n",
      "Epoch 696/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.3097 - accuracy: 0.5129 - val_loss: 1.5505 - val_accuracy: 0.4033\n",
      "Epoch 697/1000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 1.3092 - accuracy: 0.5114 - val_loss: 1.5504 - val_accuracy: 0.4033\n",
      "Epoch 698/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.3087 - accuracy: 0.5129 - val_loss: 1.5503 - val_accuracy: 0.4033\n",
      "Epoch 699/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3083 - accuracy: 0.5143 - val_loss: 1.5505 - val_accuracy: 0.4033\n",
      "Epoch 700/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3080 - accuracy: 0.5114 - val_loss: 1.5500 - val_accuracy: 0.4033\n",
      "Epoch 701/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3074 - accuracy: 0.5129 - val_loss: 1.5502 - val_accuracy: 0.4033\n",
      "Epoch 702/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3070 - accuracy: 0.5157 - val_loss: 1.5497 - val_accuracy: 0.4033\n",
      "Epoch 703/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.3063 - accuracy: 0.5157 - val_loss: 1.5500 - val_accuracy: 0.4033\n",
      "Epoch 704/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.3060 - accuracy: 0.5143 - val_loss: 1.5498 - val_accuracy: 0.4033\n",
      "Epoch 705/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.3055 - accuracy: 0.5171 - val_loss: 1.5498 - val_accuracy: 0.4033\n",
      "Epoch 706/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.3051 - accuracy: 0.5157 - val_loss: 1.5496 - val_accuracy: 0.4033\n",
      "Epoch 707/1000\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 1.3047 - accuracy: 0.5129 - val_loss: 1.5486 - val_accuracy: 0.4033\n",
      "Epoch 708/1000\n",
      "700/700 [==============================] - 0s 88us/sample - loss: 1.3042 - accuracy: 0.5157 - val_loss: 1.5487 - val_accuracy: 0.4033\n",
      "Epoch 709/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.3037 - accuracy: 0.5143 - val_loss: 1.5487 - val_accuracy: 0.4033\n",
      "Epoch 710/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.3034 - accuracy: 0.5114 - val_loss: 1.5483 - val_accuracy: 0.4033\n",
      "Epoch 711/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3029 - accuracy: 0.5157 - val_loss: 1.5480 - val_accuracy: 0.4033\n",
      "Epoch 712/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.3024 - accuracy: 0.5171 - val_loss: 1.5479 - val_accuracy: 0.4033\n",
      "Epoch 713/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.3020 - accuracy: 0.5157 - val_loss: 1.5478 - val_accuracy: 0.4000\n",
      "Epoch 714/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.3015 - accuracy: 0.5157 - val_loss: 1.5475 - val_accuracy: 0.4000\n",
      "Epoch 715/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.3010 - accuracy: 0.5157 - val_loss: 1.5476 - val_accuracy: 0.4033\n",
      "Epoch 716/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.3005 - accuracy: 0.5143 - val_loss: 1.5472 - val_accuracy: 0.4000\n",
      "Epoch 717/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.3001 - accuracy: 0.5143 - val_loss: 1.5476 - val_accuracy: 0.4033\n",
      "Epoch 718/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2997 - accuracy: 0.5157 - val_loss: 1.5474 - val_accuracy: 0.4000\n",
      "Epoch 719/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2992 - accuracy: 0.5171 - val_loss: 1.5471 - val_accuracy: 0.4000\n",
      "Epoch 720/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2986 - accuracy: 0.5129 - val_loss: 1.5466 - val_accuracy: 0.4000\n",
      "Epoch 721/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2982 - accuracy: 0.5171 - val_loss: 1.5460 - val_accuracy: 0.4000\n",
      "Epoch 722/1000\n",
      "700/700 [==============================] - 0s 89us/sample - loss: 1.2979 - accuracy: 0.5129 - val_loss: 1.5463 - val_accuracy: 0.4000\n",
      "Epoch 723/1000\n",
      "700/700 [==============================] - 0s 127us/sample - loss: 1.2974 - accuracy: 0.5129 - val_loss: 1.5462 - val_accuracy: 0.4000\n",
      "Epoch 724/1000\n",
      "700/700 [==============================] - 0s 118us/sample - loss: 1.2969 - accuracy: 0.5129 - val_loss: 1.5457 - val_accuracy: 0.4000\n",
      "Epoch 725/1000\n",
      "700/700 [==============================] - 0s 106us/sample - loss: 1.2965 - accuracy: 0.5129 - val_loss: 1.5457 - val_accuracy: 0.4000\n",
      "Epoch 726/1000\n",
      "700/700 [==============================] - 0s 130us/sample - loss: 1.2960 - accuracy: 0.5157 - val_loss: 1.5451 - val_accuracy: 0.4000\n",
      "Epoch 727/1000\n",
      "700/700 [==============================] - 0s 94us/sample - loss: 1.2957 - accuracy: 0.5143 - val_loss: 1.5453 - val_accuracy: 0.4000\n",
      "Epoch 728/1000\n",
      "700/700 [==============================] - 0s 94us/sample - loss: 1.2950 - accuracy: 0.5143 - val_loss: 1.5455 - val_accuracy: 0.4000\n",
      "Epoch 729/1000\n",
      "700/700 [==============================] - 0s 103us/sample - loss: 1.2947 - accuracy: 0.5143 - val_loss: 1.5454 - val_accuracy: 0.4033\n",
      "Epoch 730/1000\n",
      "700/700 [==============================] - 0s 95us/sample - loss: 1.2942 - accuracy: 0.5171 - val_loss: 1.5451 - val_accuracy: 0.4033\n",
      "Epoch 731/1000\n",
      "700/700 [==============================] - 0s 86us/sample - loss: 1.2938 - accuracy: 0.5171 - val_loss: 1.5451 - val_accuracy: 0.4000\n",
      "Epoch 732/1000\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 1.2934 - accuracy: 0.5157 - val_loss: 1.5450 - val_accuracy: 0.4033\n",
      "Epoch 733/1000\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 1.2930 - accuracy: 0.5171 - val_loss: 1.5443 - val_accuracy: 0.4033\n",
      "Epoch 734/1000\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 1.2925 - accuracy: 0.5143 - val_loss: 1.5443 - val_accuracy: 0.4033\n",
      "Epoch 735/1000\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 1.2919 - accuracy: 0.5171 - val_loss: 1.5442 - val_accuracy: 0.4033\n",
      "Epoch 736/1000\n",
      "700/700 [==============================] - 0s 89us/sample - loss: 1.2915 - accuracy: 0.5157 - val_loss: 1.5444 - val_accuracy: 0.4033\n",
      "Epoch 737/1000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.2912 - accuracy: 0.5157 - val_loss: 1.5443 - val_accuracy: 0.4033\n",
      "Epoch 738/1000\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 1.2906 - accuracy: 0.5129 - val_loss: 1.5437 - val_accuracy: 0.4033\n",
      "Epoch 739/1000\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 1.2902 - accuracy: 0.5157 - val_loss: 1.5434 - val_accuracy: 0.4033\n",
      "Epoch 740/1000\n",
      "700/700 [==============================] - 0s 95us/sample - loss: 1.2898 - accuracy: 0.5157 - val_loss: 1.5433 - val_accuracy: 0.4033\n",
      "Epoch 741/1000\n",
      "700/700 [==============================] - 0s 92us/sample - loss: 1.2894 - accuracy: 0.5171 - val_loss: 1.5429 - val_accuracy: 0.4033\n",
      "Epoch 742/1000\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 1.2889 - accuracy: 0.5157 - val_loss: 1.5431 - val_accuracy: 0.4033\n",
      "Epoch 743/1000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 1.2885 - accuracy: 0.5157 - val_loss: 1.5431 - val_accuracy: 0.4033\n",
      "Epoch 744/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.2880 - accuracy: 0.5186 - val_loss: 1.5435 - val_accuracy: 0.4100\n",
      "Epoch 745/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2876 - accuracy: 0.5157 - val_loss: 1.5434 - val_accuracy: 0.4100\n",
      "Epoch 746/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.2872 - accuracy: 0.5157 - val_loss: 1.5428 - val_accuracy: 0.4033\n",
      "Epoch 747/1000\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 1.2866 - accuracy: 0.5143 - val_loss: 1.5418 - val_accuracy: 0.4067\n",
      "Epoch 748/1000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.2863 - accuracy: 0.5157 - val_loss: 1.5418 - val_accuracy: 0.4067\n",
      "Epoch 749/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2859 - accuracy: 0.5171 - val_loss: 1.5418 - val_accuracy: 0.4067\n",
      "Epoch 750/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2855 - accuracy: 0.5157 - val_loss: 1.5418 - val_accuracy: 0.4067\n",
      "Epoch 751/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2850 - accuracy: 0.5186 - val_loss: 1.5421 - val_accuracy: 0.4067\n",
      "Epoch 752/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2845 - accuracy: 0.5171 - val_loss: 1.5413 - val_accuracy: 0.4067\n",
      "Epoch 753/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2841 - accuracy: 0.5171 - val_loss: 1.5414 - val_accuracy: 0.4067\n",
      "Epoch 754/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.2837 - accuracy: 0.5186 - val_loss: 1.5412 - val_accuracy: 0.4067\n",
      "Epoch 755/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2832 - accuracy: 0.5200 - val_loss: 1.5414 - val_accuracy: 0.4067\n",
      "Epoch 756/1000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.2828 - accuracy: 0.5186 - val_loss: 1.5414 - val_accuracy: 0.4067\n",
      "Epoch 757/1000\n",
      "700/700 [==============================] - 0s 86us/sample - loss: 1.2824 - accuracy: 0.5200 - val_loss: 1.5408 - val_accuracy: 0.4067\n",
      "Epoch 758/1000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.2819 - accuracy: 0.5200 - val_loss: 1.5412 - val_accuracy: 0.4067\n",
      "Epoch 759/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2814 - accuracy: 0.5200 - val_loss: 1.5405 - val_accuracy: 0.4067\n",
      "Epoch 760/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2811 - accuracy: 0.5200 - val_loss: 1.5401 - val_accuracy: 0.4067\n",
      "Epoch 761/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2805 - accuracy: 0.5214 - val_loss: 1.5397 - val_accuracy: 0.4067\n",
      "Epoch 762/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2802 - accuracy: 0.5243 - val_loss: 1.5403 - val_accuracy: 0.4067\n",
      "Epoch 763/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2798 - accuracy: 0.5229 - val_loss: 1.5396 - val_accuracy: 0.4067\n",
      "Epoch 764/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2794 - accuracy: 0.5271 - val_loss: 1.5397 - val_accuracy: 0.4067\n",
      "Epoch 765/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.2787 - accuracy: 0.5229 - val_loss: 1.5391 - val_accuracy: 0.4067\n",
      "Epoch 766/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.2784 - accuracy: 0.5243 - val_loss: 1.5391 - val_accuracy: 0.4033\n",
      "Epoch 767/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.2779 - accuracy: 0.5257 - val_loss: 1.5396 - val_accuracy: 0.4033\n",
      "Epoch 768/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.2776 - accuracy: 0.5229 - val_loss: 1.5391 - val_accuracy: 0.4033\n",
      "Epoch 769/1000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.2771 - accuracy: 0.5286 - val_loss: 1.5385 - val_accuracy: 0.4033\n",
      "Epoch 770/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2767 - accuracy: 0.5257 - val_loss: 1.5383 - val_accuracy: 0.4033\n",
      "Epoch 771/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2762 - accuracy: 0.5257 - val_loss: 1.5383 - val_accuracy: 0.4033\n",
      "Epoch 772/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2760 - accuracy: 0.5257 - val_loss: 1.5386 - val_accuracy: 0.4033\n",
      "Epoch 773/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2754 - accuracy: 0.5243 - val_loss: 1.5381 - val_accuracy: 0.4033\n",
      "Epoch 774/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2750 - accuracy: 0.5271 - val_loss: 1.5381 - val_accuracy: 0.4033\n",
      "Epoch 775/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2745 - accuracy: 0.5271 - val_loss: 1.5380 - val_accuracy: 0.4033\n",
      "Epoch 776/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2740 - accuracy: 0.5257 - val_loss: 1.5379 - val_accuracy: 0.4033\n",
      "Epoch 777/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2736 - accuracy: 0.5271 - val_loss: 1.5375 - val_accuracy: 0.4033\n",
      "Epoch 778/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2732 - accuracy: 0.5257 - val_loss: 1.5375 - val_accuracy: 0.4033\n",
      "Epoch 779/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.2728 - accuracy: 0.5271 - val_loss: 1.5376 - val_accuracy: 0.4067\n",
      "Epoch 780/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2723 - accuracy: 0.5271 - val_loss: 1.5371 - val_accuracy: 0.4033\n",
      "Epoch 781/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.2720 - accuracy: 0.5286 - val_loss: 1.5372 - val_accuracy: 0.4033\n",
      "Epoch 782/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2714 - accuracy: 0.5257 - val_loss: 1.5371 - val_accuracy: 0.4067\n",
      "Epoch 783/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.2710 - accuracy: 0.5271 - val_loss: 1.5370 - val_accuracy: 0.4067\n",
      "Epoch 784/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.2706 - accuracy: 0.5286 - val_loss: 1.5368 - val_accuracy: 0.4067\n",
      "Epoch 785/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2701 - accuracy: 0.5286 - val_loss: 1.5368 - val_accuracy: 0.4033\n",
      "Epoch 786/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2697 - accuracy: 0.5300 - val_loss: 1.5367 - val_accuracy: 0.4067\n",
      "Epoch 787/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2692 - accuracy: 0.5271 - val_loss: 1.5359 - val_accuracy: 0.4033\n",
      "Epoch 788/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.2688 - accuracy: 0.5300 - val_loss: 1.5353 - val_accuracy: 0.4067\n",
      "Epoch 789/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.2684 - accuracy: 0.5300 - val_loss: 1.5353 - val_accuracy: 0.4033\n",
      "Epoch 790/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2679 - accuracy: 0.5300 - val_loss: 1.5354 - val_accuracy: 0.4033\n",
      "Epoch 791/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2675 - accuracy: 0.5286 - val_loss: 1.5351 - val_accuracy: 0.4000\n",
      "Epoch 792/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2671 - accuracy: 0.5286 - val_loss: 1.5355 - val_accuracy: 0.4000\n",
      "Epoch 793/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.2667 - accuracy: 0.5314 - val_loss: 1.5352 - val_accuracy: 0.4000\n",
      "Epoch 794/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2662 - accuracy: 0.5271 - val_loss: 1.5352 - val_accuracy: 0.4033\n",
      "Epoch 795/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2658 - accuracy: 0.5286 - val_loss: 1.5353 - val_accuracy: 0.4000\n",
      "Epoch 796/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2654 - accuracy: 0.5286 - val_loss: 1.5354 - val_accuracy: 0.4033\n",
      "Epoch 797/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.2650 - accuracy: 0.5300 - val_loss: 1.5349 - val_accuracy: 0.4000\n",
      "Epoch 798/1000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.2645 - accuracy: 0.5300 - val_loss: 1.5349 - val_accuracy: 0.4000\n",
      "Epoch 799/1000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.2642 - accuracy: 0.5314 - val_loss: 1.5347 - val_accuracy: 0.3967\n",
      "Epoch 800/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2638 - accuracy: 0.5314 - val_loss: 1.5348 - val_accuracy: 0.3967\n",
      "Epoch 801/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2633 - accuracy: 0.5343 - val_loss: 1.5347 - val_accuracy: 0.4000\n",
      "Epoch 802/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2629 - accuracy: 0.5314 - val_loss: 1.5344 - val_accuracy: 0.4000\n",
      "Epoch 803/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.2625 - accuracy: 0.5314 - val_loss: 1.5343 - val_accuracy: 0.4000\n",
      "Epoch 804/1000\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 1.2620 - accuracy: 0.5329 - val_loss: 1.5340 - val_accuracy: 0.3933\n",
      "Epoch 805/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.2616 - accuracy: 0.5357 - val_loss: 1.5333 - val_accuracy: 0.4033\n",
      "Epoch 806/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2611 - accuracy: 0.5343 - val_loss: 1.5332 - val_accuracy: 0.3967\n",
      "Epoch 807/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2607 - accuracy: 0.5343 - val_loss: 1.5331 - val_accuracy: 0.3967\n",
      "Epoch 808/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2603 - accuracy: 0.5343 - val_loss: 1.5338 - val_accuracy: 0.3967\n",
      "Epoch 809/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.2599 - accuracy: 0.5329 - val_loss: 1.5332 - val_accuracy: 0.3967\n",
      "Epoch 810/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2594 - accuracy: 0.5329 - val_loss: 1.5334 - val_accuracy: 0.4000\n",
      "Epoch 811/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.2589 - accuracy: 0.5300 - val_loss: 1.5327 - val_accuracy: 0.3933\n",
      "Epoch 812/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2585 - accuracy: 0.5343 - val_loss: 1.5329 - val_accuracy: 0.3933\n",
      "Epoch 813/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.2581 - accuracy: 0.5329 - val_loss: 1.5331 - val_accuracy: 0.3967\n",
      "Epoch 814/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2578 - accuracy: 0.5343 - val_loss: 1.5328 - val_accuracy: 0.4000\n",
      "Epoch 815/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.2573 - accuracy: 0.5343 - val_loss: 1.5328 - val_accuracy: 0.4000\n",
      "Epoch 816/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2569 - accuracy: 0.5329 - val_loss: 1.5324 - val_accuracy: 0.4000\n",
      "Epoch 817/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.2565 - accuracy: 0.5300 - val_loss: 1.5324 - val_accuracy: 0.4000\n",
      "Epoch 818/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.2560 - accuracy: 0.5300 - val_loss: 1.5313 - val_accuracy: 0.4000\n",
      "Epoch 819/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2557 - accuracy: 0.5314 - val_loss: 1.5310 - val_accuracy: 0.4000\n",
      "Epoch 820/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2553 - accuracy: 0.5329 - val_loss: 1.5315 - val_accuracy: 0.4000\n",
      "Epoch 821/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.2548 - accuracy: 0.5329 - val_loss: 1.5316 - val_accuracy: 0.3967\n",
      "Epoch 822/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2543 - accuracy: 0.5314 - val_loss: 1.5316 - val_accuracy: 0.4000\n",
      "Epoch 823/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.2539 - accuracy: 0.5357 - val_loss: 1.5312 - val_accuracy: 0.3967\n",
      "Epoch 824/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.2535 - accuracy: 0.5271 - val_loss: 1.5312 - val_accuracy: 0.4000\n",
      "Epoch 825/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.2531 - accuracy: 0.5286 - val_loss: 1.5310 - val_accuracy: 0.4000\n",
      "Epoch 826/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.2527 - accuracy: 0.5314 - val_loss: 1.5306 - val_accuracy: 0.4000\n",
      "Epoch 827/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.2522 - accuracy: 0.5314 - val_loss: 1.5305 - val_accuracy: 0.4000\n",
      "Epoch 828/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.2517 - accuracy: 0.5314 - val_loss: 1.5301 - val_accuracy: 0.4000\n",
      "Epoch 829/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.2513 - accuracy: 0.5314 - val_loss: 1.5302 - val_accuracy: 0.4000\n",
      "Epoch 830/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2508 - accuracy: 0.5300 - val_loss: 1.5301 - val_accuracy: 0.4000\n",
      "Epoch 831/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.2503 - accuracy: 0.5300 - val_loss: 1.5297 - val_accuracy: 0.4000\n",
      "Epoch 832/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2501 - accuracy: 0.5314 - val_loss: 1.5300 - val_accuracy: 0.4000\n",
      "Epoch 833/1000\n",
      "700/700 [==============================] - 0s 100us/sample - loss: 1.2495 - accuracy: 0.5300 - val_loss: 1.5300 - val_accuracy: 0.4033\n",
      "Epoch 834/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.2490 - accuracy: 0.5286 - val_loss: 1.5301 - val_accuracy: 0.4033\n",
      "Epoch 835/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2485 - accuracy: 0.5329 - val_loss: 1.5295 - val_accuracy: 0.4000\n",
      "Epoch 836/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2479 - accuracy: 0.5286 - val_loss: 1.5292 - val_accuracy: 0.4000\n",
      "Epoch 837/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.2475 - accuracy: 0.5286 - val_loss: 1.5288 - val_accuracy: 0.4000\n",
      "Epoch 838/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2470 - accuracy: 0.5300 - val_loss: 1.5285 - val_accuracy: 0.4000\n",
      "Epoch 839/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2466 - accuracy: 0.5300 - val_loss: 1.5289 - val_accuracy: 0.4000\n",
      "Epoch 840/1000\n",
      "700/700 [==============================] - 0s 106us/sample - loss: 1.2461 - accuracy: 0.5286 - val_loss: 1.5289 - val_accuracy: 0.4033\n",
      "Epoch 841/1000\n",
      "700/700 [==============================] - 0s 88us/sample - loss: 1.2455 - accuracy: 0.5300 - val_loss: 1.5287 - val_accuracy: 0.4033\n",
      "Epoch 842/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2452 - accuracy: 0.5314 - val_loss: 1.5288 - val_accuracy: 0.4033\n",
      "Epoch 843/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2447 - accuracy: 0.5300 - val_loss: 1.5282 - val_accuracy: 0.4033\n",
      "Epoch 844/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2443 - accuracy: 0.5300 - val_loss: 1.5286 - val_accuracy: 0.4067\n",
      "Epoch 845/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2438 - accuracy: 0.5271 - val_loss: 1.5284 - val_accuracy: 0.4067\n",
      "Epoch 846/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.2432 - accuracy: 0.5300 - val_loss: 1.5280 - val_accuracy: 0.4033\n",
      "Epoch 847/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.2428 - accuracy: 0.5314 - val_loss: 1.5285 - val_accuracy: 0.4067\n",
      "Epoch 848/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2424 - accuracy: 0.5300 - val_loss: 1.5277 - val_accuracy: 0.4033\n",
      "Epoch 849/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2419 - accuracy: 0.5271 - val_loss: 1.5277 - val_accuracy: 0.4067\n",
      "Epoch 850/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2415 - accuracy: 0.5286 - val_loss: 1.5279 - val_accuracy: 0.4067\n",
      "Epoch 851/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.2410 - accuracy: 0.5300 - val_loss: 1.5279 - val_accuracy: 0.4067\n",
      "Epoch 852/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.2405 - accuracy: 0.5300 - val_loss: 1.5275 - val_accuracy: 0.4067\n",
      "Epoch 853/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2400 - accuracy: 0.5314 - val_loss: 1.5267 - val_accuracy: 0.4033\n",
      "Epoch 854/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2396 - accuracy: 0.5314 - val_loss: 1.5267 - val_accuracy: 0.4033\n",
      "Epoch 855/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2392 - accuracy: 0.5329 - val_loss: 1.5273 - val_accuracy: 0.4067\n",
      "Epoch 856/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.2387 - accuracy: 0.5286 - val_loss: 1.5265 - val_accuracy: 0.4033\n",
      "Epoch 857/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.2383 - accuracy: 0.5343 - val_loss: 1.5269 - val_accuracy: 0.4067\n",
      "Epoch 858/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2378 - accuracy: 0.5329 - val_loss: 1.5271 - val_accuracy: 0.4067\n",
      "Epoch 859/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2374 - accuracy: 0.5329 - val_loss: 1.5271 - val_accuracy: 0.4067\n",
      "Epoch 860/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.2369 - accuracy: 0.5329 - val_loss: 1.5271 - val_accuracy: 0.4067\n",
      "Epoch 861/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.2364 - accuracy: 0.5314 - val_loss: 1.5264 - val_accuracy: 0.4067\n",
      "Epoch 862/1000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.2360 - accuracy: 0.5329 - val_loss: 1.5268 - val_accuracy: 0.4067\n",
      "Epoch 863/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2355 - accuracy: 0.5343 - val_loss: 1.5271 - val_accuracy: 0.4067\n",
      "Epoch 864/1000\n",
      "700/700 [==============================] - 0s 114us/sample - loss: 1.2351 - accuracy: 0.5329 - val_loss: 1.5265 - val_accuracy: 0.4067\n",
      "Epoch 865/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2347 - accuracy: 0.5329 - val_loss: 1.5258 - val_accuracy: 0.4067\n",
      "Epoch 866/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2343 - accuracy: 0.5343 - val_loss: 1.5258 - val_accuracy: 0.4067\n",
      "Epoch 867/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.2338 - accuracy: 0.5343 - val_loss: 1.5258 - val_accuracy: 0.4067\n",
      "Epoch 868/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.2334 - accuracy: 0.5300 - val_loss: 1.5259 - val_accuracy: 0.4067\n",
      "Epoch 869/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.2329 - accuracy: 0.5371 - val_loss: 1.5262 - val_accuracy: 0.4100\n",
      "Epoch 870/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2324 - accuracy: 0.5314 - val_loss: 1.5257 - val_accuracy: 0.4067\n",
      "Epoch 871/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2319 - accuracy: 0.5371 - val_loss: 1.5253 - val_accuracy: 0.4100\n",
      "Epoch 872/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2315 - accuracy: 0.5343 - val_loss: 1.5251 - val_accuracy: 0.4100\n",
      "Epoch 873/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2311 - accuracy: 0.5357 - val_loss: 1.5245 - val_accuracy: 0.4133\n",
      "Epoch 874/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2306 - accuracy: 0.5329 - val_loss: 1.5249 - val_accuracy: 0.4133\n",
      "Epoch 875/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.2302 - accuracy: 0.5371 - val_loss: 1.5245 - val_accuracy: 0.4133\n",
      "Epoch 876/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.2297 - accuracy: 0.5343 - val_loss: 1.5248 - val_accuracy: 0.4167\n",
      "Epoch 877/1000\n",
      "700/700 [==============================] - 0s 96us/sample - loss: 1.2292 - accuracy: 0.5371 - val_loss: 1.5245 - val_accuracy: 0.4133\n",
      "Epoch 878/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2288 - accuracy: 0.5371 - val_loss: 1.5243 - val_accuracy: 0.4133\n",
      "Epoch 879/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2283 - accuracy: 0.5343 - val_loss: 1.5244 - val_accuracy: 0.4133\n",
      "Epoch 880/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.2278 - accuracy: 0.5357 - val_loss: 1.5247 - val_accuracy: 0.4133\n",
      "Epoch 881/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2275 - accuracy: 0.5357 - val_loss: 1.5245 - val_accuracy: 0.4100\n",
      "Epoch 882/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.2270 - accuracy: 0.5371 - val_loss: 1.5246 - val_accuracy: 0.4133\n",
      "Epoch 883/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.2267 - accuracy: 0.5386 - val_loss: 1.5241 - val_accuracy: 0.4133\n",
      "Epoch 884/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2260 - accuracy: 0.5386 - val_loss: 1.5243 - val_accuracy: 0.4133\n",
      "Epoch 885/1000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.2257 - accuracy: 0.5371 - val_loss: 1.5231 - val_accuracy: 0.4100\n",
      "Epoch 886/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2254 - accuracy: 0.5371 - val_loss: 1.5235 - val_accuracy: 0.4100\n",
      "Epoch 887/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.2248 - accuracy: 0.5400 - val_loss: 1.5234 - val_accuracy: 0.4133\n",
      "Epoch 888/1000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.2243 - accuracy: 0.5371 - val_loss: 1.5229 - val_accuracy: 0.4133\n",
      "Epoch 889/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2238 - accuracy: 0.5371 - val_loss: 1.5235 - val_accuracy: 0.4133\n",
      "Epoch 890/1000\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 1.2235 - accuracy: 0.5371 - val_loss: 1.5228 - val_accuracy: 0.4133\n",
      "Epoch 891/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.2229 - accuracy: 0.5400 - val_loss: 1.5234 - val_accuracy: 0.4100\n",
      "Epoch 892/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2227 - accuracy: 0.5386 - val_loss: 1.5226 - val_accuracy: 0.4100\n",
      "Epoch 893/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2220 - accuracy: 0.5429 - val_loss: 1.5224 - val_accuracy: 0.4100\n",
      "Epoch 894/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2217 - accuracy: 0.5386 - val_loss: 1.5223 - val_accuracy: 0.4100\n",
      "Epoch 895/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.2213 - accuracy: 0.5400 - val_loss: 1.5224 - val_accuracy: 0.4100\n",
      "Epoch 896/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.2208 - accuracy: 0.5429 - val_loss: 1.5226 - val_accuracy: 0.4100\n",
      "Epoch 897/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2203 - accuracy: 0.5386 - val_loss: 1.5217 - val_accuracy: 0.4100\n",
      "Epoch 898/1000\n",
      "700/700 [==============================] - 0s 93us/sample - loss: 1.2199 - accuracy: 0.5400 - val_loss: 1.5217 - val_accuracy: 0.4100\n",
      "Epoch 899/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.2195 - accuracy: 0.5414 - val_loss: 1.5220 - val_accuracy: 0.4100\n",
      "Epoch 900/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.2190 - accuracy: 0.5414 - val_loss: 1.5217 - val_accuracy: 0.4100\n",
      "Epoch 901/1000\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 1.2186 - accuracy: 0.5414 - val_loss: 1.5221 - val_accuracy: 0.4100\n",
      "Epoch 902/1000\n",
      "700/700 [==============================] - 0s 87us/sample - loss: 1.2181 - accuracy: 0.5400 - val_loss: 1.5218 - val_accuracy: 0.4100\n",
      "Epoch 903/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.2178 - accuracy: 0.5414 - val_loss: 1.5217 - val_accuracy: 0.4100\n",
      "Epoch 904/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2173 - accuracy: 0.5429 - val_loss: 1.5214 - val_accuracy: 0.4100\n",
      "Epoch 905/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2169 - accuracy: 0.5414 - val_loss: 1.5213 - val_accuracy: 0.4100\n",
      "Epoch 906/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2164 - accuracy: 0.5429 - val_loss: 1.5212 - val_accuracy: 0.4100\n",
      "Epoch 907/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2160 - accuracy: 0.5443 - val_loss: 1.5209 - val_accuracy: 0.4100\n",
      "Epoch 908/1000\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 1.2155 - accuracy: 0.5429 - val_loss: 1.5212 - val_accuracy: 0.4100\n",
      "Epoch 909/1000\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 1.2152 - accuracy: 0.5400 - val_loss: 1.5212 - val_accuracy: 0.4100\n",
      "Epoch 910/1000\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 1.2146 - accuracy: 0.5400 - val_loss: 1.5207 - val_accuracy: 0.4133\n",
      "Epoch 911/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2142 - accuracy: 0.5414 - val_loss: 1.5204 - val_accuracy: 0.4100\n",
      "Epoch 912/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.2139 - accuracy: 0.5414 - val_loss: 1.5204 - val_accuracy: 0.4100\n",
      "Epoch 913/1000\n",
      "700/700 [==============================] - 0s 86us/sample - loss: 1.2134 - accuracy: 0.5429 - val_loss: 1.5197 - val_accuracy: 0.4100\n",
      "Epoch 914/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.2129 - accuracy: 0.5443 - val_loss: 1.5202 - val_accuracy: 0.4100\n",
      "Epoch 915/1000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.2126 - accuracy: 0.5371 - val_loss: 1.5203 - val_accuracy: 0.4100\n",
      "Epoch 916/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.2121 - accuracy: 0.5457 - val_loss: 1.5198 - val_accuracy: 0.4100\n",
      "Epoch 917/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2116 - accuracy: 0.5457 - val_loss: 1.5204 - val_accuracy: 0.4100\n",
      "Epoch 918/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.2112 - accuracy: 0.5414 - val_loss: 1.5198 - val_accuracy: 0.4100\n",
      "Epoch 919/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2108 - accuracy: 0.5457 - val_loss: 1.5199 - val_accuracy: 0.4100\n",
      "Epoch 920/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.2104 - accuracy: 0.5443 - val_loss: 1.5195 - val_accuracy: 0.4100\n",
      "Epoch 921/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2099 - accuracy: 0.5429 - val_loss: 1.5192 - val_accuracy: 0.4100\n",
      "Epoch 922/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.2094 - accuracy: 0.5429 - val_loss: 1.5195 - val_accuracy: 0.4100\n",
      "Epoch 923/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.2092 - accuracy: 0.5443 - val_loss: 1.5195 - val_accuracy: 0.4100\n",
      "Epoch 924/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.2086 - accuracy: 0.5471 - val_loss: 1.5188 - val_accuracy: 0.4133\n",
      "Epoch 925/1000\n",
      "700/700 [==============================] - 0s 75us/sample - loss: 1.2082 - accuracy: 0.5443 - val_loss: 1.5196 - val_accuracy: 0.4167\n",
      "Epoch 926/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2078 - accuracy: 0.5457 - val_loss: 1.5194 - val_accuracy: 0.4167\n",
      "Epoch 927/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.2073 - accuracy: 0.5443 - val_loss: 1.5187 - val_accuracy: 0.4133\n",
      "Epoch 928/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.2069 - accuracy: 0.5471 - val_loss: 1.5187 - val_accuracy: 0.4167\n",
      "Epoch 929/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.2066 - accuracy: 0.5457 - val_loss: 1.5183 - val_accuracy: 0.4133\n",
      "Epoch 930/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.2061 - accuracy: 0.5443 - val_loss: 1.5188 - val_accuracy: 0.4133\n",
      "Epoch 931/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2057 - accuracy: 0.5486 - val_loss: 1.5185 - val_accuracy: 0.4133\n",
      "Epoch 932/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2052 - accuracy: 0.5471 - val_loss: 1.5180 - val_accuracy: 0.4167\n",
      "Epoch 933/1000\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 1.2049 - accuracy: 0.5471 - val_loss: 1.5187 - val_accuracy: 0.4133\n",
      "Epoch 934/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.2043 - accuracy: 0.5471 - val_loss: 1.5179 - val_accuracy: 0.4133\n",
      "Epoch 935/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2040 - accuracy: 0.5486 - val_loss: 1.5184 - val_accuracy: 0.4133\n",
      "Epoch 936/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.2036 - accuracy: 0.5471 - val_loss: 1.5186 - val_accuracy: 0.4133\n",
      "Epoch 937/1000\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 1.2031 - accuracy: 0.5486 - val_loss: 1.5175 - val_accuracy: 0.4133\n",
      "Epoch 938/1000\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 1.2029 - accuracy: 0.5471 - val_loss: 1.5180 - val_accuracy: 0.4133\n",
      "Epoch 939/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2023 - accuracy: 0.5486 - val_loss: 1.5172 - val_accuracy: 0.4133\n",
      "Epoch 940/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2019 - accuracy: 0.5471 - val_loss: 1.5177 - val_accuracy: 0.4167\n",
      "Epoch 941/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.2015 - accuracy: 0.5486 - val_loss: 1.5177 - val_accuracy: 0.4167\n",
      "Epoch 942/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2012 - accuracy: 0.5457 - val_loss: 1.5171 - val_accuracy: 0.4167\n",
      "Epoch 943/1000\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1.2009 - accuracy: 0.5471 - val_loss: 1.5174 - val_accuracy: 0.4167\n",
      "Epoch 944/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.2004 - accuracy: 0.5457 - val_loss: 1.5174 - val_accuracy: 0.4133\n",
      "Epoch 945/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.2000 - accuracy: 0.5457 - val_loss: 1.5174 - val_accuracy: 0.4133\n",
      "Epoch 946/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1995 - accuracy: 0.5471 - val_loss: 1.5175 - val_accuracy: 0.4167\n",
      "Epoch 947/1000\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 1.1991 - accuracy: 0.5486 - val_loss: 1.5174 - val_accuracy: 0.4167\n",
      "Epoch 948/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.1988 - accuracy: 0.5486 - val_loss: 1.5174 - val_accuracy: 0.4133\n",
      "Epoch 949/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.1984 - accuracy: 0.5486 - val_loss: 1.5172 - val_accuracy: 0.4167\n",
      "Epoch 950/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1978 - accuracy: 0.5486 - val_loss: 1.5167 - val_accuracy: 0.4133\n",
      "Epoch 951/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.1974 - accuracy: 0.5529 - val_loss: 1.5173 - val_accuracy: 0.4167\n",
      "Epoch 952/1000\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 1.1972 - accuracy: 0.5471 - val_loss: 1.5173 - val_accuracy: 0.4167\n",
      "Epoch 953/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.1968 - accuracy: 0.5529 - val_loss: 1.5169 - val_accuracy: 0.4167\n",
      "Epoch 954/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1964 - accuracy: 0.5529 - val_loss: 1.5168 - val_accuracy: 0.4133\n",
      "Epoch 955/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1959 - accuracy: 0.5500 - val_loss: 1.5169 - val_accuracy: 0.4133\n",
      "Epoch 956/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1956 - accuracy: 0.5529 - val_loss: 1.5168 - val_accuracy: 0.4133\n",
      "Epoch 957/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.1952 - accuracy: 0.5514 - val_loss: 1.5161 - val_accuracy: 0.4167\n",
      "Epoch 958/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1948 - accuracy: 0.5486 - val_loss: 1.5166 - val_accuracy: 0.4167\n",
      "Epoch 959/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.1943 - accuracy: 0.5500 - val_loss: 1.5160 - val_accuracy: 0.4167\n",
      "Epoch 960/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.1940 - accuracy: 0.5514 - val_loss: 1.5165 - val_accuracy: 0.4167\n",
      "Epoch 961/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1936 - accuracy: 0.5514 - val_loss: 1.5165 - val_accuracy: 0.4167\n",
      "Epoch 962/1000\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1.1931 - accuracy: 0.5514 - val_loss: 1.5163 - val_accuracy: 0.4167\n",
      "Epoch 963/1000\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 1.1928 - accuracy: 0.5471 - val_loss: 1.5162 - val_accuracy: 0.4167\n",
      "Epoch 964/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1924 - accuracy: 0.5486 - val_loss: 1.5160 - val_accuracy: 0.4167\n",
      "Epoch 965/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1919 - accuracy: 0.5514 - val_loss: 1.5161 - val_accuracy: 0.4167\n",
      "Epoch 966/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.1914 - accuracy: 0.5514 - val_loss: 1.5165 - val_accuracy: 0.4167\n",
      "Epoch 967/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1912 - accuracy: 0.5471 - val_loss: 1.5166 - val_accuracy: 0.4167\n",
      "Epoch 968/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.1907 - accuracy: 0.5486 - val_loss: 1.5162 - val_accuracy: 0.4133\n",
      "Epoch 969/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.1903 - accuracy: 0.5486 - val_loss: 1.5157 - val_accuracy: 0.4133\n",
      "Epoch 970/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.1899 - accuracy: 0.5514 - val_loss: 1.5149 - val_accuracy: 0.4167\n",
      "Epoch 971/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1896 - accuracy: 0.5557 - val_loss: 1.5158 - val_accuracy: 0.4167\n",
      "Epoch 972/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.1892 - accuracy: 0.5471 - val_loss: 1.5155 - val_accuracy: 0.4167\n",
      "Epoch 973/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.1887 - accuracy: 0.5514 - val_loss: 1.5154 - val_accuracy: 0.4133\n",
      "Epoch 974/1000\n",
      "700/700 [==============================] - 0s 86us/sample - loss: 1.1884 - accuracy: 0.5500 - val_loss: 1.5162 - val_accuracy: 0.4133\n",
      "Epoch 975/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.1880 - accuracy: 0.5571 - val_loss: 1.5153 - val_accuracy: 0.4167\n",
      "Epoch 976/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1875 - accuracy: 0.5529 - val_loss: 1.5159 - val_accuracy: 0.4167\n",
      "Epoch 977/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1872 - accuracy: 0.5486 - val_loss: 1.5156 - val_accuracy: 0.4167\n",
      "Epoch 978/1000\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 1.1868 - accuracy: 0.5471 - val_loss: 1.5156 - val_accuracy: 0.4133\n",
      "Epoch 979/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.1864 - accuracy: 0.5543 - val_loss: 1.5159 - val_accuracy: 0.4167\n",
      "Epoch 980/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1860 - accuracy: 0.5529 - val_loss: 1.5154 - val_accuracy: 0.4167\n",
      "Epoch 981/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1855 - accuracy: 0.5486 - val_loss: 1.5154 - val_accuracy: 0.4133\n",
      "Epoch 982/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1853 - accuracy: 0.5543 - val_loss: 1.5154 - val_accuracy: 0.4167\n",
      "Epoch 983/1000\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 1.1848 - accuracy: 0.5529 - val_loss: 1.5151 - val_accuracy: 0.4167\n",
      "Epoch 984/1000\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 1.1844 - accuracy: 0.5500 - val_loss: 1.5146 - val_accuracy: 0.4167\n",
      "Epoch 985/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1840 - accuracy: 0.5557 - val_loss: 1.5144 - val_accuracy: 0.4167\n",
      "Epoch 986/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1836 - accuracy: 0.5571 - val_loss: 1.5151 - val_accuracy: 0.4167\n",
      "Epoch 987/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.1833 - accuracy: 0.5529 - val_loss: 1.5150 - val_accuracy: 0.4167\n",
      "Epoch 988/1000\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 1.1829 - accuracy: 0.5557 - val_loss: 1.5151 - val_accuracy: 0.4167\n",
      "Epoch 989/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.1824 - accuracy: 0.5529 - val_loss: 1.5154 - val_accuracy: 0.4167\n",
      "Epoch 990/1000\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1.1821 - accuracy: 0.5543 - val_loss: 1.5146 - val_accuracy: 0.4167\n",
      "Epoch 991/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.1817 - accuracy: 0.5514 - val_loss: 1.5147 - val_accuracy: 0.4200\n",
      "Epoch 992/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.1813 - accuracy: 0.5543 - val_loss: 1.5140 - val_accuracy: 0.4167\n",
      "Epoch 993/1000\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 1.1809 - accuracy: 0.5543 - val_loss: 1.5147 - val_accuracy: 0.4167\n",
      "Epoch 994/1000\n",
      "700/700 [==============================] - 0s 101us/sample - loss: 1.1805 - accuracy: 0.5529 - val_loss: 1.5142 - val_accuracy: 0.4167\n",
      "Epoch 995/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.1801 - accuracy: 0.5629 - val_loss: 1.5148 - val_accuracy: 0.4167\n",
      "Epoch 996/1000\n",
      "700/700 [==============================] - 0s 72us/sample - loss: 1.1798 - accuracy: 0.5543 - val_loss: 1.5145 - val_accuracy: 0.4167\n",
      "Epoch 997/1000\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 1.1794 - accuracy: 0.5571 - val_loss: 1.5147 - val_accuracy: 0.4200\n",
      "Epoch 998/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1790 - accuracy: 0.5543 - val_loss: 1.5144 - val_accuracy: 0.4167\n",
      "Epoch 999/1000\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1.1787 - accuracy: 0.5514 - val_loss: 1.5143 - val_accuracy: 0.4167\n",
      "Epoch 1000/1000\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 1.1782 - accuracy: 0.5586 - val_loss: 1.5146 - val_accuracy: 0.4200\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(3)\n",
    "\n",
    "# 1. 데이터셋 준비하기\n",
    "\n",
    "# 훈련셋과 시험셋 로딩\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# 훈련셋과 검증셋 분리\n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "\n",
    "X_train = X_train.reshape(50000, 784).astype('float32') / 255.0\n",
    "X_val = X_val.reshape(10000, 784).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "# 훈련셋, 검증셋 고르기\n",
    "train_rand_idxs = np.random.choice(50000, 700)\n",
    "val_rand_idxs = np.random.choice(10000, 300)\n",
    "\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]\n",
    "\n",
    "# 라벨링 전환\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_val = np_utils.to_categorical(Y_val)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# 3. 모델 엮기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(patience = 20) # 조기종료 콜백함수 정의\n",
    "hist = model.fit(X_train, Y_train, epochs=1000, batch_size=10, validation_data=(X_val, Y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x182f481cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 12us/sample - loss: 1.4686 - accuracy: 0.4508\n",
      "\n",
      "loss : 1.4686308243751527\n",
      "accuray : 0.4508\n"
     ]
    }
   ],
   "source": [
    "# 6. 모델 사용하기\n",
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "\n",
    "print('')\n",
    "print('loss : ' + str(loss_and_metrics[0]))\n",
    "print('accuray : ' + str(loss_and_metrics[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 모델 저장 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18000 samples, validate on 42000 samples\n",
      "Epoch 1/5\n",
      "18000/18000 [==============================] - 1s 66us/sample - loss: 2.2162 - accuracy: 0.2174 - val_loss: 2.0477 - val_accuracy: 0.4031\n",
      "Epoch 2/5\n",
      "18000/18000 [==============================] - 1s 66us/sample - loss: 1.8745 - accuracy: 0.5422 - val_loss: 1.7257 - val_accuracy: 0.6023\n",
      "Epoch 3/5\n",
      "18000/18000 [==============================] - 1s 67us/sample - loss: 1.5600 - accuracy: 0.6653 - val_loss: 1.4405 - val_accuracy: 0.6868\n",
      "Epoch 4/5\n",
      "18000/18000 [==============================] - 1s 68us/sample - loss: 1.3006 - accuracy: 0.7293 - val_loss: 1.2189 - val_accuracy: 0.7380\n",
      "Epoch 5/5\n",
      "18000/18000 [==============================] - 1s 67us/sample - loss: 1.1053 - accuracy: 0.7705 - val_loss: 1.0560 - val_accuracy: 0.7686\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 1.0208 - accuracy: 0.7819\n",
      "\n",
      "loss_and_metrics : [1.0207999114990234, 0.7819]\n",
      "True : 4, Predict : 4\n",
      "True : 8, Predict : 8\n",
      "True : 6, Predict : 6\n",
      "True : 5, Predict : 5\n",
      "True : 6, Predict : 6\n"
     ]
    }
   ],
   "source": [
    "# 훈련셋과 시험셋 불러오기\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 데이터셋 전처리\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "# 원핫인코딩 (one-hot encoding) 처리\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "# 훈련셋과 검증셋 분리\n",
    "x_val = x_train[:42000] # 훈련셋의 30%를 검증셋으로 사용\n",
    "x_train = x_train[42000:]\n",
    "y_val = y_train[:42000] # 훈련셋의 30%를 검증셋으로 사용\n",
    "y_train = y_train[42000:]\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# 3. 모델 학습과정 설정하기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_val, y_val))\n",
    "\n",
    "# 5. 모델 평가하기\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=32)\n",
    "print('')\n",
    "print('loss_and_metrics : ' + str(loss_and_metrics))\n",
    "\n",
    "\n",
    "# 6. 모델 사용하기\n",
    "xhat_idx = np.random.choice(x_test.shape[0], 5)\n",
    "xhat = x_test[xhat_idx]\n",
    "yhat = model.predict_classes(xhat)\n",
    "\n",
    "for i in range(5):\n",
    "    print('True : ' + str(np.argmax(y_test[xhat_idx[i]])) + ', Predict : ' + str(yhat[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6. 모델 저장하기\n",
    "from keras.models import load_model\n",
    "model.save('mnist_mlp_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True : 9, Predict : 9\n",
      "True : 6, Predict : 6\n",
      "True : 5, Predict : 5\n",
      "True : 8, Predict : 8\n",
      "True : 1, Predict : 1\n"
     ]
    }
   ],
   "source": [
    "# 1. 실무에 사용할 데이터 준비하기\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "xhat_idx = np.random.choice(x_test.shape[0], 5)\n",
    "xhat = x_test[xhat_idx]\n",
    "\n",
    "# 2. 모델 불러오기\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('mnist_mlp_model.h5')\n",
    "\n",
    "# 3. 모델 사용하기\n",
    "yhat = model.predict_classes(xhat)\n",
    "\n",
    "for i in range(5):\n",
    "    print('True : ' + str(np.argmax(y_test[xhat_idx[i]])) + ', Predict : ' + str(yhat[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
