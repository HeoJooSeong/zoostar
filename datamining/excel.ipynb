{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'jips.xls'\n",
    "xl = pd.ExcelFile(file)\n",
    "df = xl.parse('Sheet1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>symbol</th>\n",
       "      <th>price_start</th>\n",
       "      <th>price_end</th>\n",
       "      <th>price_max</th>\n",
       "      <th>price_min</th>\n",
       "      <th>volume</th>\n",
       "      <th>time_epoch</th>\n",
       "      <th>date_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>btc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7094000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529944200000</td>\n",
       "      <td>2018-06-25 16:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>eth</td>\n",
       "      <td>0.0</td>\n",
       "      <td>521000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529944200000</td>\n",
       "      <td>2018-06-25 16:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>xrp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>542.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529944200000</td>\n",
       "      <td>2018-06-25 16:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>bch</td>\n",
       "      <td>0.0</td>\n",
       "      <td>856000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529944200000</td>\n",
       "      <td>2018-06-25 16:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ltc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529944200000</td>\n",
       "      <td>2018-06-25 16:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>dash</td>\n",
       "      <td>0.0</td>\n",
       "      <td>271300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529944200000</td>\n",
       "      <td>2018-06-25 16:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>etc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17830.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529944200000</td>\n",
       "      <td>2018-06-25 16:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>btc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7046000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529947800000</td>\n",
       "      <td>2018-06-25 17:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>eth</td>\n",
       "      <td>0.0</td>\n",
       "      <td>521000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529947800000</td>\n",
       "      <td>2018-06-25 17:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>xrp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529947800000</td>\n",
       "      <td>2018-06-25 17:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>bch</td>\n",
       "      <td>0.0</td>\n",
       "      <td>854000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529947800000</td>\n",
       "      <td>2018-06-25 17:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>ltc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529947800000</td>\n",
       "      <td>2018-06-25 17:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>dash</td>\n",
       "      <td>0.0</td>\n",
       "      <td>271200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529947800000</td>\n",
       "      <td>2018-06-25 17:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>etc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17760.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529947800000</td>\n",
       "      <td>2018-06-25 17:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>btc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7048000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529949600000</td>\n",
       "      <td>2018-06-25 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>eth</td>\n",
       "      <td>0.0</td>\n",
       "      <td>521000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529949600000</td>\n",
       "      <td>2018-06-25 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>xrp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>542.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529949600000</td>\n",
       "      <td>2018-06-25 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>bch</td>\n",
       "      <td>0.0</td>\n",
       "      <td>856000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529949600000</td>\n",
       "      <td>2018-06-25 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>ltc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529949600000</td>\n",
       "      <td>2018-06-25 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>dash</td>\n",
       "      <td>0.0</td>\n",
       "      <td>273000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529949600000</td>\n",
       "      <td>2018-06-25 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>etc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529949600000</td>\n",
       "      <td>2018-06-25 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>btc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7052000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529951400000</td>\n",
       "      <td>2018-06-25 18:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>eth</td>\n",
       "      <td>0.0</td>\n",
       "      <td>521000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529951400000</td>\n",
       "      <td>2018-06-25 18:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>xrp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>542.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529951400000</td>\n",
       "      <td>2018-06-25 18:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>bch</td>\n",
       "      <td>0.0</td>\n",
       "      <td>852000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529951400000</td>\n",
       "      <td>2018-06-25 18:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>ltc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529951400000</td>\n",
       "      <td>2018-06-25 18:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>dash</td>\n",
       "      <td>0.0</td>\n",
       "      <td>273000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529951400000</td>\n",
       "      <td>2018-06-25 18:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>etc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17860.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529951400000</td>\n",
       "      <td>2018-06-25 18:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>btc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7042000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529953200000</td>\n",
       "      <td>2018-06-25 19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>eth</td>\n",
       "      <td>0.0</td>\n",
       "      <td>520000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1529953200000</td>\n",
       "      <td>2018-06-25 19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4970</th>\n",
       "      <td>5172</td>\n",
       "      <td>etc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531457400000</td>\n",
       "      <td>2018-07-13 04:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4971</th>\n",
       "      <td>5173</td>\n",
       "      <td>btc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7092000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531458000000</td>\n",
       "      <td>2018-07-13 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4972</th>\n",
       "      <td>5174</td>\n",
       "      <td>eth</td>\n",
       "      <td>0.0</td>\n",
       "      <td>494500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531458000000</td>\n",
       "      <td>2018-07-13 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>5175</td>\n",
       "      <td>xrp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531458000000</td>\n",
       "      <td>2018-07-13 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4974</th>\n",
       "      <td>5176</td>\n",
       "      <td>bch</td>\n",
       "      <td>0.0</td>\n",
       "      <td>790000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531458000000</td>\n",
       "      <td>2018-07-13 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4975</th>\n",
       "      <td>5177</td>\n",
       "      <td>etc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18870.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531458000000</td>\n",
       "      <td>2018-07-13 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>5178</td>\n",
       "      <td>btc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7093000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531458600000</td>\n",
       "      <td>2018-07-13 05:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>5179</td>\n",
       "      <td>eth</td>\n",
       "      <td>0.0</td>\n",
       "      <td>494000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531458600000</td>\n",
       "      <td>2018-07-13 05:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978</th>\n",
       "      <td>5180</td>\n",
       "      <td>xrp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531458600000</td>\n",
       "      <td>2018-07-13 05:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>5181</td>\n",
       "      <td>bch</td>\n",
       "      <td>0.0</td>\n",
       "      <td>791000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531458600000</td>\n",
       "      <td>2018-07-13 05:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4980</th>\n",
       "      <td>5182</td>\n",
       "      <td>etc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531458600000</td>\n",
       "      <td>2018-07-13 05:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>5183</td>\n",
       "      <td>btc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7085000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531459200000</td>\n",
       "      <td>2018-07-13 05:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>5184</td>\n",
       "      <td>eth</td>\n",
       "      <td>0.0</td>\n",
       "      <td>493500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531459200000</td>\n",
       "      <td>2018-07-13 05:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>5185</td>\n",
       "      <td>xrp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531459200000</td>\n",
       "      <td>2018-07-13 05:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4984</th>\n",
       "      <td>5186</td>\n",
       "      <td>bch</td>\n",
       "      <td>0.0</td>\n",
       "      <td>791000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531459200000</td>\n",
       "      <td>2018-07-13 05:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>5187</td>\n",
       "      <td>etc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18880.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531459200000</td>\n",
       "      <td>2018-07-13 05:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>5188</td>\n",
       "      <td>btc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7090000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531459800000</td>\n",
       "      <td>2018-07-13 05:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4987</th>\n",
       "      <td>5189</td>\n",
       "      <td>eth</td>\n",
       "      <td>0.0</td>\n",
       "      <td>494500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531459800000</td>\n",
       "      <td>2018-07-13 05:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>5190</td>\n",
       "      <td>xrp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531459800000</td>\n",
       "      <td>2018-07-13 05:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>5191</td>\n",
       "      <td>bch</td>\n",
       "      <td>0.0</td>\n",
       "      <td>791000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531459800000</td>\n",
       "      <td>2018-07-13 05:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>5192</td>\n",
       "      <td>etc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18870.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531459800000</td>\n",
       "      <td>2018-07-13 05:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>5193</td>\n",
       "      <td>btc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7088000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531460400000</td>\n",
       "      <td>2018-07-13 05:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>5194</td>\n",
       "      <td>eth</td>\n",
       "      <td>0.0</td>\n",
       "      <td>494500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531460400000</td>\n",
       "      <td>2018-07-13 05:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>5195</td>\n",
       "      <td>xrp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531460400000</td>\n",
       "      <td>2018-07-13 05:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>5196</td>\n",
       "      <td>bch</td>\n",
       "      <td>0.0</td>\n",
       "      <td>791000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531460400000</td>\n",
       "      <td>2018-07-13 05:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>5197</td>\n",
       "      <td>etc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18880.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531460400000</td>\n",
       "      <td>2018-07-13 05:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>5198</td>\n",
       "      <td>btc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7087000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531461000000</td>\n",
       "      <td>2018-07-13 05:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>5199</td>\n",
       "      <td>eth</td>\n",
       "      <td>0.0</td>\n",
       "      <td>494500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531461000000</td>\n",
       "      <td>2018-07-13 05:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>5200</td>\n",
       "      <td>xrp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531461000000</td>\n",
       "      <td>2018-07-13 05:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>5201</td>\n",
       "      <td>bch</td>\n",
       "      <td>0.0</td>\n",
       "      <td>792000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1531461000000</td>\n",
       "      <td>2018-07-13 05:50:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id symbol  price_start  price_end  price_max  price_min  volume  \\\n",
       "0        1    btc          0.0  7094000.0        0.0        0.0     0.0   \n",
       "1        2    eth          0.0   521000.0        0.0        0.0     0.0   \n",
       "2        3    xrp          0.0      542.0        0.0        0.0     0.0   \n",
       "3        4    bch          0.0   856000.0        0.0        0.0     0.0   \n",
       "4        5    ltc          0.0    93000.0        0.0        0.0     0.0   \n",
       "5        6   dash          0.0   271300.0        0.0        0.0     0.0   \n",
       "6        7    etc          0.0    17830.0        0.0        0.0     0.0   \n",
       "7        8    btc          0.0  7046000.0        0.0        0.0     0.0   \n",
       "8        9    eth          0.0   521000.0        0.0        0.0     0.0   \n",
       "9       10    xrp          0.0      541.0        0.0        0.0     0.0   \n",
       "10      11    bch          0.0   854000.0        0.0        0.0     0.0   \n",
       "11      12    ltc          0.0    92500.0        0.0        0.0     0.0   \n",
       "12      13   dash          0.0   271200.0        0.0        0.0     0.0   \n",
       "13      14    etc          0.0    17760.0        0.0        0.0     0.0   \n",
       "14      15    btc          0.0  7048000.0        0.0        0.0     0.0   \n",
       "15      16    eth          0.0   521000.0        0.0        0.0     0.0   \n",
       "16      17    xrp          0.0      542.0        0.0        0.0     0.0   \n",
       "17      18    bch          0.0   856000.0        0.0        0.0     0.0   \n",
       "18      19    ltc          0.0    92400.0        0.0        0.0     0.0   \n",
       "19      20   dash          0.0   273000.0        0.0        0.0     0.0   \n",
       "20      21    etc          0.0    17750.0        0.0        0.0     0.0   \n",
       "21      22    btc          0.0  7052000.0        0.0        0.0     0.0   \n",
       "22      23    eth          0.0   521000.0        0.0        0.0     0.0   \n",
       "23      24    xrp          0.0      542.0        0.0        0.0     0.0   \n",
       "24      25    bch          0.0   852000.0        0.0        0.0     0.0   \n",
       "25      26    ltc          0.0    93200.0        0.0        0.0     0.0   \n",
       "26      27   dash          0.0   273000.0        0.0        0.0     0.0   \n",
       "27      28    etc          0.0    17860.0        0.0        0.0     0.0   \n",
       "28      29    btc          0.0  7042000.0        0.0        0.0     0.0   \n",
       "29      30    eth          0.0   520000.0        0.0        0.0     0.0   \n",
       "...    ...    ...          ...        ...        ...        ...     ...   \n",
       "4970  5172    etc          0.0    18900.0        0.0        0.0     0.0   \n",
       "4971  5173    btc          0.0  7092000.0        0.0        0.0     0.0   \n",
       "4972  5174    eth          0.0   494500.0        0.0        0.0     0.0   \n",
       "4973  5175    xrp          0.0      503.0        0.0        0.0     0.0   \n",
       "4974  5176    bch          0.0   790000.0        0.0        0.0     0.0   \n",
       "4975  5177    etc          0.0    18870.0        0.0        0.0     0.0   \n",
       "4976  5178    btc          0.0  7093000.0        0.0        0.0     0.0   \n",
       "4977  5179    eth          0.0   494000.0        0.0        0.0     0.0   \n",
       "4978  5180    xrp          0.0      502.0        0.0        0.0     0.0   \n",
       "4979  5181    bch          0.0   791000.0        0.0        0.0     0.0   \n",
       "4980  5182    etc          0.0    18900.0        0.0        0.0     0.0   \n",
       "4981  5183    btc          0.0  7085000.0        0.0        0.0     0.0   \n",
       "4982  5184    eth          0.0   493500.0        0.0        0.0     0.0   \n",
       "4983  5185    xrp          0.0      503.0        0.0        0.0     0.0   \n",
       "4984  5186    bch          0.0   791000.0        0.0        0.0     0.0   \n",
       "4985  5187    etc          0.0    18880.0        0.0        0.0     0.0   \n",
       "4986  5188    btc          0.0  7090000.0        0.0        0.0     0.0   \n",
       "4987  5189    eth          0.0   494500.0        0.0        0.0     0.0   \n",
       "4988  5190    xrp          0.0      503.0        0.0        0.0     0.0   \n",
       "4989  5191    bch          0.0   791000.0        0.0        0.0     0.0   \n",
       "4990  5192    etc          0.0    18870.0        0.0        0.0     0.0   \n",
       "4991  5193    btc          0.0  7088000.0        0.0        0.0     0.0   \n",
       "4992  5194    eth          0.0   494500.0        0.0        0.0     0.0   \n",
       "4993  5195    xrp          0.0      504.0        0.0        0.0     0.0   \n",
       "4994  5196    bch          0.0   791000.0        0.0        0.0     0.0   \n",
       "4995  5197    etc          0.0    18880.0        0.0        0.0     0.0   \n",
       "4996  5198    btc          0.0  7087000.0        0.0        0.0     0.0   \n",
       "4997  5199    eth          0.0   494500.0        0.0        0.0     0.0   \n",
       "4998  5200    xrp          0.0      503.0        0.0        0.0     0.0   \n",
       "4999  5201    bch          0.0   792000.0        0.0        0.0     0.0   \n",
       "\n",
       "         time_epoch            date_time  \n",
       "0     1529944200000  2018-06-25 16:30:00  \n",
       "1     1529944200000  2018-06-25 16:30:00  \n",
       "2     1529944200000  2018-06-25 16:30:00  \n",
       "3     1529944200000  2018-06-25 16:30:00  \n",
       "4     1529944200000  2018-06-25 16:30:00  \n",
       "5     1529944200000  2018-06-25 16:30:00  \n",
       "6     1529944200000  2018-06-25 16:30:00  \n",
       "7     1529947800000  2018-06-25 17:30:00  \n",
       "8     1529947800000  2018-06-25 17:30:00  \n",
       "9     1529947800000  2018-06-25 17:30:00  \n",
       "10    1529947800000  2018-06-25 17:30:00  \n",
       "11    1529947800000  2018-06-25 17:30:00  \n",
       "12    1529947800000  2018-06-25 17:30:00  \n",
       "13    1529947800000  2018-06-25 17:30:00  \n",
       "14    1529949600000  2018-06-25 18:00:00  \n",
       "15    1529949600000  2018-06-25 18:00:00  \n",
       "16    1529949600000  2018-06-25 18:00:00  \n",
       "17    1529949600000  2018-06-25 18:00:00  \n",
       "18    1529949600000  2018-06-25 18:00:00  \n",
       "19    1529949600000  2018-06-25 18:00:00  \n",
       "20    1529949600000  2018-06-25 18:00:00  \n",
       "21    1529951400000  2018-06-25 18:30:00  \n",
       "22    1529951400000  2018-06-25 18:30:00  \n",
       "23    1529951400000  2018-06-25 18:30:00  \n",
       "24    1529951400000  2018-06-25 18:30:00  \n",
       "25    1529951400000  2018-06-25 18:30:00  \n",
       "26    1529951400000  2018-06-25 18:30:00  \n",
       "27    1529951400000  2018-06-25 18:30:00  \n",
       "28    1529953200000  2018-06-25 19:00:00  \n",
       "29    1529953200000  2018-06-25 19:00:00  \n",
       "...             ...                  ...  \n",
       "4970  1531457400000  2018-07-13 04:50:00  \n",
       "4971  1531458000000  2018-07-13 05:00:00  \n",
       "4972  1531458000000  2018-07-13 05:00:00  \n",
       "4973  1531458000000  2018-07-13 05:00:00  \n",
       "4974  1531458000000  2018-07-13 05:00:00  \n",
       "4975  1531458000000  2018-07-13 05:00:00  \n",
       "4976  1531458600000  2018-07-13 05:10:00  \n",
       "4977  1531458600000  2018-07-13 05:10:00  \n",
       "4978  1531458600000  2018-07-13 05:10:00  \n",
       "4979  1531458600000  2018-07-13 05:10:00  \n",
       "4980  1531458600000  2018-07-13 05:10:00  \n",
       "4981  1531459200000  2018-07-13 05:20:00  \n",
       "4982  1531459200000  2018-07-13 05:20:00  \n",
       "4983  1531459200000  2018-07-13 05:20:00  \n",
       "4984  1531459200000  2018-07-13 05:20:00  \n",
       "4985  1531459200000  2018-07-13 05:20:00  \n",
       "4986  1531459800000  2018-07-13 05:30:00  \n",
       "4987  1531459800000  2018-07-13 05:30:00  \n",
       "4988  1531459800000  2018-07-13 05:30:00  \n",
       "4989  1531459800000  2018-07-13 05:30:00  \n",
       "4990  1531459800000  2018-07-13 05:30:00  \n",
       "4991  1531460400000  2018-07-13 05:40:00  \n",
       "4992  1531460400000  2018-07-13 05:40:00  \n",
       "4993  1531460400000  2018-07-13 05:40:00  \n",
       "4994  1531460400000  2018-07-13 05:40:00  \n",
       "4995  1531460400000  2018-07-13 05:40:00  \n",
       "4996  1531461000000  2018-07-13 05:50:00  \n",
       "4997  1531461000000  2018-07-13 05:50:00  \n",
       "4998  1531461000000  2018-07-13 05:50:00  \n",
       "4999  1531461000000  2018-07-13 05:50:00  \n",
       "\n",
       "[5000 rows x 9 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'coin_data.csv'\n",
    "x2 = pd.read_csv(file)\n",
    "x2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      2\n",
       "2      3\n",
       "3      4\n",
       "4      5\n",
       "5      6\n",
       "6      7\n",
       "7      8\n",
       "8      9\n",
       "9     10\n",
       "10    11\n",
       "11    12\n",
       "12    13\n",
       "13    14\n",
       "14    15\n",
       "15    16\n",
       "16    17\n",
       "17    18\n",
       "18    19\n",
       "Name: A, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=19, step=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 'X', '10.3745/JIPS.02.0107',\n",
       "        'Young-Sik Jeong and Jong Hyuk Park',\n",
       "        'Advanced Big Data Analysis, Artificial Intelligence & Communication Systems',\n",
       "        'Recently, big data and artificial intelligence (AI) based on communication systems have become one of the\\nhottest issues in the technology sector, and methods of analyzing big data using AI approaches are now\\nconsidered essential. This paper presents diverse paradigms to subjects which deal with diverse research areas, such as image segmentation, fingerprint matching, human tracking techniques, malware distribution networks, methods of intrusion detection, digital image watermarking, wireless sensor networks, probabilistic neural networks, query processing of encrypted data, the semantic web, decision-making, software engineering, and so on.',\n",
       "        'Artificial Intelligence, Big Data, Communication System', 2019,\n",
       "        15, 1, 1, 6],\n",
       "       [2, 'X', '10.3745/JIPS.02.0105', 'Yan Wang  and Xianfa Xu',\n",
       "        'An Improved Level Set Method to Image Segmentation Based on Saliency',\n",
       "        'In order to improve the edge segmentation effect of the level set image segmentation and avoid the influence of\\nthe initial contour on the level set method, a saliency level set image segmentation model based on local Renyi\\nentropy is proposed. Firstly, the saliency map of the original image is extracted by using saliency detection\\nalgorithm. And the outline of the saliency map can be used to initialize the level set. Secondly, the local energy\\nand edge energy of the image are obtained by using local Renyi entropy and Canny operator respectively. At\\nthe same time, new adaptive weight coefficient and boundary indication function are constructed. Finally, the\\nlocal binary fitting energy model (LBF) as an external energy term is introduced. In this paper, the contrast\\nexperiments are implemented in different image database. The robustness of the proposed model for\\nsegmentation of images with intensity inhomogeneity and complicated edges is verified.',\n",
       "        'Canny Operator, Edge Energy, Level Set Method, Local Renyi Entropy, Saliency Map',\n",
       "        2019, 15, 1, 7, 21],\n",
       "       [3, 'X', '10.3745/JIPS.04.0098', 'Kittiya Khongkraphan',\n",
       "        'An Efficient Fingerprint Matching by Multiple Reference Points',\n",
       "        'This paper introduces an efficient fingerprint matching method based on multiple reference minutiae points.\\nFirst, we attempt to effectively align two fingerprints by employing multiple reference minutiae points.\\nHowever, the corresponding minutiae points between two fingerprints are ambiguous since a minutia of one\\nfingerprint can be a match to any minutia of the other fingerprint. Therefore, we introduce a novel method\\nbased on linear classification concept to establish minutiae correspondences between two fingerprints. Each\\nminutiae correspondence represents a possible alignment. For each possible alignment, a matching score is\\ncomputed using minutiae and ridge orientation features and the maximum score is then selected to represent\\nthe similarity of the two fingerprints. The proposed method is evaluated using fingerprint databases, FVC2002\\nand FVC2004. In addition, we compare our approach with two existing methods and find that our approach\\noutperforms them in term of matching accuracy, especially in the case of non-linear distorted fingerprints.\\nFurthermore, the experiments show that our method provides additional advantages in low quality fingerprint\\nimages such as inaccurate position, missing minutiae, and spurious extracted minutiae.',\n",
       "        'Fingerprint Matching, Matching Score, Multiple Reference Points, Non-linear Distortion',\n",
       "        2019, 15, 1, 22, 33],\n",
       "       [4, 'X', '10.3745/JIPS.02.0106',\n",
       "        'Jinlong Zhu, Fanhua Yu, Mingyu Sun, Dong Zhao, and Qingtian Geng',\n",
       "        'Foreign Detection based on Wavelet Transform Algorithm with Image Analysis Mechanism in The Inner Wall of The Tube',\n",
       "        'A method for detecting foreign substances in mould based on scatter grams was presented to protect moulds\\nautomatically during moulding production. This paper proposes a wavelet transform foreign detection method\\nbased on Monte Carlo analysis mechanism to identify foreign objects in the tube. We use the Monte Carlo\\nmethod to evaluate the image, and obtain the width of the confidence interval by the deviation statistical gray\\nhistogram to divide the image type. In order to stabilize the performance of the algorithm, the high-frequency\\nimage and the low-frequency image are respectively drawn. By analyzing the position distribution of the pixel\\ngray in the two images, the suspected foreign object region is obtained. The experiments demonstrate the\\neffectiveness of our approach by evaluating the labeled data.',\n",
       "        'Foreign Substance Inspection, Monte Carlo, Wavelets Transform',\n",
       "        2019, 15, 1, 34, 46],\n",
       "       [5, 'X', '10.3745/JIPS.04.0099', 'Jaeyoung Park and Sangjoon Lee',\n",
       "        'A Study on an Automatic Multi-Focus System for Cell Observation',\n",
       "        'This study is concerned with the mechanism and structure of an optical microscope and an automatic multifocus\\nalgorithm for automatically selecting sharp images from multiple foci of a cell. To obtain precise cell\\nimages quickly, a z-axis actuator with a resolution of 0.1 μm was designed to control an optical microscope\\nMoreover, a lighting control system was constructed to select the color and brightness of light that best suit the\\nobject being viewed. Cell images are captured by the instrument and the sharpness of each image is determined\\nusing Gaussian and Laplacian filters. Next, cubic spline interpolation and peak detection algorithms are applied\\nto automatically find the most vivid points among multiple images of a single object. A cancer cell imaging\\nexperiment using propidium iodide staining confirmed that a sharp multipoint image can be obtained using\\nthis microscope. The proposed system is expected to save time and effort required to extract suitable cell images\\nand increase the convenience of cell analysis.',\n",
       "        'Automatic Multi-Focus, Cell Observation, Cubic Spline Interpolation, Peak Detection',\n",
       "        2019, 15, 1, 47, 54],\n",
       "       [6, 'X', '10.3745/JIPS.01.0035', 'Jun Li and  Mengshu Hou',\n",
       "        'HRSF: Single Disk Failure Recovery for Liberation Code Based Storage Systems',\n",
       "        'Storage system often applies erasure codes to protect against disk failure and ensure system reliability and\\navailability. Liberation code that is a type of coding scheme has been widely used in many storage systems\\nbecause its encoding and modifying operations are efficient. However, it cannot effectively achieve fast recovery\\nfrom single disk failure in storage systems, and has great influence on recovery performance as well as response\\ntime of client requests. To solve this problem, in this paper, we present HRSF, a Hybrid Recovery method for\\nsolving Single disk Failure. We present the optimal algorithm to accelerate failure recovery process. Theoretical\\nanalysis proves that our scheme consumes approximately 25% less amount of data read than the conventional\\nmethod. In the evaluation, we perform extensive experiments by setting different number of disks and chunk\\nsizes. The results show that HRSF outperforms conventional method in terms of the amount of data read and\\nfailure recovery time.',\n",
       "        'Erasure Codes, Disk Failure, Recovery Scheme, Reliability, Storage System',\n",
       "        2019, 15, 1, 55, 66],\n",
       "       [7, 'X', '10.3745/JIPS.04.0100',\n",
       "        'Sunitha Madasi Ramachandra, Haradagere Siddaramaiah Jayanna, and Ramegowda',\n",
       "        'Hierarchical Graph based Segmentation and Consensus based Human Tracking Technique  ',\n",
       "        'Accurate detection, tracking and analysis of human movement using robots and other visual surveillance\\nsystems is still a challenge. Efforts are on to make the system robust against constraints such as variation in\\nshape, size, pose and occlusion. Traditional methods of detection used the sliding window approach which\\ninvolved scanning of various sizes of windows across an image. This paper concentrates on employing a stateof-\\nthe-art, hierarchical graph based method for segmentation. It has two stages: part level segmentation for\\ncolor-consistent segments and object level segmentation for category-consistent regions. The tracking phase is\\nachieved by employing SIFT keypoint descriptor based technique in a combined matching and tracking scheme\\nwith validation phase. Localization of human region in each frame is performed by keypoints by casting votes\\nfor the center of the human detected region. As it is difficult to avoid incorrect keypoints, a consensus-based\\nframework is used to detect voting behavior. The designed methodology is tested on the video sequences having\\n3 to 4 persons.',\n",
       "        'Consensus Based Framework, Hierarchical Graph Based Segmentation, SIFT Keypoint Descriptor',\n",
       "        2019, 15, 1, 67, 90],\n",
       "       [8, 'X', '10.3745/JIPS.04.0101',\n",
       "        'Hao Chao, Cheng Song, Bao-yun Lu, and Yong-li Liu ',\n",
       "        'Feature Extraction based on DBN-SVM for Tone Recognition',\n",
       "        'An innovative tone modeling framework based on deep neural networks in tone recognition was proposed in\\nthis paper. In the framework, both the prosodic features and the articulatory features were firstly extracted as\\nthe raw input data. Then, a 5-layer-deep deep belief network was presented to obtain high-level tone features.\\nFinally, support vector machine was trained to recognize tones. The 863-data corpus had been applied in\\nexperiments, and the results show that the proposed method helped improve the recognition accuracy\\nsignificantly for all tone patterns. Meanwhile, the average tone recognition rate reached 83.03%, which is 8.61%\\nhigher than that of the original method.',\n",
       "        'Deep Belief Networks, Deep Learning, Feature Fusion, Support Vector Machine, Tone Feature Extraction',\n",
       "        2019, 15, 1, 91, 99],\n",
       "       [9, 'X', '10.3745/JIPS.03.0107',\n",
       "        'Sang-Yong Choi, Chang Gyoon Lim, and Yong-Min Kim',\n",
       "        'Automated Link Tracing for Classification of Malicious Websites in Malware Distribution Networks',\n",
       "        'Malicious code distribution on the Internet is one of the most critical Internet-based threats and distribution\\ntechnology has evolved to bypass detection systems. As a new defense against the detection bypass technology\\nof malicious attackers, this study proposes the automated tracing of malicious websites in a malware\\ndistribution network (MDN). The proposed technology extracts automated links and classifies websites into\\nmalicious and normal websites based on link structure. Even if attackers use a new distribution technology,\\nwebsite classification is possible as long as the connections are established through automated links. The use of\\na real web-browser and proxy server enables an adequate response to attackers’ perception of analysis\\nenvironments and evasion technology and prevents analysis environments from being infected by malicious\\ncode. The validity and accuracy of the proposed method for classification are verified using 20,000 links, 10,000\\neach from normal and malicious websites.',\n",
       "        'Auto Link Tracer, Drive-by Download, Malicious Website, MDN, Real Browser and Forward Proxy',\n",
       "        2019, 15, 1, 100, 115],\n",
       "       [10, 'X', '10.3745/JIPS.04.0102', 'Liquan Zhao and Yan Long',\n",
       "        'An Improved PSO Algorithm for the Classification of Multiple Power Quality Disturbances',\n",
       "        'In this paper, an improved one-against-one support vector machine algorithm is used to classify multiple power\\nquality disturbances. To solve the problem of parameter selection, an improved particle swarm optimization\\nalgorithm is proposed to optimize the parameters of the support vector machine. By proposing a new inertia\\nweight expression, the particle swarm optimization algorithm can effectively conduct a global search at the\\noutset and effectively search locally later in a study, which improves the overall classification accuracy. The\\nexperimental results show that the improved particle swarm optimization method is more accurate than a grid\\nsearch algorithm optimization and other improved particle swarm optimizations with regard to its classification\\nof multiple power quality disturbances. Furthermore, the number of support vectors is reduced.',\n",
       "        'Classification Accuracy, Classification of Power Quality Disturbance, Particle Swarm Optimization, Support\\nVector Machine',\n",
       "        2019, 15, 1, 116, 126],\n",
       "       [11, 'X', '10.3745/JIPS.01.0036', 'Se-Chang Oh and Min Choi',\n",
       "        'A Simple and Effective Combination of User-Based and Item-Based Recommendation Methods',\n",
       "        'User-based and item-based approaches have been developed as the solutions of the movie recommendation\\nproblem. However, the user-based approach is faced with the problem of sparsity, and the item-based approach\\nis faced with the problem of not reflecting users’ preferences. In order to solve these problems, there is a research\\non the combination of the two methods using the concept of similarity. In reality, it is not free from the problem\\nof sparsity, since it has a lot of parameters to be calculated. In this study, we propose a combining method that\\nsimplifies the combination equation of prior study. This method is relatively free from the problem of sparsity,\\nsince it has less parameters to be calculated. Thus, it can get more accurate results by reflecting the users rating\\nto calculate the parameters. It is very fast to predict new movie ratings as well. In experiments for the proposed\\nmethod, the initial error is large, but the performance gets quickly stabilized after. In addition, it showed about\\n6% lower average error rate than the existing method using similarity.',\n",
       "        'Collaborative Filtering, Electronic Commerce, Recommender System, Sparsity',\n",
       "        2019, 15, 1, 127, 136],\n",
       "       [12, 'X', '10.3745/JIPS.03.0108', 'Ruirui Zhang and Xin Xiao',\n",
       "        'An Intrusion Detection Method Based on Changes of Antibody Concentration in Immune Response',\n",
       "        'Although the research of immune-based anomaly detection technology has made some progress, there are still\\nsome defects which have not been solved, such as the loophole problem which leads to low detection rate and\\nhigh false alarm rate, the exponential relationship between training cost of mature detectors and size of selfantigens.\\nThis paper proposed an intrusion detection method based on changes of antibody concentration in\\nimmune response to improve and solve existing problems of immune based anomaly detection technology. The\\nmethod introduces blood relative and blood family to classify antibodies and antigens and simulate correlations\\nbetween antibodies and antigens. Then, the method establishes dynamic evolution models of antigens and\\nantibodies in intrusion detection. In addition, the method determines concentration changes of antibodies in\\nthe immune system drawing the experience of cloud model, and divides the risk levels to guide immune\\nresponses. Experimental results show that the method has better detection performance and adaptability than\\ntraditional methods.',\n",
       "        'Antibody Concentration, Artificial Immune, Cloud Model, Evolutionary Algorithms, Intrusion Detection',\n",
       "        2019, 15, 1, 137, 150],\n",
       "       [13, 'X', '10.3745/JIPS.01.0037',\n",
       "        'Yongseob Lee and Sungyong Park',\n",
       "        'MBS-LVM: A High-Performance Logical Volume Manager for Memory Bus-connected Storages over NUMA Servers',\n",
       "        'With the recent advances of memory technologies, high-performance non-volatile memories such as nonvolatile\\ndual in-line memory module (NVDIMM) have begun to be used as an addition or an alternative to\\nserver-side storages. When these memory bus-connected storages (MBSs) are installed over non-uniform\\nmemory access (NUMA) servers, the distance between NUMA nodes and MBSs is one of the crucial factors\\nthat influence file processing performance, because the access latency of a NUMA system varies depending on\\nits distance from the NUMA nodes. This paper presents the design and implementation of a high-performance\\nlogical volume manager for MBSs, called MBS-LVM, when multiple MBSs are scattered over a NUMA server.\\nThe MBS-LVM consolidates the address space of each MBS into a single global address space and dynamically\\nutilizes storage spaces such that each thread can access an MBS with the lowest latency possible. We\\nimplemented the MBS-LVM in the Linux kernel and evaluated its performance by porting it over the tmpfs, a\\nmemory-based file system widely used in Linux. The results of the benchmarking show that the write\\nperformance of the tmpfs using MBS-LVM has been improved by up to twenty times against the original tmpfs\\nover a NUMA server with four nodes.',\n",
       "        'Logical Volume Manager, Memory Bus Connected Storage, Non-volatile Memory, NUMA, NVDIMM',\n",
       "        2019, 15, 1, 151, 158],\n",
       "       [14, 'X', '10.3745/JIPS.01.0038',\n",
       "        'Mubarak Adam Ishag Mahmoud and Honge Ren ',\n",
       "        'Forest fire detection and identification using image processing and SVM',\n",
       "        'Accurate forest fires detection algorithms remain a challenging issue, because, some of the objects have the\\nsame features with fire, which may result in high false alarms rate. This paper presents a new video-based, image\\nprocessing forest fires detection method, which consists of four stages. First, a background-subtraction\\nalgorithm is applied to detect moving regions. Secondly, candidate fire regions are determined using CIE\\nL∗a∗b∗ color space. Thirdly, special wavelet analysis is used to differentiate between actual fire and fire-like\\nobjects, because candidate regions may contain moving fire-like objects. Finally, support vector machine is used\\nto classify the region of interest to either real fire or non-fire. The final experimental results verify that the\\nproposed method effectively identifies the forest fires.',\n",
       "        'Background Subtraction, CIE L∗a∗b∗ Color Space, Forest Fire, SVM, Wavelet',\n",
       "        2019, 15, 1, 159, 168],\n",
       "       [15, 'X', '10.3745/JIPS.03.0109',\n",
       "        'Jantana Panyavaraporn and Paramate Horkaew',\n",
       "        'Wavelet-based Digital Image Watermarking by using Lorenz Chaotic Signal Localization',\n",
       "        'Transmitting visual information over a broadcasting network is not only prone to a copyright violation but also\\nis a forgery. Authenticating such information and protecting its authorship rights call for more advanced data\\nencoding. To this end, electronic watermarking is often adopted to embed inscriptive signature in imaging data.\\nMost existing watermarking methods while focusing on robustness against degradation remain lacking of\\nmeasurement against security loophole in which the encrypting scheme once discovered may be recreated by\\nan unauthorized party. This could reveal the underlying signature which may potentially be replaced or forged.\\nThis paper therefore proposes a novel digital watermarking scheme in temporal-frequency domain. Unlike\\nother typical wavelet based watermarking, the proposed scheme employed the Lorenz chaotic map to specify\\nembedding positions. Effectively making this is not only a formidable method to decrypt but also a stronger\\nwill against deterministic attacks. Simulation report herein highlights its strength to withstand spatial and\\nfrequent adulterations, e.g., lossy compression, filtering, zooming and noise.',\n",
       "        'Binary Image, Chaotic Signal, QR Code, Watermarking, Wavelet Analysis',\n",
       "        2019, 15, 1, 169, 180],\n",
       "       [16, 'X', '10.3745/JIPS.04.0103', 'Hyun Sik Sim',\n",
       "        'A Study on the Development and Effect of Smart Manufacturing System in PCB Line',\n",
       "        'A production system is a management system that supports all activities to perform production operations at\\nthe manufacturing site. From the point-of-view of a smart factory, smart manufacturing systems redesigned the\\nconcept of onsite production systems to fit the entire system and its necessary functional composition. In this\\nstudy, we select the key functions needed to build a smart factory for a PCB line and propose a new six-step\\nmodel for the deployment of a smart manufacturing system by integrating essential functions. The smart\\nmanufacturing system newly classified the production and operation tasks of PCB manufacturing and selected\\nnecessary functions through requirement analysis and benchmarking of advanced companies. The selected\\nproduction operation tasks are mapped to the functions of the system and configured into seven modules, and\\nthe optimal deployment model is presented to allow flexible responses to the characteristics of the tasks. These\\nmethodologies are first presented in this study, and the proposed model was applied to the PCB line to confirm\\nthat they had significant changes in the work method, qualitative effects, and quantitative effects. Typically, lead\\ntime and WIP have reduced by about 50%.',\n",
       "        'Effectiveness Evaluation, Key Function Extraction, Manufacturing Execution System, Smart Factory, Smart\\nManufacturing System, 4th Industrial Revolution',\n",
       "        2019, 15, 1, 181, 188],\n",
       "       [17, 'X', '10.3745/JIPS.04.0104',\n",
       "        'Li-jun Chen, Yang Wang, and Cheng Su',\n",
       "        'Simulation study on measuring pulverized coal concentration in power plant boiler',\n",
       "        'During thermal power coal-fired boiler operation, it is very important to detect the pulverized coal\\nconcentration in the air pipeline for the boiler combustion stability and economic security. Because the current\\nmeasurement methods used by power plants are often involved with large measurement errors and unable to\\nmonitor the pulverized coal concentration in real-time, a new method is needed. In this paper, a new method\\nbased on microwave circular waveguide is presented. High Frequency Electromagnetic Simulation (HFSS)\\nsoftware was used to construct a simulation model for measuring pulverized coal concentration in power plant\\npipeline. Theoretical analysis and simulation experiments were done to find the effective microwave emission\\nfrequency, installation angle, the type of antenna probe, antenna installation distance and other important\\nparameters. Finally, field experiment in Jilin Thermal Power Plant proved that with selected parameters, the\\nmeasuring device accurately reflected the changes in the concentration of pulverized coal.',\n",
       "        'Circular Waveguide, Concentration of Pulverized Coal, Firing Frequency, HFSS',\n",
       "        2019, 15, 1, 189, 202],\n",
       "       [18, 'X', '10.3745/JIPS.03.0110',\n",
       "        'J. Sebastian Terence and Geethanjali Purushothaman',\n",
       "        'A Novel Technique to Detect Malicious Packet Dropping Attacks in Wireless Sensor Networks',\n",
       "        'The nature of wireless transmission has made wireless sensor networks defenseless against various attacks. This\\npaper presents warning message counter method (WMC) to detect blackhole attack, grayhole attack and\\nsinkhole attack in wireless sensor networks. The objective of these attackers are, to draw the nearby network\\ntraffic by false routing information and disrupt the network operation through dropping all the received packets\\n(blackhole attack), selectively dropping the received packets (grayhole and sinkhole attack) and modifying the\\ncontent of the packet (sinkhole attack). We have also attempted light weighted symmetric key cryptography to\\nfind data modification by the sinkhole node. Simulation results shows that, WMC detects sinkhole attack,\\nblackhole attack and grayhole attack with less false positive 8% and less false negative 6%.',\n",
       "        'Blackhole Attack, Grayhole Attack, Packet Dropping Attacks, Sinkhole Attack, Wireless Sensor Network',\n",
       "        2019, 15, 1, 203, 216],\n",
       "       [19, 'X', '10.3745/JIPS.04.0105', 'Jun-Ho Huh and Kyungryong Seo',\n",
       "        \"Digitalization of Seafarer's Book for Authentication and e-Navigation\",\n",
       "        \"Currently, the crew working on a ship is required to carry a seafarer's book in most countries around the world,\\nincluding the Republic of Korea (ROK). Yet, many fishermen working in the international waters of the ROK\\ndo not abide by this rule as the procedure of obtaining it is rather inconvenient or they do not understand the\\nnecessity or the benefits of having it. Also, as the regulation of carrying the certificate has been strengthened, it\\nis important for them to avoid making a criminal record unintentionally. This study discusses the digitalization\\nof the seafarer’s book based on several security measures in addition to BLE Beacon-based positioning\\ntechnology, which can be useful for the e-Navigation. Normally, seamen’s certificates are recorded by the\\ncaptain, medical institution, or issuing authority and then kept in an onboard safe or a certificate cabinet. The\\nmaterial of the certificates is a cloth that can withstand salinity as the certificate could be contaminated by mold.\\nIn the past, the captains and their crews were uncooperative when the ROK’s maritime police tried to inspect\\nseveral ships simultaneously because of the time and cost involved. Thus, a system with which the maritime\\npolice will be able to conveniently manage the crews is proposed.\",\n",
       "        'Android Application, Authentication, Digitalization, e-Navigation, Parallel Computing, Seafarer’s Book, Seaman\\nService Book, System Architecture',\n",
       "        2019, 15, 1, 217, 232]], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "      <th>K</th>\n",
       "      <th>L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>109.105263</td>\n",
       "      <td>120.315789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.627314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.837889</td>\n",
       "      <td>69.172130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.500000</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14.500000</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>174.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>232.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               A       H     I     J           K           L\n",
       "count  19.000000    19.0  19.0  19.0   19.000000   19.000000\n",
       "mean   10.000000  2019.0  15.0   1.0  109.105263  120.315789\n",
       "std     5.627314     0.0   0.0   0.0   68.837889   69.172130\n",
       "min     1.000000  2019.0  15.0   1.0    1.000000    6.000000\n",
       "25%     5.500000  2019.0  15.0   1.0   51.000000   60.000000\n",
       "50%    10.000000  2019.0  15.0   1.0  116.000000  126.000000\n",
       "75%    14.500000  2019.0  15.0   1.0  164.000000  174.000000\n",
       "max    19.000000  2019.0  15.0   1.0  217.000000  232.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    L\n",
       "0    1    6\n",
       "1    2   21\n",
       "2    3   33\n",
       "3    4   46\n",
       "4    5   54\n",
       "5    6   66\n",
       "6    7   90\n",
       "7    8   99\n",
       "8    9  115\n",
       "9   10  126\n",
       "10  11  136\n",
       "11  12  150\n",
       "12  13  158\n",
       "13  14  168\n",
       "14  15  180\n",
       "15  16  188\n",
       "16  17  202\n",
       "17  18  216\n",
       "18  19  232"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['A','L']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.Series([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['M'] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "      <th>K</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "      <td>10.3745/JIPS.02.0107</td>\n",
       "      <td>Young-Sik Jeong and Jong Hyuk Park</td>\n",
       "      <td>Advanced Big Data Analysis, Artificial Intelli...</td>\n",
       "      <td>Recently, big data and artificial intelligence...</td>\n",
       "      <td>Artificial Intelligence, Big Data, Communicati...</td>\n",
       "      <td>2019</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>X</td>\n",
       "      <td>10.3745/JIPS.02.0105</td>\n",
       "      <td>Yan Wang  and Xianfa Xu</td>\n",
       "      <td>An Improved Level Set Method to Image Segmenta...</td>\n",
       "      <td>In order to improve the edge segmentation effe...</td>\n",
       "      <td>Canny Operator, Edge Energy, Level Set Method,...</td>\n",
       "      <td>2019</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>X</td>\n",
       "      <td>10.3745/JIPS.04.0098</td>\n",
       "      <td>Kittiya Khongkraphan</td>\n",
       "      <td>An Efficient Fingerprint Matching by Multiple ...</td>\n",
       "      <td>This paper introduces an efficient fingerprint...</td>\n",
       "      <td>Fingerprint Matching, Matching Score, Multiple...</td>\n",
       "      <td>2019</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>33</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>X</td>\n",
       "      <td>10.3745/JIPS.02.0106</td>\n",
       "      <td>Jinlong Zhu, Fanhua Yu, Mingyu Sun, Dong Zhao,...</td>\n",
       "      <td>Foreign Detection based on Wavelet Transform A...</td>\n",
       "      <td>A method for detecting foreign substances in m...</td>\n",
       "      <td>Foreign Substance Inspection, Monte Carlo, Wav...</td>\n",
       "      <td>2019</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>46</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>X</td>\n",
       "      <td>10.3745/JIPS.04.0099</td>\n",
       "      <td>Jaeyoung Park and Sangjoon Lee</td>\n",
       "      <td>A Study on an Automatic Multi-Focus System for...</td>\n",
       "      <td>This study is concerned with the mechanism and...</td>\n",
       "      <td>Automatic Multi-Focus, Cell Observation, Cubic...</td>\n",
       "      <td>2019</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>54</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>X</td>\n",
       "      <td>10.3745/JIPS.01.0035</td>\n",
       "      <td>Jun Li and  Mengshu Hou</td>\n",
       "      <td>HRSF: Single Disk Failure Recovery for Liberat...</td>\n",
       "      <td>Storage system often applies erasure codes to ...</td>\n",
       "      <td>Erasure Codes, Disk Failure, Recovery Scheme, ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>66</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>X</td>\n",
       "      <td>10.3745/JIPS.04.0100</td>\n",
       "      <td>Sunitha Madasi Ramachandra, Haradagere Siddara...</td>\n",
       "      <td>Hierarchical Graph based Segmentation and Cons...</td>\n",
       "      <td>Accurate detection, tracking and analysis of h...</td>\n",
       "      <td>Consensus Based Framework, Hierarchical Graph ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>90</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>X</td>\n",
       "      <td>10.3745/JIPS.04.0101</td>\n",
       "      <td>Hao Chao, Cheng Song, Bao-yun Lu, and Yong-li ...</td>\n",
       "      <td>Feature Extraction based on DBN-SVM for Tone R...</td>\n",
       "      <td>An innovative tone modeling framework based on...</td>\n",
       "      <td>Deep Belief Networks, Deep Learning, Feature F...</td>\n",
       "      <td>2019</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>99</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>X</td>\n",
       "      <td>10.3745/JIPS.03.0107</td>\n",
       "      <td>Sang-Yong Choi, Chang Gyoon Lim, and Yong-Min Kim</td>\n",
       "      <td>Automated Link Tracing for Classification of M...</td>\n",
       "      <td>Malicious code distribution on the Internet is...</td>\n",
       "      <td>Auto Link Tracer, Drive-by Download, Malicious...</td>\n",
       "      <td>2019</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>115</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>X</td>\n",
       "      <td>10.3745/JIPS.04.0102</td>\n",
       "      <td>Liquan Zhao and Yan Long</td>\n",
       "      <td>An Improved PSO Algorithm for the Classificati...</td>\n",
       "      <td>In this paper, an improved one-against-one sup...</td>\n",
       "      <td>Classification Accuracy, Classification of Pow...</td>\n",
       "      <td>2019</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>126</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>X</td>\n",
       "      <td>10.3745/JIPS.01.0036</td>\n",
       "      <td>Se-Chang Oh and Min Choi</td>\n",
       "      <td>A Simple and Effective Combination of User-Bas...</td>\n",
       "      <td>User-based and item-based approaches have been...</td>\n",
       "      <td>Collaborative Filtering, Electronic Commerce, ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>127</td>\n",
       "      <td>136</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>X</td>\n",
       "      <td>10.3745/JIPS.03.0108</td>\n",
       "      <td>Ruirui Zhang and Xin Xiao</td>\n",
       "      <td>An Intrusion Detection Method Based on Changes...</td>\n",
       "      <td>Although the research of immune-based anomaly ...</td>\n",
       "      <td>Antibody Concentration, Artificial Immune, Clo...</td>\n",
       "      <td>2019</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "      <td>150</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>X</td>\n",
       "      <td>10.3745/JIPS.01.0037</td>\n",
       "      <td>Yongseob Lee and Sungyong Park</td>\n",
       "      <td>MBS-LVM: A High-Performance Logical Volume Man...</td>\n",
       "      <td>With the recent advances of memory technologie...</td>\n",
       "      <td>Logical Volume Manager, Memory Bus Connected S...</td>\n",
       "      <td>2019</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>158</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>X</td>\n",
       "      <td>10.3745/JIPS.01.0038</td>\n",
       "      <td>Mubarak Adam Ishag Mahmoud and Honge Ren</td>\n",
       "      <td>Forest fire detection and identification using...</td>\n",
       "      <td>Accurate forest fires detection algorithms rem...</td>\n",
       "      <td>Background Subtraction, CIE L∗a∗b∗ Color Space...</td>\n",
       "      <td>2019</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>159</td>\n",
       "      <td>168</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>X</td>\n",
       "      <td>10.3745/JIPS.03.0109</td>\n",
       "      <td>Jantana Panyavaraporn and Paramate Horkaew</td>\n",
       "      <td>Wavelet-based Digital Image Watermarking by us...</td>\n",
       "      <td>Transmitting visual information over a broadca...</td>\n",
       "      <td>Binary Image, Chaotic Signal, QR Code, Waterma...</td>\n",
       "      <td>2019</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "      <td>180</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>X</td>\n",
       "      <td>10.3745/JIPS.04.0103</td>\n",
       "      <td>Hyun Sik Sim</td>\n",
       "      <td>A Study on the Development and Effect of Smart...</td>\n",
       "      <td>A production system is a management system tha...</td>\n",
       "      <td>Effectiveness Evaluation, Key Function Extract...</td>\n",
       "      <td>2019</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>188</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>X</td>\n",
       "      <td>10.3745/JIPS.04.0104</td>\n",
       "      <td>Li-jun Chen, Yang Wang, and Cheng Su</td>\n",
       "      <td>Simulation study on measuring pulverized coal ...</td>\n",
       "      <td>During thermal power coal-fired boiler operati...</td>\n",
       "      <td>Circular Waveguide, Concentration of Pulverize...</td>\n",
       "      <td>2019</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>202</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>X</td>\n",
       "      <td>10.3745/JIPS.03.0110</td>\n",
       "      <td>J. Sebastian Terence and Geethanjali Purushoth...</td>\n",
       "      <td>A Novel Technique to Detect Malicious Packet D...</td>\n",
       "      <td>The nature of wireless transmission has made w...</td>\n",
       "      <td>Blackhole Attack, Grayhole Attack, Packet Drop...</td>\n",
       "      <td>2019</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>203</td>\n",
       "      <td>216</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>X</td>\n",
       "      <td>10.3745/JIPS.04.0105</td>\n",
       "      <td>Jun-Ho Huh and Kyungryong Seo</td>\n",
       "      <td>Digitalization of Seafarer's Book for Authenti...</td>\n",
       "      <td>Currently, the crew working on a ship is requi...</td>\n",
       "      <td>Android Application, Authentication, Digitaliz...</td>\n",
       "      <td>2019</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>217</td>\n",
       "      <td>232</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A  B                     C  \\\n",
       "0    1  X  10.3745/JIPS.02.0107   \n",
       "1    2  X  10.3745/JIPS.02.0105   \n",
       "2    3  X  10.3745/JIPS.04.0098   \n",
       "3    4  X  10.3745/JIPS.02.0106   \n",
       "4    5  X  10.3745/JIPS.04.0099   \n",
       "5    6  X  10.3745/JIPS.01.0035   \n",
       "6    7  X  10.3745/JIPS.04.0100   \n",
       "7    8  X  10.3745/JIPS.04.0101   \n",
       "8    9  X  10.3745/JIPS.03.0107   \n",
       "9   10  X  10.3745/JIPS.04.0102   \n",
       "10  11  X  10.3745/JIPS.01.0036   \n",
       "11  12  X  10.3745/JIPS.03.0108   \n",
       "12  13  X  10.3745/JIPS.01.0037   \n",
       "13  14  X  10.3745/JIPS.01.0038   \n",
       "14  15  X  10.3745/JIPS.03.0109   \n",
       "15  16  X  10.3745/JIPS.04.0103   \n",
       "16  17  X  10.3745/JIPS.04.0104   \n",
       "17  18  X  10.3745/JIPS.03.0110   \n",
       "18  19  X  10.3745/JIPS.04.0105   \n",
       "\n",
       "                                                    D  \\\n",
       "0                  Young-Sik Jeong and Jong Hyuk Park   \n",
       "1                             Yan Wang  and Xianfa Xu   \n",
       "2                                Kittiya Khongkraphan   \n",
       "3   Jinlong Zhu, Fanhua Yu, Mingyu Sun, Dong Zhao,...   \n",
       "4                      Jaeyoung Park and Sangjoon Lee   \n",
       "5                             Jun Li and  Mengshu Hou   \n",
       "6   Sunitha Madasi Ramachandra, Haradagere Siddara...   \n",
       "7   Hao Chao, Cheng Song, Bao-yun Lu, and Yong-li ...   \n",
       "8   Sang-Yong Choi, Chang Gyoon Lim, and Yong-Min Kim   \n",
       "9                            Liquan Zhao and Yan Long   \n",
       "10                           Se-Chang Oh and Min Choi   \n",
       "11                          Ruirui Zhang and Xin Xiao   \n",
       "12                     Yongseob Lee and Sungyong Park   \n",
       "13          Mubarak Adam Ishag Mahmoud and Honge Ren    \n",
       "14         Jantana Panyavaraporn and Paramate Horkaew   \n",
       "15                                       Hyun Sik Sim   \n",
       "16               Li-jun Chen, Yang Wang, and Cheng Su   \n",
       "17  J. Sebastian Terence and Geethanjali Purushoth...   \n",
       "18                      Jun-Ho Huh and Kyungryong Seo   \n",
       "\n",
       "                                                    E  \\\n",
       "0   Advanced Big Data Analysis, Artificial Intelli...   \n",
       "1   An Improved Level Set Method to Image Segmenta...   \n",
       "2   An Efficient Fingerprint Matching by Multiple ...   \n",
       "3   Foreign Detection based on Wavelet Transform A...   \n",
       "4   A Study on an Automatic Multi-Focus System for...   \n",
       "5   HRSF: Single Disk Failure Recovery for Liberat...   \n",
       "6   Hierarchical Graph based Segmentation and Cons...   \n",
       "7   Feature Extraction based on DBN-SVM for Tone R...   \n",
       "8   Automated Link Tracing for Classification of M...   \n",
       "9   An Improved PSO Algorithm for the Classificati...   \n",
       "10  A Simple and Effective Combination of User-Bas...   \n",
       "11  An Intrusion Detection Method Based on Changes...   \n",
       "12  MBS-LVM: A High-Performance Logical Volume Man...   \n",
       "13  Forest fire detection and identification using...   \n",
       "14  Wavelet-based Digital Image Watermarking by us...   \n",
       "15  A Study on the Development and Effect of Smart...   \n",
       "16  Simulation study on measuring pulverized coal ...   \n",
       "17  A Novel Technique to Detect Malicious Packet D...   \n",
       "18  Digitalization of Seafarer's Book for Authenti...   \n",
       "\n",
       "                                                    F  \\\n",
       "0   Recently, big data and artificial intelligence...   \n",
       "1   In order to improve the edge segmentation effe...   \n",
       "2   This paper introduces an efficient fingerprint...   \n",
       "3   A method for detecting foreign substances in m...   \n",
       "4   This study is concerned with the mechanism and...   \n",
       "5   Storage system often applies erasure codes to ...   \n",
       "6   Accurate detection, tracking and analysis of h...   \n",
       "7   An innovative tone modeling framework based on...   \n",
       "8   Malicious code distribution on the Internet is...   \n",
       "9   In this paper, an improved one-against-one sup...   \n",
       "10  User-based and item-based approaches have been...   \n",
       "11  Although the research of immune-based anomaly ...   \n",
       "12  With the recent advances of memory technologie...   \n",
       "13  Accurate forest fires detection algorithms rem...   \n",
       "14  Transmitting visual information over a broadca...   \n",
       "15  A production system is a management system tha...   \n",
       "16  During thermal power coal-fired boiler operati...   \n",
       "17  The nature of wireless transmission has made w...   \n",
       "18  Currently, the crew working on a ship is requi...   \n",
       "\n",
       "                                                    G     H   I  J    K    L  \\\n",
       "0   Artificial Intelligence, Big Data, Communicati...  2019  15  1    1    6   \n",
       "1   Canny Operator, Edge Energy, Level Set Method,...  2019  15  1    7   21   \n",
       "2   Fingerprint Matching, Matching Score, Multiple...  2019  15  1   22   33   \n",
       "3   Foreign Substance Inspection, Monte Carlo, Wav...  2019  15  1   34   46   \n",
       "4   Automatic Multi-Focus, Cell Observation, Cubic...  2019  15  1   47   54   \n",
       "5   Erasure Codes, Disk Failure, Recovery Scheme, ...  2019  15  1   55   66   \n",
       "6   Consensus Based Framework, Hierarchical Graph ...  2019  15  1   67   90   \n",
       "7   Deep Belief Networks, Deep Learning, Feature F...  2019  15  1   91   99   \n",
       "8   Auto Link Tracer, Drive-by Download, Malicious...  2019  15  1  100  115   \n",
       "9   Classification Accuracy, Classification of Pow...  2019  15  1  116  126   \n",
       "10  Collaborative Filtering, Electronic Commerce, ...  2019  15  1  127  136   \n",
       "11  Antibody Concentration, Artificial Immune, Clo...  2019  15  1  137  150   \n",
       "12  Logical Volume Manager, Memory Bus Connected S...  2019  15  1  151  158   \n",
       "13  Background Subtraction, CIE L∗a∗b∗ Color Space...  2019  15  1  159  168   \n",
       "14  Binary Image, Chaotic Signal, QR Code, Waterma...  2019  15  1  169  180   \n",
       "15  Effectiveness Evaluation, Key Function Extract...  2019  15  1  181  188   \n",
       "16  Circular Waveguide, Concentration of Pulverize...  2019  15  1  189  202   \n",
       "17  Blackhole Attack, Grayhole Attack, Packet Drop...  2019  15  1  203  216   \n",
       "18  Android Application, Authentication, Digitaliz...  2019  15  1  217  232   \n",
       "\n",
       "       M  \n",
       "0    1.0  \n",
       "1    2.0  \n",
       "2    3.0  \n",
       "3    4.0  \n",
       "4    5.0  \n",
       "5    6.0  \n",
       "6    7.0  \n",
       "7    8.0  \n",
       "8    9.0  \n",
       "9   10.0  \n",
       "10  11.0  \n",
       "11  12.0  \n",
       "12  13.0  \n",
       "13  14.0  \n",
       "14  15.0  \n",
       "15  16.0  \n",
       "16   NaN  \n",
       "17   NaN  \n",
       "18   NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
